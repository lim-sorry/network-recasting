{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "from model import CustomResNet\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import ToTensor, Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'cifar100'\n",
    "student_name = 'resnet38_baseline'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_class = 100\n",
    "batch_size = 128\n",
    "epoch = 180\n",
    "gamma = 0.2\n",
    "milestones = [60, 120, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(size=[32, 32], padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR100(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 569972\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CustomResNet(block=BasicBlock,\n",
    "                   layers=[6, 6, 6],\n",
    "                   num_classes=num_class).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(params=model.parameters(), lr=0.1, nesterov=True, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0, train_loss=4.0690, test_acc=0.109\n",
      "epoch=  1, train_loss=3.4937, test_acc=0.188\n",
      "epoch=  2, train_loss=3.0126, test_acc=0.278\n",
      "epoch=  3, train_loss=2.6186, test_acc=0.335\n",
      "epoch=  4, train_loss=2.3225, test_acc=0.393\n",
      "epoch=  5, train_loss=2.1022, test_acc=0.411\n",
      "epoch=  6, train_loss=1.9345, test_acc=0.434\n",
      "epoch=  7, train_loss=1.8037, test_acc=0.465\n",
      "epoch=  8, train_loss=1.7150, test_acc=0.463\n",
      "epoch=  9, train_loss=1.6302, test_acc=0.510\n",
      "epoch= 10, train_loss=1.5611, test_acc=0.488\n",
      "epoch= 11, train_loss=1.5005, test_acc=0.523\n",
      "epoch= 12, train_loss=1.4488, test_acc=0.512\n",
      "epoch= 13, train_loss=1.4027, test_acc=0.510\n",
      "epoch= 14, train_loss=1.3705, test_acc=0.525\n",
      "epoch= 15, train_loss=1.3294, test_acc=0.542\n",
      "epoch= 16, train_loss=1.3020, test_acc=0.532\n",
      "epoch= 17, train_loss=1.2647, test_acc=0.535\n",
      "epoch= 18, train_loss=1.2358, test_acc=0.557\n",
      "epoch= 19, train_loss=1.2121, test_acc=0.563\n",
      "epoch= 20, train_loss=1.1869, test_acc=0.530\n",
      "epoch= 21, train_loss=1.1708, test_acc=0.554\n",
      "epoch= 22, train_loss=1.1403, test_acc=0.567\n",
      "epoch= 23, train_loss=1.1274, test_acc=0.585\n",
      "epoch= 24, train_loss=1.1167, test_acc=0.579\n",
      "epoch= 25, train_loss=1.0840, test_acc=0.541\n",
      "epoch= 26, train_loss=1.0861, test_acc=0.572\n",
      "epoch= 27, train_loss=1.0665, test_acc=0.571\n",
      "epoch= 28, train_loss=1.0462, test_acc=0.590\n",
      "epoch= 29, train_loss=1.0387, test_acc=0.550\n",
      "epoch= 30, train_loss=1.0301, test_acc=0.587\n",
      "epoch= 31, train_loss=1.0151, test_acc=0.576\n",
      "epoch= 32, train_loss=1.0038, test_acc=0.612\n",
      "epoch= 33, train_loss=0.9918, test_acc=0.600\n",
      "epoch= 34, train_loss=0.9796, test_acc=0.583\n",
      "epoch= 35, train_loss=0.9747, test_acc=0.598\n",
      "epoch= 36, train_loss=0.9679, test_acc=0.568\n",
      "epoch= 37, train_loss=0.9600, test_acc=0.594\n",
      "epoch= 38, train_loss=0.9489, test_acc=0.594\n",
      "epoch= 39, train_loss=0.9365, test_acc=0.581\n",
      "epoch= 40, train_loss=0.9346, test_acc=0.593\n",
      "epoch= 41, train_loss=0.9250, test_acc=0.599\n",
      "epoch= 42, train_loss=0.9224, test_acc=0.599\n",
      "epoch= 43, train_loss=0.9117, test_acc=0.596\n",
      "epoch= 44, train_loss=0.8965, test_acc=0.596\n",
      "epoch= 45, train_loss=0.8934, test_acc=0.586\n",
      "epoch= 46, train_loss=0.8975, test_acc=0.591\n",
      "epoch= 47, train_loss=0.8915, test_acc=0.578\n",
      "epoch= 48, train_loss=0.8791, test_acc=0.598\n",
      "epoch= 49, train_loss=0.8793, test_acc=0.602\n",
      "epoch= 50, train_loss=0.8680, test_acc=0.602\n",
      "epoch= 51, train_loss=0.8650, test_acc=0.596\n",
      "epoch= 52, train_loss=0.8662, test_acc=0.595\n",
      "epoch= 53, train_loss=0.8514, test_acc=0.583\n",
      "epoch= 54, train_loss=0.8424, test_acc=0.606\n",
      "epoch= 55, train_loss=0.8544, test_acc=0.596\n",
      "epoch= 56, train_loss=0.8391, test_acc=0.614\n",
      "epoch= 57, train_loss=0.8397, test_acc=0.613\n",
      "epoch= 58, train_loss=0.8444, test_acc=0.581\n",
      "epoch= 59, train_loss=0.8326, test_acc=0.607\n",
      "epoch= 60, train_loss=0.5564, test_acc=0.690\n",
      "epoch= 61, train_loss=0.4745, test_acc=0.690\n",
      "epoch= 62, train_loss=0.4409, test_acc=0.688\n",
      "epoch= 63, train_loss=0.4250, test_acc=0.685\n",
      "epoch= 64, train_loss=0.4070, test_acc=0.687\n",
      "epoch= 65, train_loss=0.3909, test_acc=0.687\n",
      "epoch= 66, train_loss=0.3773, test_acc=0.684\n",
      "epoch= 67, train_loss=0.3719, test_acc=0.681\n",
      "epoch= 68, train_loss=0.3605, test_acc=0.687\n",
      "epoch= 69, train_loss=0.3522, test_acc=0.686\n",
      "epoch= 70, train_loss=0.3410, test_acc=0.685\n",
      "epoch= 71, train_loss=0.3413, test_acc=0.675\n",
      "epoch= 72, train_loss=0.3391, test_acc=0.678\n",
      "epoch= 73, train_loss=0.3259, test_acc=0.677\n",
      "epoch= 74, train_loss=0.3241, test_acc=0.677\n",
      "epoch= 75, train_loss=0.3180, test_acc=0.676\n",
      "epoch= 76, train_loss=0.3156, test_acc=0.669\n",
      "epoch= 77, train_loss=0.3128, test_acc=0.669\n",
      "epoch= 78, train_loss=0.3174, test_acc=0.669\n",
      "epoch= 79, train_loss=0.3121, test_acc=0.674\n",
      "epoch= 80, train_loss=0.3055, test_acc=0.665\n",
      "epoch= 81, train_loss=0.3101, test_acc=0.669\n",
      "epoch= 82, train_loss=0.3088, test_acc=0.671\n",
      "epoch= 83, train_loss=0.3024, test_acc=0.674\n",
      "epoch= 84, train_loss=0.2987, test_acc=0.663\n",
      "epoch= 85, train_loss=0.3072, test_acc=0.666\n",
      "epoch= 86, train_loss=0.2995, test_acc=0.673\n",
      "epoch= 87, train_loss=0.3013, test_acc=0.667\n",
      "epoch= 88, train_loss=0.3012, test_acc=0.663\n",
      "epoch= 89, train_loss=0.2961, test_acc=0.669\n",
      "epoch= 90, train_loss=0.2963, test_acc=0.665\n",
      "epoch= 91, train_loss=0.2890, test_acc=0.663\n",
      "epoch= 92, train_loss=0.2942, test_acc=0.660\n",
      "epoch= 93, train_loss=0.2933, test_acc=0.659\n",
      "epoch= 94, train_loss=0.2958, test_acc=0.665\n",
      "epoch= 95, train_loss=0.2859, test_acc=0.664\n",
      "epoch= 96, train_loss=0.2956, test_acc=0.664\n",
      "epoch= 97, train_loss=0.2875, test_acc=0.654\n",
      "epoch= 98, train_loss=0.2871, test_acc=0.664\n",
      "epoch= 99, train_loss=0.2873, test_acc=0.661\n",
      "epoch=100, train_loss=0.2912, test_acc=0.662\n",
      "epoch=101, train_loss=0.2877, test_acc=0.663\n",
      "epoch=102, train_loss=0.2860, test_acc=0.663\n",
      "epoch=103, train_loss=0.2863, test_acc=0.654\n",
      "epoch=104, train_loss=0.2944, test_acc=0.653\n",
      "epoch=105, train_loss=0.2921, test_acc=0.655\n",
      "epoch=106, train_loss=0.2882, test_acc=0.658\n",
      "epoch=107, train_loss=0.2873, test_acc=0.648\n",
      "epoch=108, train_loss=0.2889, test_acc=0.655\n",
      "epoch=109, train_loss=0.2930, test_acc=0.660\n",
      "epoch=110, train_loss=0.2882, test_acc=0.649\n",
      "epoch=111, train_loss=0.2906, test_acc=0.657\n",
      "epoch=112, train_loss=0.2864, test_acc=0.661\n",
      "epoch=113, train_loss=0.2825, test_acc=0.657\n",
      "epoch=114, train_loss=0.2945, test_acc=0.656\n",
      "epoch=115, train_loss=0.2746, test_acc=0.661\n",
      "epoch=116, train_loss=0.2817, test_acc=0.660\n",
      "epoch=117, train_loss=0.2799, test_acc=0.663\n",
      "epoch=118, train_loss=0.2930, test_acc=0.661\n",
      "epoch=119, train_loss=0.2820, test_acc=0.663\n",
      "epoch=120, train_loss=0.1830, test_acc=0.688\n",
      "epoch=121, train_loss=0.1485, test_acc=0.688\n",
      "epoch=122, train_loss=0.1374, test_acc=0.688\n",
      "epoch=123, train_loss=0.1269, test_acc=0.689\n",
      "epoch=124, train_loss=0.1229, test_acc=0.688\n",
      "epoch=125, train_loss=0.1184, test_acc=0.688\n",
      "epoch=126, train_loss=0.1170, test_acc=0.686\n",
      "epoch=127, train_loss=0.1115, test_acc=0.685\n",
      "epoch=128, train_loss=0.1076, test_acc=0.690\n",
      "epoch=129, train_loss=0.1068, test_acc=0.693\n",
      "epoch=130, train_loss=0.1034, test_acc=0.688\n",
      "epoch=131, train_loss=0.1011, test_acc=0.690\n",
      "epoch=132, train_loss=0.0997, test_acc=0.689\n",
      "epoch=133, train_loss=0.1003, test_acc=0.692\n",
      "epoch=134, train_loss=0.0965, test_acc=0.689\n",
      "epoch=135, train_loss=0.0932, test_acc=0.688\n",
      "epoch=136, train_loss=0.0939, test_acc=0.691\n",
      "epoch=137, train_loss=0.0907, test_acc=0.688\n",
      "epoch=138, train_loss=0.0896, test_acc=0.691\n",
      "epoch=139, train_loss=0.0920, test_acc=0.690\n",
      "epoch=140, train_loss=0.0886, test_acc=0.689\n",
      "epoch=141, train_loss=0.0881, test_acc=0.686\n",
      "epoch=142, train_loss=0.0866, test_acc=0.686\n",
      "epoch=143, train_loss=0.0855, test_acc=0.685\n",
      "epoch=144, train_loss=0.0867, test_acc=0.687\n",
      "epoch=145, train_loss=0.0866, test_acc=0.686\n",
      "epoch=146, train_loss=0.0827, test_acc=0.689\n",
      "epoch=147, train_loss=0.0823, test_acc=0.684\n",
      "epoch=148, train_loss=0.0817, test_acc=0.685\n",
      "epoch=149, train_loss=0.0810, test_acc=0.687\n",
      "epoch=150, train_loss=0.0741, test_acc=0.688\n",
      "epoch=151, train_loss=0.0709, test_acc=0.691\n",
      "epoch=152, train_loss=0.0725, test_acc=0.691\n",
      "epoch=153, train_loss=0.0710, test_acc=0.690\n",
      "epoch=154, train_loss=0.0685, test_acc=0.690\n",
      "epoch=155, train_loss=0.0691, test_acc=0.689\n",
      "epoch=156, train_loss=0.0696, test_acc=0.692\n",
      "epoch=157, train_loss=0.0662, test_acc=0.692\n",
      "epoch=158, train_loss=0.0668, test_acc=0.690\n",
      "epoch=159, train_loss=0.0660, test_acc=0.690\n",
      "epoch=160, train_loss=0.0656, test_acc=0.691\n",
      "epoch=161, train_loss=0.0667, test_acc=0.688\n",
      "epoch=162, train_loss=0.0647, test_acc=0.691\n",
      "epoch=163, train_loss=0.0649, test_acc=0.691\n",
      "epoch=164, train_loss=0.0659, test_acc=0.689\n",
      "epoch=165, train_loss=0.0639, test_acc=0.689\n",
      "epoch=166, train_loss=0.0657, test_acc=0.690\n",
      "epoch=167, train_loss=0.0641, test_acc=0.690\n",
      "epoch=168, train_loss=0.0641, test_acc=0.687\n",
      "epoch=169, train_loss=0.0646, test_acc=0.689\n",
      "epoch=170, train_loss=0.0638, test_acc=0.689\n",
      "epoch=171, train_loss=0.0644, test_acc=0.689\n",
      "epoch=172, train_loss=0.0631, test_acc=0.689\n",
      "epoch=173, train_loss=0.0642, test_acc=0.687\n",
      "epoch=174, train_loss=0.0631, test_acc=0.688\n",
      "epoch=175, train_loss=0.0630, test_acc=0.688\n",
      "epoch=176, train_loss=0.0637, test_acc=0.689\n",
      "epoch=177, train_loss=0.0626, test_acc=0.690\n",
      "epoch=178, train_loss=0.0635, test_acc=0.690\n",
      "epoch=179, train_loss=0.0609, test_acc=0.690\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], test_acc=[], train_time=[], test_time=[])\n",
    "for ep in range(epoch):\n",
    "    # train step\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    s_time = time.time()\n",
    "    for image, target in train_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, num_class).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    e_time = time.time()\n",
    "    history['train_loss'].append(train_loss/len(train_loader))\n",
    "    history['train_time'].append(e_time - s_time)\n",
    "\n",
    "    # test step\n",
    "    test_acc = 0.0\n",
    "    model.eval()\n",
    "    s_time = time.time()\n",
    "    for image, target in test_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, num_class).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        test_acc += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(target, dim=1)).item()\n",
    "    e_time = time.time()\n",
    "    history['test_acc'].append(test_acc/len(test_dataset))\n",
    "    history['test_time'].append(e_time - s_time)\n",
    "    print(f'epoch={ep:3d}, train_loss={train_loss/len(train_loader):.4f}, test_acc={test_acc/len(test_dataset):.3f}')\n",
    "\n",
    "    checkpoint = dict(\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "        history=history,\n",
    "        epoch=ep\n",
    "    )\n",
    "    torch.save(checkpoint, f'./result/{dataset_name}_{student_name}.pt')\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
