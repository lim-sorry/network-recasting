{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "from model import CustomResNet\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import ToTensor, Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'cifar100'\n",
    "student_name = 'resnet56_baseline'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_class = 100\n",
    "batch_size = 128\n",
    "epoch = 180\n",
    "gamma = 0.2\n",
    "milestones = [60, 120, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(size=[32, 32], padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR100(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 861620\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (24): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (25): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CustomResNet(block=BasicBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=num_class).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(params=model.parameters(), lr=0.1, nesterov=True, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0, train_loss=4.2635, test_acc=0.077\n",
      "epoch=  1, train_loss=3.6382, test_acc=0.156\n",
      "epoch=  2, train_loss=3.1579, test_acc=0.256\n",
      "epoch=  3, train_loss=2.7113, test_acc=0.297\n",
      "epoch=  4, train_loss=2.3728, test_acc=0.353\n",
      "epoch=  5, train_loss=2.1227, test_acc=0.428\n",
      "epoch=  6, train_loss=1.9483, test_acc=0.410\n",
      "epoch=  7, train_loss=1.8079, test_acc=0.471\n",
      "epoch=  8, train_loss=1.7059, test_acc=0.476\n",
      "epoch=  9, train_loss=1.6112, test_acc=0.450\n",
      "epoch= 10, train_loss=1.5346, test_acc=0.506\n",
      "epoch= 11, train_loss=1.4698, test_acc=0.520\n",
      "epoch= 12, train_loss=1.4201, test_acc=0.552\n",
      "epoch= 13, train_loss=1.3702, test_acc=0.526\n",
      "epoch= 14, train_loss=1.3253, test_acc=0.548\n",
      "epoch= 15, train_loss=1.2898, test_acc=0.570\n",
      "epoch= 16, train_loss=1.2536, test_acc=0.542\n",
      "epoch= 17, train_loss=1.2124, test_acc=0.556\n",
      "epoch= 18, train_loss=1.1928, test_acc=0.525\n",
      "epoch= 19, train_loss=1.1620, test_acc=0.562\n",
      "epoch= 20, train_loss=1.1401, test_acc=0.570\n",
      "epoch= 21, train_loss=1.1161, test_acc=0.588\n",
      "epoch= 22, train_loss=1.0863, test_acc=0.582\n",
      "epoch= 23, train_loss=1.0707, test_acc=0.580\n",
      "epoch= 24, train_loss=1.0570, test_acc=0.579\n",
      "epoch= 25, train_loss=1.0331, test_acc=0.540\n",
      "epoch= 26, train_loss=1.0127, test_acc=0.568\n",
      "epoch= 27, train_loss=1.0052, test_acc=0.588\n",
      "epoch= 28, train_loss=0.9882, test_acc=0.566\n",
      "epoch= 29, train_loss=0.9718, test_acc=0.573\n",
      "epoch= 30, train_loss=0.9612, test_acc=0.559\n",
      "epoch= 31, train_loss=0.9431, test_acc=0.562\n",
      "epoch= 32, train_loss=0.9304, test_acc=0.604\n",
      "epoch= 33, train_loss=0.9259, test_acc=0.603\n",
      "epoch= 34, train_loss=0.9020, test_acc=0.596\n",
      "epoch= 35, train_loss=0.9029, test_acc=0.594\n",
      "epoch= 36, train_loss=0.8963, test_acc=0.596\n",
      "epoch= 37, train_loss=0.8800, test_acc=0.589\n",
      "epoch= 38, train_loss=0.8780, test_acc=0.587\n",
      "epoch= 39, train_loss=0.8572, test_acc=0.590\n",
      "epoch= 40, train_loss=0.8535, test_acc=0.598\n",
      "epoch= 41, train_loss=0.8474, test_acc=0.592\n",
      "epoch= 42, train_loss=0.8385, test_acc=0.582\n",
      "epoch= 43, train_loss=0.8335, test_acc=0.588\n",
      "epoch= 44, train_loss=0.8223, test_acc=0.599\n",
      "epoch= 45, train_loss=0.8289, test_acc=0.596\n",
      "epoch= 46, train_loss=0.8068, test_acc=0.611\n",
      "epoch= 47, train_loss=0.8163, test_acc=0.607\n",
      "epoch= 48, train_loss=0.8015, test_acc=0.597\n",
      "epoch= 49, train_loss=0.7975, test_acc=0.613\n",
      "epoch= 50, train_loss=0.7897, test_acc=0.608\n",
      "epoch= 51, train_loss=0.7822, test_acc=0.596\n",
      "epoch= 52, train_loss=0.7747, test_acc=0.609\n",
      "epoch= 53, train_loss=0.7804, test_acc=0.616\n",
      "epoch= 54, train_loss=0.7779, test_acc=0.621\n",
      "epoch= 55, train_loss=0.7647, test_acc=0.628\n",
      "epoch= 56, train_loss=0.7569, test_acc=0.616\n",
      "epoch= 57, train_loss=0.7554, test_acc=0.594\n",
      "epoch= 58, train_loss=0.7562, test_acc=0.596\n",
      "epoch= 59, train_loss=0.7565, test_acc=0.589\n",
      "epoch= 60, train_loss=0.4664, test_acc=0.691\n",
      "epoch= 61, train_loss=0.3775, test_acc=0.693\n",
      "epoch= 62, train_loss=0.3459, test_acc=0.694\n",
      "epoch= 63, train_loss=0.3158, test_acc=0.696\n",
      "epoch= 64, train_loss=0.2975, test_acc=0.696\n",
      "epoch= 65, train_loss=0.2803, test_acc=0.691\n",
      "epoch= 66, train_loss=0.2750, test_acc=0.689\n",
      "epoch= 67, train_loss=0.2605, test_acc=0.688\n",
      "epoch= 68, train_loss=0.2529, test_acc=0.687\n",
      "epoch= 69, train_loss=0.2473, test_acc=0.686\n",
      "epoch= 70, train_loss=0.2370, test_acc=0.685\n",
      "epoch= 71, train_loss=0.2341, test_acc=0.681\n",
      "epoch= 72, train_loss=0.2203, test_acc=0.684\n",
      "epoch= 73, train_loss=0.2270, test_acc=0.682\n",
      "epoch= 74, train_loss=0.2178, test_acc=0.678\n",
      "epoch= 75, train_loss=0.2153, test_acc=0.676\n",
      "epoch= 76, train_loss=0.2104, test_acc=0.679\n",
      "epoch= 77, train_loss=0.2092, test_acc=0.679\n",
      "epoch= 78, train_loss=0.2079, test_acc=0.679\n",
      "epoch= 79, train_loss=0.1971, test_acc=0.675\n",
      "epoch= 80, train_loss=0.2046, test_acc=0.673\n",
      "epoch= 81, train_loss=0.2039, test_acc=0.670\n",
      "epoch= 82, train_loss=0.1927, test_acc=0.674\n",
      "epoch= 83, train_loss=0.1950, test_acc=0.674\n",
      "epoch= 84, train_loss=0.1942, test_acc=0.673\n",
      "epoch= 85, train_loss=0.1940, test_acc=0.674\n",
      "epoch= 86, train_loss=0.1950, test_acc=0.680\n",
      "epoch= 87, train_loss=0.1904, test_acc=0.672\n",
      "epoch= 88, train_loss=0.1976, test_acc=0.669\n",
      "epoch= 89, train_loss=0.2000, test_acc=0.677\n",
      "epoch= 90, train_loss=0.1946, test_acc=0.671\n",
      "epoch= 91, train_loss=0.1974, test_acc=0.670\n",
      "epoch= 92, train_loss=0.1928, test_acc=0.668\n",
      "epoch= 93, train_loss=0.1926, test_acc=0.670\n",
      "epoch= 94, train_loss=0.1895, test_acc=0.667\n",
      "epoch= 95, train_loss=0.1832, test_acc=0.665\n",
      "epoch= 96, train_loss=0.1933, test_acc=0.665\n",
      "epoch= 97, train_loss=0.1944, test_acc=0.668\n",
      "epoch= 98, train_loss=0.1886, test_acc=0.666\n",
      "epoch= 99, train_loss=0.1917, test_acc=0.666\n",
      "epoch=100, train_loss=0.1990, test_acc=0.667\n",
      "epoch=101, train_loss=0.1992, test_acc=0.662\n",
      "epoch=102, train_loss=0.1956, test_acc=0.668\n",
      "epoch=103, train_loss=0.1911, test_acc=0.670\n",
      "epoch=104, train_loss=0.1986, test_acc=0.664\n",
      "epoch=105, train_loss=0.1930, test_acc=0.657\n",
      "epoch=106, train_loss=0.1981, test_acc=0.666\n",
      "epoch=107, train_loss=0.1924, test_acc=0.665\n",
      "epoch=108, train_loss=0.2004, test_acc=0.662\n",
      "epoch=109, train_loss=0.2026, test_acc=0.660\n",
      "epoch=110, train_loss=0.2011, test_acc=0.668\n",
      "epoch=111, train_loss=0.1902, test_acc=0.674\n",
      "epoch=112, train_loss=0.1904, test_acc=0.663\n",
      "epoch=113, train_loss=0.1987, test_acc=0.662\n",
      "epoch=114, train_loss=0.2007, test_acc=0.669\n",
      "epoch=115, train_loss=0.1901, test_acc=0.656\n",
      "epoch=116, train_loss=0.1936, test_acc=0.658\n",
      "epoch=117, train_loss=0.1998, test_acc=0.659\n",
      "epoch=118, train_loss=0.1961, test_acc=0.668\n",
      "epoch=119, train_loss=0.1990, test_acc=0.652\n",
      "epoch=120, train_loss=0.1140, test_acc=0.695\n",
      "epoch=121, train_loss=0.0845, test_acc=0.696\n",
      "epoch=122, train_loss=0.0717, test_acc=0.696\n",
      "epoch=123, train_loss=0.0680, test_acc=0.698\n",
      "epoch=124, train_loss=0.0631, test_acc=0.695\n",
      "epoch=125, train_loss=0.0588, test_acc=0.697\n",
      "epoch=126, train_loss=0.0577, test_acc=0.696\n",
      "epoch=127, train_loss=0.0552, test_acc=0.694\n",
      "epoch=128, train_loss=0.0553, test_acc=0.697\n",
      "epoch=129, train_loss=0.0506, test_acc=0.694\n",
      "epoch=130, train_loss=0.0492, test_acc=0.696\n",
      "epoch=131, train_loss=0.0473, test_acc=0.695\n",
      "epoch=132, train_loss=0.0466, test_acc=0.694\n",
      "epoch=133, train_loss=0.0463, test_acc=0.694\n",
      "epoch=134, train_loss=0.0455, test_acc=0.694\n",
      "epoch=135, train_loss=0.0432, test_acc=0.695\n",
      "epoch=136, train_loss=0.0428, test_acc=0.694\n",
      "epoch=137, train_loss=0.0423, test_acc=0.694\n",
      "epoch=138, train_loss=0.0414, test_acc=0.696\n",
      "epoch=139, train_loss=0.0387, test_acc=0.696\n",
      "epoch=140, train_loss=0.0389, test_acc=0.695\n",
      "epoch=141, train_loss=0.0393, test_acc=0.694\n",
      "epoch=142, train_loss=0.0383, test_acc=0.693\n",
      "epoch=143, train_loss=0.0394, test_acc=0.693\n",
      "epoch=144, train_loss=0.0364, test_acc=0.694\n",
      "epoch=145, train_loss=0.0357, test_acc=0.688\n",
      "epoch=146, train_loss=0.0343, test_acc=0.694\n",
      "epoch=147, train_loss=0.0358, test_acc=0.693\n",
      "epoch=148, train_loss=0.0353, test_acc=0.693\n",
      "epoch=149, train_loss=0.0347, test_acc=0.693\n",
      "epoch=150, train_loss=0.0312, test_acc=0.695\n",
      "epoch=151, train_loss=0.0316, test_acc=0.696\n",
      "epoch=152, train_loss=0.0302, test_acc=0.696\n",
      "epoch=153, train_loss=0.0307, test_acc=0.694\n",
      "epoch=154, train_loss=0.0302, test_acc=0.695\n",
      "epoch=155, train_loss=0.0299, test_acc=0.693\n",
      "epoch=156, train_loss=0.0289, test_acc=0.695\n",
      "epoch=157, train_loss=0.0290, test_acc=0.693\n",
      "epoch=158, train_loss=0.0290, test_acc=0.695\n",
      "epoch=159, train_loss=0.0283, test_acc=0.696\n",
      "epoch=160, train_loss=0.0290, test_acc=0.695\n",
      "epoch=161, train_loss=0.0286, test_acc=0.693\n",
      "epoch=162, train_loss=0.0285, test_acc=0.696\n",
      "epoch=163, train_loss=0.0292, test_acc=0.695\n",
      "epoch=164, train_loss=0.0283, test_acc=0.694\n",
      "epoch=165, train_loss=0.0275, test_acc=0.696\n",
      "epoch=166, train_loss=0.0278, test_acc=0.695\n",
      "epoch=167, train_loss=0.0279, test_acc=0.695\n",
      "epoch=168, train_loss=0.0285, test_acc=0.694\n",
      "epoch=169, train_loss=0.0286, test_acc=0.696\n",
      "epoch=170, train_loss=0.0279, test_acc=0.695\n",
      "epoch=171, train_loss=0.0277, test_acc=0.696\n",
      "epoch=172, train_loss=0.0278, test_acc=0.695\n",
      "epoch=173, train_loss=0.0265, test_acc=0.695\n",
      "epoch=174, train_loss=0.0275, test_acc=0.695\n",
      "epoch=175, train_loss=0.0269, test_acc=0.695\n",
      "epoch=176, train_loss=0.0267, test_acc=0.694\n",
      "epoch=177, train_loss=0.0263, test_acc=0.695\n",
      "epoch=178, train_loss=0.0259, test_acc=0.694\n",
      "epoch=179, train_loss=0.0271, test_acc=0.695\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], test_acc=[], train_time=[], test_time=[])\n",
    "for ep in range(epoch):\n",
    "    # train step\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    s_time = time.time()\n",
    "    for image, target in train_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, num_class).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    e_time = time.time()\n",
    "    history['train_loss'].append(train_loss/len(train_loader))\n",
    "    history['train_time'].append(e_time - s_time)\n",
    "\n",
    "    # test step\n",
    "    test_acc = 0.0\n",
    "    model.eval()\n",
    "    s_time = time.time()\n",
    "    for image, target in test_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, num_class).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        test_acc += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(target, dim=1)).item()\n",
    "    e_time = time.time()\n",
    "    history['test_acc'].append(test_acc/len(test_dataset))\n",
    "    history['test_time'].append(e_time - s_time)\n",
    "    print(f'epoch={ep:3d}, train_loss={train_loss/len(train_loader):.4f}, test_acc={test_acc/len(test_dataset):.3f}')\n",
    "\n",
    "    checkpoint = dict(\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "        history=history,\n",
    "        epoch=ep\n",
    "    )\n",
    "    torch.save(checkpoint, f'./result/{dataset_name}_{student_name}.pt')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4625.111322402954"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./result/cifar10_resnet56_baseline.pt')\n",
    "sum(checkpoint['history']['train_time']) + sum(checkpoint['history']['test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033.6733675003052, 185.7128963470459)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./result/cifar10_resnet56_recast.pt')\n",
    "sum(checkpoint['history'][0]['train_time']), sum(checkpoint['history'][0]['test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvBlock\n",
    "student_name = 'resnet56_recast'\n",
    "\n",
    "model = CustomResNet(block=BasicBlock,\n",
    "                layers=[9, 9, 9],\n",
    "                num_classes=10).to(device).eval()\n",
    "model.layers[0] = ConvBlock(16,16,2)\n",
    "state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layers.0.conv1.weight', 'layers.0.bn1.weight', 'layers.0.bn1.bias', 'layers.0.bn1.running_mean', 'layers.0.bn1.running_var', 'layers.0.bn1.num_batches_tracked', 'layers.1.conv1.weight', 'layers.1.bn1.weight', 'layers.1.bn1.bias', 'layers.1.bn1.running_mean', 'layers.1.bn1.running_var', 'layers.1.bn1.num_batches_tracked', 'layers.1.conv2.weight', 'layers.1.bn2.weight', 'layers.1.bn2.bias', 'layers.1.bn2.running_mean', 'layers.1.bn2.running_var', 'layers.1.bn2.num_batches_tracked', 'layers.2.conv1.weight', 'layers.2.bn1.weight', 'layers.2.bn1.bias', 'layers.2.bn1.running_mean', 'layers.2.bn1.running_var', 'layers.2.bn1.num_batches_tracked', 'layers.2.conv2.weight', 'layers.2.bn2.weight', 'layers.2.bn2.bias', 'layers.2.bn2.running_mean', 'layers.2.bn2.running_var', 'layers.2.bn2.num_batches_tracked', 'layers.3.conv1.weight', 'layers.3.bn1.weight', 'layers.3.bn1.bias', 'layers.3.bn1.running_mean', 'layers.3.bn1.running_var', 'layers.3.bn1.num_batches_tracked', 'layers.3.conv2.weight', 'layers.3.bn2.weight', 'layers.3.bn2.bias', 'layers.3.bn2.running_mean', 'layers.3.bn2.running_var', 'layers.3.bn2.num_batches_tracked', 'layers.4.conv1.weight', 'layers.4.bn1.weight', 'layers.4.bn1.bias', 'layers.4.bn1.running_mean', 'layers.4.bn1.running_var', 'layers.4.bn1.num_batches_tracked', 'layers.4.conv2.weight', 'layers.4.bn2.weight', 'layers.4.bn2.bias', 'layers.4.bn2.running_mean', 'layers.4.bn2.running_var', 'layers.4.bn2.num_batches_tracked', 'layers.5.conv1.weight', 'layers.5.bn1.weight', 'layers.5.bn1.bias', 'layers.5.bn1.running_mean', 'layers.5.bn1.running_var', 'layers.5.bn1.num_batches_tracked', 'layers.5.conv2.weight', 'layers.5.bn2.weight', 'layers.5.bn2.bias', 'layers.5.bn2.running_mean', 'layers.5.bn2.running_var', 'layers.5.bn2.num_batches_tracked', 'layers.6.conv1.weight', 'layers.6.bn1.weight', 'layers.6.bn1.bias', 'layers.6.bn1.running_mean', 'layers.6.bn1.running_var', 'layers.6.bn1.num_batches_tracked', 'layers.6.conv2.weight', 'layers.6.bn2.weight', 'layers.6.bn2.bias', 'layers.6.bn2.running_mean', 'layers.6.bn2.running_var', 'layers.6.bn2.num_batches_tracked', 'layers.7.conv1.weight', 'layers.7.bn1.weight', 'layers.7.bn1.bias', 'layers.7.bn1.running_mean', 'layers.7.bn1.running_var', 'layers.7.bn1.num_batches_tracked', 'layers.7.conv2.weight', 'layers.7.bn2.weight', 'layers.7.bn2.bias', 'layers.7.bn2.running_mean', 'layers.7.bn2.running_var', 'layers.7.bn2.num_batches_tracked', 'layers.8.conv1.weight', 'layers.8.bn1.weight', 'layers.8.bn1.bias', 'layers.8.bn1.running_mean', 'layers.8.bn1.running_var', 'layers.8.bn1.num_batches_tracked', 'layers.8.conv2.weight', 'layers.8.bn2.weight', 'layers.8.bn2.bias', 'layers.8.bn2.running_mean', 'layers.8.bn2.running_var', 'layers.8.bn2.num_batches_tracked', 'layers.9.conv1.weight', 'layers.9.bn1.weight', 'layers.9.bn1.bias', 'layers.9.bn1.running_mean', 'layers.9.bn1.running_var', 'layers.9.bn1.num_batches_tracked', 'layers.9.conv2.weight', 'layers.9.bn2.weight', 'layers.9.bn2.bias', 'layers.9.bn2.running_mean', 'layers.9.bn2.running_var', 'layers.9.bn2.num_batches_tracked', 'layers.9.downsample.0.weight', 'layers.9.downsample.1.weight', 'layers.9.downsample.1.bias', 'layers.9.downsample.1.running_mean', 'layers.9.downsample.1.running_var', 'layers.9.downsample.1.num_batches_tracked', 'layers.10.conv1.weight', 'layers.10.bn1.weight', 'layers.10.bn1.bias', 'layers.10.bn1.running_mean', 'layers.10.bn1.running_var', 'layers.10.bn1.num_batches_tracked', 'layers.10.conv2.weight', 'layers.10.bn2.weight', 'layers.10.bn2.bias', 'layers.10.bn2.running_mean', 'layers.10.bn2.running_var', 'layers.10.bn2.num_batches_tracked', 'layers.11.conv1.weight', 'layers.11.bn1.weight', 'layers.11.bn1.bias', 'layers.11.bn1.running_mean', 'layers.11.bn1.running_var', 'layers.11.bn1.num_batches_tracked', 'layers.11.conv2.weight', 'layers.11.bn2.weight', 'layers.11.bn2.bias', 'layers.11.bn2.running_mean', 'layers.11.bn2.running_var', 'layers.11.bn2.num_batches_tracked', 'layers.12.conv1.weight', 'layers.12.bn1.weight', 'layers.12.bn1.bias', 'layers.12.bn1.running_mean', 'layers.12.bn1.running_var', 'layers.12.bn1.num_batches_tracked', 'layers.12.conv2.weight', 'layers.12.bn2.weight', 'layers.12.bn2.bias', 'layers.12.bn2.running_mean', 'layers.12.bn2.running_var', 'layers.12.bn2.num_batches_tracked', 'layers.13.conv1.weight', 'layers.13.bn1.weight', 'layers.13.bn1.bias', 'layers.13.bn1.running_mean', 'layers.13.bn1.running_var', 'layers.13.bn1.num_batches_tracked', 'layers.13.conv2.weight', 'layers.13.bn2.weight', 'layers.13.bn2.bias', 'layers.13.bn2.running_mean', 'layers.13.bn2.running_var', 'layers.13.bn2.num_batches_tracked', 'layers.14.conv1.weight', 'layers.14.bn1.weight', 'layers.14.bn1.bias', 'layers.14.bn1.running_mean', 'layers.14.bn1.running_var', 'layers.14.bn1.num_batches_tracked', 'layers.14.conv2.weight', 'layers.14.bn2.weight', 'layers.14.bn2.bias', 'layers.14.bn2.running_mean', 'layers.14.bn2.running_var', 'layers.14.bn2.num_batches_tracked', 'layers.15.conv1.weight', 'layers.15.bn1.weight', 'layers.15.bn1.bias', 'layers.15.bn1.running_mean', 'layers.15.bn1.running_var', 'layers.15.bn1.num_batches_tracked', 'layers.15.conv2.weight', 'layers.15.bn2.weight', 'layers.15.bn2.bias', 'layers.15.bn2.running_mean', 'layers.15.bn2.running_var', 'layers.15.bn2.num_batches_tracked', 'layers.16.conv1.weight', 'layers.16.bn1.weight', 'layers.16.bn1.bias', 'layers.16.bn1.running_mean', 'layers.16.bn1.running_var', 'layers.16.bn1.num_batches_tracked', 'layers.16.conv2.weight', 'layers.16.bn2.weight', 'layers.16.bn2.bias', 'layers.16.bn2.running_mean', 'layers.16.bn2.running_var', 'layers.16.bn2.num_batches_tracked', 'layers.17.conv1.weight', 'layers.17.bn1.weight', 'layers.17.bn1.bias', 'layers.17.bn1.running_mean', 'layers.17.bn1.running_var', 'layers.17.bn1.num_batches_tracked', 'layers.17.conv2.weight', 'layers.17.bn2.weight', 'layers.17.bn2.bias', 'layers.17.bn2.running_mean', 'layers.17.bn2.running_var', 'layers.17.bn2.num_batches_tracked', 'layers.18.conv1.weight', 'layers.18.bn1.weight', 'layers.18.bn1.bias', 'layers.18.bn1.running_mean', 'layers.18.bn1.running_var', 'layers.18.bn1.num_batches_tracked', 'layers.18.conv2.weight', 'layers.18.bn2.weight', 'layers.18.bn2.bias', 'layers.18.bn2.running_mean', 'layers.18.bn2.running_var', 'layers.18.bn2.num_batches_tracked', 'layers.18.downsample.0.weight', 'layers.18.downsample.1.weight', 'layers.18.downsample.1.bias', 'layers.18.downsample.1.running_mean', 'layers.18.downsample.1.running_var', 'layers.18.downsample.1.num_batches_tracked', 'layers.19.conv1.weight', 'layers.19.bn1.weight', 'layers.19.bn1.bias', 'layers.19.bn1.running_mean', 'layers.19.bn1.running_var', 'layers.19.bn1.num_batches_tracked', 'layers.19.conv2.weight', 'layers.19.bn2.weight', 'layers.19.bn2.bias', 'layers.19.bn2.running_mean', 'layers.19.bn2.running_var', 'layers.19.bn2.num_batches_tracked', 'layers.20.conv1.weight', 'layers.20.bn1.weight', 'layers.20.bn1.bias', 'layers.20.bn1.running_mean', 'layers.20.bn1.running_var', 'layers.20.bn1.num_batches_tracked', 'layers.20.conv2.weight', 'layers.20.bn2.weight', 'layers.20.bn2.bias', 'layers.20.bn2.running_mean', 'layers.20.bn2.running_var', 'layers.20.bn2.num_batches_tracked', 'layers.21.conv1.weight', 'layers.21.bn1.weight', 'layers.21.bn1.bias', 'layers.21.bn1.running_mean', 'layers.21.bn1.running_var', 'layers.21.bn1.num_batches_tracked', 'layers.21.conv2.weight', 'layers.21.bn2.weight', 'layers.21.bn2.bias', 'layers.21.bn2.running_mean', 'layers.21.bn2.running_var', 'layers.21.bn2.num_batches_tracked', 'layers.22.conv1.weight', 'layers.22.bn1.weight', 'layers.22.bn1.bias', 'layers.22.bn1.running_mean', 'layers.22.bn1.running_var', 'layers.22.bn1.num_batches_tracked', 'layers.22.conv2.weight', 'layers.22.bn2.weight', 'layers.22.bn2.bias', 'layers.22.bn2.running_mean', 'layers.22.bn2.running_var', 'layers.22.bn2.num_batches_tracked', 'layers.23.conv1.weight', 'layers.23.bn1.weight', 'layers.23.bn1.bias', 'layers.23.bn1.running_mean', 'layers.23.bn1.running_var', 'layers.23.bn1.num_batches_tracked', 'layers.23.conv2.weight', 'layers.23.bn2.weight', 'layers.23.bn2.bias', 'layers.23.bn2.running_mean', 'layers.23.bn2.running_var', 'layers.23.bn2.num_batches_tracked', 'layers.24.conv1.weight', 'layers.24.bn1.weight', 'layers.24.bn1.bias', 'layers.24.bn1.running_mean', 'layers.24.bn1.running_var', 'layers.24.bn1.num_batches_tracked', 'layers.24.conv2.weight', 'layers.24.bn2.weight', 'layers.24.bn2.bias', 'layers.24.bn2.running_mean', 'layers.24.bn2.running_var', 'layers.24.bn2.num_batches_tracked', 'layers.25.conv1.weight', 'layers.25.bn1.weight', 'layers.25.bn1.bias', 'layers.25.bn1.running_mean', 'layers.25.bn1.running_var', 'layers.25.bn1.num_batches_tracked', 'layers.25.conv2.weight', 'layers.25.bn2.weight', 'layers.25.bn2.bias', 'layers.25.bn2.running_mean', 'layers.25.bn2.running_var', 'layers.25.bn2.num_batches_tracked', 'layers.26.conv1.weight', 'layers.26.bn1.weight', 'layers.26.bn1.bias', 'layers.26.bn1.running_mean', 'layers.26.bn1.running_var', 'layers.26.bn1.num_batches_tracked', 'layers.26.conv2.weight', 'layers.26.bn2.weight', 'layers.26.bn2.bias', 'layers.26.bn2.running_mean', 'layers.26.bn2.running_var', 'layers.26.bn2.num_batches_tracked', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
