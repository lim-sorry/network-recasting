{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "from model import CustomResNet, ConvBlock\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import ToTensor, Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'cifar100'\n",
    "teacher_name = 'resnet56_baseline'\n",
    "student_name = 'resnet56_recast'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_class = 100\n",
    "batch_size = 64\n",
    "epoch = 60\n",
    "lr = 0.001\n",
    "step_size = 20\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(size=[32, 32], padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR100(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 861620\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (24): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (25): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "teacher = CustomResNet(block=BasicBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=num_class).to(device).eval()\n",
    "checkpoint = torch.load(f'./result/{dataset_name}_{teacher_name}.pt')\n",
    "teacher.load_state_dict(checkpoint['model'])\n",
    "\n",
    "total_params = sum(p.numel() for p in teacher.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 861620\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (24): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (25): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "student = CustomResNet(block=BasicBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=num_class).to(device)\n",
    "checkpoint = torch.load(f'./result/{dataset_name}_{teacher_name}.pt')\n",
    "student.load_state_dict(checkpoint['model'])\n",
    "\n",
    "total_params = sum(p.numel() for p in student.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 0 recasting...\n",
      "block 0 training started...\n",
      "epoch=0, train_loss=0.5370, test_acc=0.5458\n",
      "epoch=1, train_loss=0.1971, test_acc=0.6577\n",
      "epoch=2, train_loss=0.0829, test_acc=0.6718\n",
      "epoch=3, train_loss=0.0492, test_acc=0.6759\n",
      "epoch=4, train_loss=0.0411, test_acc=0.6702\n",
      "epoch=5, train_loss=0.0320, test_acc=0.6748\n",
      "epoch=6, train_loss=0.0253, test_acc=0.6864\n",
      "epoch=7, train_loss=0.0209, test_acc=0.6917\n",
      "epoch=8, train_loss=0.0191, test_acc=0.6925\n",
      "epoch=9, train_loss=0.0190, test_acc=0.6910\n",
      "epoch=10, train_loss=0.0186, test_acc=0.6929\n",
      "epoch=11, train_loss=0.0185, test_acc=0.6940\n",
      "epoch=12, train_loss=0.0185, test_acc=0.6937\n",
      "epoch=13, train_loss=0.0185, test_acc=0.6940\n",
      "epoch=14, train_loss=0.0184, test_acc=0.6941\n",
      "epoch=15, train_loss=0.0184, test_acc=0.6940\n",
      "epoch=16, train_loss=0.0183, test_acc=0.6938\n",
      "epoch=17, train_loss=0.0183, test_acc=0.6959\n",
      "epoch=18, train_loss=0.0183, test_acc=0.6945\n",
      "epoch=19, train_loss=0.0182, test_acc=0.6951\n",
      "epoch=20, train_loss=0.0182, test_acc=0.6940\n",
      "epoch=21, train_loss=0.0182, test_acc=0.6948\n",
      "epoch=22, train_loss=0.0183, test_acc=0.6939\n",
      "epoch=23, train_loss=0.0182, test_acc=0.6956\n",
      "epoch=24, train_loss=0.0178, test_acc=0.6959\n",
      "epoch=25, train_loss=0.0182, test_acc=0.6949\n",
      "epoch=26, train_loss=0.0182, test_acc=0.6954\n",
      "epoch=27, train_loss=0.0181, test_acc=0.6953\n",
      "epoch=28, train_loss=0.0182, test_acc=0.6935\n",
      "epoch=29, train_loss=0.0181, test_acc=0.6955\n",
      "epoch=30, train_loss=0.0181, test_acc=0.6938\n",
      "epoch=31, train_loss=0.0183, test_acc=0.6933\n",
      "epoch=32, train_loss=0.0182, test_acc=0.6949\n",
      "epoch=33, train_loss=0.0182, test_acc=0.6939\n",
      "epoch=34, train_loss=0.0181, test_acc=0.6950\n",
      "epoch=35, train_loss=0.0182, test_acc=0.6940\n",
      "epoch=36, train_loss=0.0181, test_acc=0.6947\n",
      "epoch=37, train_loss=0.0181, test_acc=0.6954\n",
      "epoch=38, train_loss=0.0183, test_acc=0.6940\n",
      "epoch=39, train_loss=0.0180, test_acc=0.6948\n",
      "epoch=40, train_loss=0.0181, test_acc=0.6945\n",
      "epoch=41, train_loss=0.0181, test_acc=0.6940\n",
      "epoch=42, train_loss=0.0181, test_acc=0.6944\n",
      "epoch=43, train_loss=0.0181, test_acc=0.6936\n",
      "epoch=44, train_loss=0.0179, test_acc=0.6949\n",
      "epoch=45, train_loss=0.0181, test_acc=0.6956\n",
      "epoch=46, train_loss=0.0180, test_acc=0.6955\n",
      "epoch=47, train_loss=0.0181, test_acc=0.6942\n",
      "epoch=48, train_loss=0.0180, test_acc=0.6958\n",
      "epoch=49, train_loss=0.0180, test_acc=0.6957\n",
      "epoch=50, train_loss=0.0181, test_acc=0.6936\n",
      "epoch=51, train_loss=0.0182, test_acc=0.6936\n",
      "epoch=52, train_loss=0.0180, test_acc=0.6957\n",
      "epoch=53, train_loss=0.0180, test_acc=0.6946\n",
      "epoch=54, train_loss=0.0180, test_acc=0.6952\n",
      "epoch=55, train_loss=0.0180, test_acc=0.6939\n",
      "epoch=56, train_loss=0.0181, test_acc=0.6956\n",
      "epoch=57, train_loss=0.0180, test_acc=0.6954\n",
      "epoch=58, train_loss=0.0182, test_acc=0.6961\n",
      "epoch=59, train_loss=0.0183, test_acc=0.6938\n",
      "block 1 recasting...\n",
      "block 1 training started...\n",
      "epoch=0, train_loss=0.6959, test_acc=0.5212\n",
      "epoch=1, train_loss=0.2492, test_acc=0.6483\n",
      "epoch=2, train_loss=0.0998, test_acc=0.6770\n",
      "epoch=3, train_loss=0.0485, test_acc=0.6872\n",
      "epoch=4, train_loss=0.0293, test_acc=0.6900\n",
      "epoch=5, train_loss=0.0213, test_acc=0.6900\n",
      "epoch=6, train_loss=0.0194, test_acc=0.6913\n",
      "epoch=7, train_loss=0.0181, test_acc=0.6924\n",
      "epoch=8, train_loss=0.0171, test_acc=0.6920\n",
      "epoch=9, train_loss=0.0164, test_acc=0.6941\n",
      "epoch=10, train_loss=0.0156, test_acc=0.6933\n",
      "epoch=11, train_loss=0.0153, test_acc=0.6932\n",
      "epoch=12, train_loss=0.0149, test_acc=0.6930\n",
      "epoch=13, train_loss=0.0147, test_acc=0.6944\n",
      "epoch=14, train_loss=0.0147, test_acc=0.6913\n",
      "epoch=15, train_loss=0.0144, test_acc=0.6929\n",
      "epoch=16, train_loss=0.0141, test_acc=0.6944\n",
      "epoch=17, train_loss=0.0141, test_acc=0.6949\n",
      "epoch=18, train_loss=0.0138, test_acc=0.6927\n",
      "epoch=19, train_loss=0.0135, test_acc=0.6951\n",
      "epoch=20, train_loss=0.0128, test_acc=0.6937\n",
      "epoch=21, train_loss=0.0129, test_acc=0.6929\n",
      "epoch=22, train_loss=0.0128, test_acc=0.6933\n",
      "epoch=23, train_loss=0.0127, test_acc=0.6921\n",
      "epoch=24, train_loss=0.0126, test_acc=0.6922\n",
      "epoch=25, train_loss=0.0126, test_acc=0.6934\n",
      "epoch=26, train_loss=0.0126, test_acc=0.6918\n",
      "epoch=27, train_loss=0.0124, test_acc=0.6936\n",
      "epoch=28, train_loss=0.0125, test_acc=0.6935\n",
      "epoch=29, train_loss=0.0125, test_acc=0.6944\n",
      "epoch=30, train_loss=0.0124, test_acc=0.6938\n",
      "epoch=31, train_loss=0.0125, test_acc=0.6936\n",
      "epoch=32, train_loss=0.0122, test_acc=0.6934\n",
      "epoch=33, train_loss=0.0124, test_acc=0.6933\n",
      "epoch=34, train_loss=0.0124, test_acc=0.6925\n",
      "epoch=35, train_loss=0.0124, test_acc=0.6928\n",
      "epoch=36, train_loss=0.0124, test_acc=0.6939\n",
      "epoch=37, train_loss=0.0123, test_acc=0.6924\n",
      "epoch=38, train_loss=0.0122, test_acc=0.6937\n",
      "epoch=39, train_loss=0.0121, test_acc=0.6924\n",
      "epoch=40, train_loss=0.0121, test_acc=0.6937\n",
      "epoch=41, train_loss=0.0121, test_acc=0.6922\n",
      "epoch=42, train_loss=0.0122, test_acc=0.6921\n",
      "epoch=43, train_loss=0.0122, test_acc=0.6940\n",
      "epoch=44, train_loss=0.0121, test_acc=0.6940\n",
      "epoch=45, train_loss=0.0122, test_acc=0.6915\n",
      "epoch=46, train_loss=0.0123, test_acc=0.6928\n",
      "epoch=47, train_loss=0.0121, test_acc=0.6942\n",
      "epoch=48, train_loss=0.0121, test_acc=0.6935\n",
      "epoch=49, train_loss=0.0121, test_acc=0.6923\n",
      "epoch=50, train_loss=0.0121, test_acc=0.6941\n",
      "epoch=51, train_loss=0.0121, test_acc=0.6912\n",
      "epoch=52, train_loss=0.0120, test_acc=0.6914\n",
      "epoch=53, train_loss=0.0120, test_acc=0.6928\n",
      "epoch=54, train_loss=0.0121, test_acc=0.6925\n",
      "epoch=55, train_loss=0.0121, test_acc=0.6918\n",
      "epoch=56, train_loss=0.0121, test_acc=0.6927\n",
      "epoch=57, train_loss=0.0121, test_acc=0.6924\n",
      "epoch=58, train_loss=0.0122, test_acc=0.6940\n",
      "epoch=59, train_loss=0.0121, test_acc=0.6931\n",
      "block 2 recasting...\n",
      "block 2 training started...\n",
      "epoch=0, train_loss=0.8129, test_acc=0.4998\n",
      "epoch=1, train_loss=0.2980, test_acc=0.6598\n",
      "epoch=2, train_loss=0.1207, test_acc=0.6830\n",
      "epoch=3, train_loss=0.0641, test_acc=0.6853\n",
      "epoch=4, train_loss=0.0488, test_acc=0.6927\n",
      "epoch=5, train_loss=0.0400, test_acc=0.6928\n",
      "epoch=6, train_loss=0.0366, test_acc=0.6879\n",
      "epoch=7, train_loss=0.0345, test_acc=0.6921\n",
      "epoch=8, train_loss=0.0329, test_acc=0.6911\n",
      "epoch=9, train_loss=0.0318, test_acc=0.6934\n",
      "epoch=10, train_loss=0.0308, test_acc=0.6906\n",
      "epoch=11, train_loss=0.0301, test_acc=0.6891\n",
      "epoch=12, train_loss=0.0294, test_acc=0.6908\n",
      "epoch=13, train_loss=0.0289, test_acc=0.6913\n",
      "epoch=14, train_loss=0.0286, test_acc=0.6905\n",
      "epoch=15, train_loss=0.0284, test_acc=0.6900\n",
      "epoch=16, train_loss=0.0282, test_acc=0.6906\n",
      "epoch=17, train_loss=0.0280, test_acc=0.6919\n",
      "epoch=18, train_loss=0.0275, test_acc=0.6928\n",
      "epoch=19, train_loss=0.0272, test_acc=0.6915\n",
      "epoch=20, train_loss=0.0263, test_acc=0.6927\n",
      "epoch=21, train_loss=0.0264, test_acc=0.6913\n",
      "epoch=22, train_loss=0.0263, test_acc=0.6919\n",
      "epoch=23, train_loss=0.0264, test_acc=0.6925\n",
      "epoch=24, train_loss=0.0263, test_acc=0.6908\n",
      "epoch=25, train_loss=0.0262, test_acc=0.6909\n",
      "epoch=26, train_loss=0.0262, test_acc=0.6908\n",
      "epoch=27, train_loss=0.0262, test_acc=0.6907\n",
      "epoch=28, train_loss=0.0261, test_acc=0.6910\n",
      "epoch=29, train_loss=0.0264, test_acc=0.6920\n",
      "epoch=30, train_loss=0.0261, test_acc=0.6893\n",
      "epoch=31, train_loss=0.0261, test_acc=0.6922\n",
      "epoch=32, train_loss=0.0261, test_acc=0.6921\n",
      "epoch=33, train_loss=0.0260, test_acc=0.6911\n",
      "epoch=34, train_loss=0.0262, test_acc=0.6919\n",
      "epoch=35, train_loss=0.0260, test_acc=0.6905\n",
      "epoch=36, train_loss=0.0259, test_acc=0.6915\n",
      "epoch=37, train_loss=0.0260, test_acc=0.6902\n",
      "epoch=38, train_loss=0.0260, test_acc=0.6920\n",
      "epoch=39, train_loss=0.0260, test_acc=0.6912\n",
      "epoch=40, train_loss=0.0258, test_acc=0.6918\n",
      "epoch=41, train_loss=0.0259, test_acc=0.6913\n",
      "epoch=42, train_loss=0.0257, test_acc=0.6913\n",
      "epoch=43, train_loss=0.0258, test_acc=0.6906\n",
      "epoch=44, train_loss=0.0257, test_acc=0.6913\n",
      "epoch=45, train_loss=0.0260, test_acc=0.6915\n",
      "epoch=46, train_loss=0.0259, test_acc=0.6925\n",
      "epoch=47, train_loss=0.0259, test_acc=0.6915\n",
      "epoch=48, train_loss=0.0259, test_acc=0.6920\n",
      "epoch=49, train_loss=0.0259, test_acc=0.6922\n",
      "epoch=50, train_loss=0.0258, test_acc=0.6912\n",
      "epoch=51, train_loss=0.0258, test_acc=0.6934\n",
      "epoch=52, train_loss=0.0260, test_acc=0.6914\n",
      "epoch=53, train_loss=0.0259, test_acc=0.6914\n",
      "epoch=54, train_loss=0.0258, test_acc=0.6917\n",
      "epoch=55, train_loss=0.0259, test_acc=0.6911\n",
      "epoch=56, train_loss=0.0258, test_acc=0.6910\n",
      "epoch=57, train_loss=0.0258, test_acc=0.6913\n",
      "epoch=58, train_loss=0.0259, test_acc=0.6903\n",
      "epoch=59, train_loss=0.0258, test_acc=0.6915\n",
      "block 3 recasting...\n",
      "block 3 training started...\n",
      "epoch=0, train_loss=0.9684, test_acc=0.5054\n",
      "epoch=1, train_loss=0.3454, test_acc=0.6529\n",
      "epoch=2, train_loss=0.1321, test_acc=0.6793\n",
      "epoch=3, train_loss=0.0550, test_acc=0.6887\n",
      "epoch=4, train_loss=0.0360, test_acc=0.6895\n",
      "epoch=5, train_loss=0.0291, test_acc=0.6900\n",
      "epoch=6, train_loss=0.0268, test_acc=0.6916\n",
      "epoch=7, train_loss=0.0263, test_acc=0.6906\n",
      "epoch=8, train_loss=0.0223, test_acc=0.6922\n",
      "epoch=9, train_loss=0.0214, test_acc=0.6907\n",
      "epoch=10, train_loss=0.0209, test_acc=0.6924\n",
      "epoch=11, train_loss=0.0204, test_acc=0.6920\n",
      "epoch=12, train_loss=0.0202, test_acc=0.6913\n",
      "epoch=13, train_loss=0.0197, test_acc=0.6903\n",
      "epoch=14, train_loss=0.0194, test_acc=0.6905\n",
      "epoch=15, train_loss=0.0193, test_acc=0.6907\n",
      "epoch=16, train_loss=0.0188, test_acc=0.6914\n",
      "epoch=17, train_loss=0.0188, test_acc=0.6895\n",
      "epoch=18, train_loss=0.0184, test_acc=0.6883\n",
      "epoch=19, train_loss=0.0183, test_acc=0.6906\n",
      "epoch=20, train_loss=0.0174, test_acc=0.6923\n",
      "epoch=21, train_loss=0.0171, test_acc=0.6924\n",
      "epoch=22, train_loss=0.0171, test_acc=0.6921\n",
      "epoch=23, train_loss=0.0172, test_acc=0.6911\n",
      "epoch=24, train_loss=0.0171, test_acc=0.6913\n",
      "epoch=25, train_loss=0.0171, test_acc=0.6903\n",
      "epoch=26, train_loss=0.0170, test_acc=0.6921\n",
      "epoch=27, train_loss=0.0170, test_acc=0.6907\n",
      "epoch=28, train_loss=0.0171, test_acc=0.6924\n",
      "epoch=29, train_loss=0.0172, test_acc=0.6921\n",
      "epoch=30, train_loss=0.0171, test_acc=0.6915\n",
      "epoch=31, train_loss=0.0171, test_acc=0.6912\n",
      "epoch=32, train_loss=0.0169, test_acc=0.6911\n",
      "epoch=33, train_loss=0.0170, test_acc=0.6903\n",
      "epoch=34, train_loss=0.0171, test_acc=0.6917\n",
      "epoch=35, train_loss=0.0169, test_acc=0.6924\n",
      "epoch=36, train_loss=0.0170, test_acc=0.6906\n",
      "epoch=37, train_loss=0.0170, test_acc=0.6908\n",
      "epoch=38, train_loss=0.0170, test_acc=0.6915\n",
      "epoch=39, train_loss=0.0167, test_acc=0.6912\n",
      "epoch=40, train_loss=0.0170, test_acc=0.6907\n",
      "epoch=41, train_loss=0.0168, test_acc=0.6921\n",
      "epoch=42, train_loss=0.0167, test_acc=0.6913\n",
      "epoch=43, train_loss=0.0167, test_acc=0.6924\n",
      "epoch=44, train_loss=0.0168, test_acc=0.6924\n",
      "epoch=45, train_loss=0.0168, test_acc=0.6910\n",
      "epoch=46, train_loss=0.0167, test_acc=0.6901\n",
      "epoch=47, train_loss=0.0167, test_acc=0.6910\n",
      "epoch=48, train_loss=0.0168, test_acc=0.6906\n",
      "epoch=49, train_loss=0.0168, test_acc=0.6912\n",
      "epoch=50, train_loss=0.0167, test_acc=0.6912\n",
      "epoch=51, train_loss=0.0168, test_acc=0.6923\n",
      "epoch=52, train_loss=0.0167, test_acc=0.6907\n",
      "epoch=53, train_loss=0.0166, test_acc=0.6917\n",
      "epoch=54, train_loss=0.0167, test_acc=0.6914\n",
      "epoch=55, train_loss=0.0167, test_acc=0.6914\n",
      "epoch=56, train_loss=0.0166, test_acc=0.6910\n",
      "epoch=57, train_loss=0.0167, test_acc=0.6903\n",
      "epoch=58, train_loss=0.0167, test_acc=0.6914\n",
      "epoch=59, train_loss=0.0166, test_acc=0.6911\n",
      "block 4 recasting...\n",
      "block 4 training started...\n",
      "epoch=0, train_loss=1.2432, test_acc=0.4996\n",
      "epoch=1, train_loss=0.4736, test_acc=0.6354\n",
      "epoch=2, train_loss=0.2137, test_acc=0.6811\n",
      "epoch=3, train_loss=0.1174, test_acc=0.6840\n",
      "epoch=4, train_loss=0.0861, test_acc=0.6859\n",
      "epoch=5, train_loss=0.0777, test_acc=0.6874\n",
      "epoch=6, train_loss=0.0707, test_acc=0.6881\n",
      "epoch=7, train_loss=0.0668, test_acc=0.6877\n",
      "epoch=8, train_loss=0.0647, test_acc=0.6886\n",
      "epoch=9, train_loss=0.0636, test_acc=0.6886\n",
      "epoch=10, train_loss=0.0623, test_acc=0.6888\n",
      "epoch=11, train_loss=0.0616, test_acc=0.6891\n",
      "epoch=12, train_loss=0.0613, test_acc=0.6853\n",
      "epoch=13, train_loss=0.0608, test_acc=0.6891\n",
      "epoch=14, train_loss=0.0604, test_acc=0.6873\n",
      "epoch=15, train_loss=0.0603, test_acc=0.6897\n",
      "epoch=16, train_loss=0.0594, test_acc=0.6918\n",
      "epoch=17, train_loss=0.0590, test_acc=0.6904\n",
      "epoch=18, train_loss=0.0588, test_acc=0.6920\n",
      "epoch=19, train_loss=0.0583, test_acc=0.6921\n",
      "epoch=20, train_loss=0.0572, test_acc=0.6905\n",
      "epoch=21, train_loss=0.0569, test_acc=0.6915\n",
      "epoch=22, train_loss=0.0566, test_acc=0.6896\n",
      "epoch=23, train_loss=0.0567, test_acc=0.6908\n",
      "epoch=24, train_loss=0.0565, test_acc=0.6909\n",
      "epoch=25, train_loss=0.0517, test_acc=0.6926\n",
      "epoch=26, train_loss=0.0491, test_acc=0.6905\n",
      "epoch=27, train_loss=0.0489, test_acc=0.6922\n",
      "epoch=28, train_loss=0.0488, test_acc=0.6912\n",
      "epoch=29, train_loss=0.0486, test_acc=0.6904\n",
      "epoch=30, train_loss=0.0488, test_acc=0.6916\n",
      "epoch=31, train_loss=0.0485, test_acc=0.6909\n",
      "epoch=32, train_loss=0.0482, test_acc=0.6905\n",
      "epoch=33, train_loss=0.0484, test_acc=0.6913\n",
      "epoch=34, train_loss=0.0483, test_acc=0.6902\n",
      "epoch=35, train_loss=0.0482, test_acc=0.6918\n",
      "epoch=36, train_loss=0.0482, test_acc=0.6913\n",
      "epoch=37, train_loss=0.0481, test_acc=0.6910\n",
      "epoch=38, train_loss=0.0481, test_acc=0.6908\n",
      "epoch=39, train_loss=0.0481, test_acc=0.6912\n",
      "epoch=40, train_loss=0.0479, test_acc=0.6912\n",
      "epoch=41, train_loss=0.0479, test_acc=0.6898\n",
      "epoch=42, train_loss=0.0477, test_acc=0.6917\n",
      "epoch=43, train_loss=0.0479, test_acc=0.6912\n",
      "epoch=44, train_loss=0.0479, test_acc=0.6908\n",
      "epoch=45, train_loss=0.0479, test_acc=0.6899\n",
      "epoch=46, train_loss=0.0484, test_acc=0.6891\n",
      "epoch=47, train_loss=0.0477, test_acc=0.6916\n",
      "epoch=48, train_loss=0.0479, test_acc=0.6908\n",
      "epoch=49, train_loss=0.0478, test_acc=0.6909\n",
      "epoch=50, train_loss=0.0477, test_acc=0.6909\n",
      "epoch=51, train_loss=0.0479, test_acc=0.6916\n",
      "epoch=52, train_loss=0.0478, test_acc=0.6913\n",
      "epoch=53, train_loss=0.0478, test_acc=0.6913\n",
      "epoch=54, train_loss=0.0478, test_acc=0.6909\n",
      "epoch=55, train_loss=0.0480, test_acc=0.6895\n",
      "epoch=56, train_loss=0.0479, test_acc=0.6901\n",
      "epoch=57, train_loss=0.0482, test_acc=0.6889\n",
      "epoch=58, train_loss=0.0479, test_acc=0.6901\n",
      "epoch=59, train_loss=0.0479, test_acc=0.6919\n",
      "block 5 recasting...\n",
      "block 5 training started...\n",
      "epoch=0, train_loss=1.4587, test_acc=0.4865\n",
      "epoch=1, train_loss=0.5432, test_acc=0.5626\n",
      "epoch=2, train_loss=0.2478, test_acc=0.6697\n",
      "epoch=3, train_loss=0.1323, test_acc=0.6822\n",
      "epoch=4, train_loss=0.0967, test_acc=0.6865\n",
      "epoch=5, train_loss=0.0858, test_acc=0.6862\n",
      "epoch=6, train_loss=0.0782, test_acc=0.6858\n",
      "epoch=7, train_loss=0.0753, test_acc=0.6878\n",
      "epoch=8, train_loss=0.0731, test_acc=0.6863\n",
      "epoch=9, train_loss=0.0718, test_acc=0.6849\n",
      "epoch=10, train_loss=0.0706, test_acc=0.6863\n",
      "epoch=11, train_loss=0.0700, test_acc=0.6882\n",
      "epoch=12, train_loss=0.0694, test_acc=0.6869\n",
      "epoch=13, train_loss=0.0643, test_acc=0.6824\n",
      "epoch=14, train_loss=0.0632, test_acc=0.6873\n",
      "epoch=15, train_loss=0.0619, test_acc=0.6827\n",
      "epoch=16, train_loss=0.0610, test_acc=0.6883\n",
      "epoch=17, train_loss=0.0606, test_acc=0.6872\n",
      "epoch=18, train_loss=0.0605, test_acc=0.6874\n",
      "epoch=19, train_loss=0.0600, test_acc=0.6873\n",
      "epoch=20, train_loss=0.0589, test_acc=0.6894\n",
      "epoch=21, train_loss=0.0586, test_acc=0.6909\n",
      "epoch=22, train_loss=0.0585, test_acc=0.6897\n",
      "epoch=23, train_loss=0.0586, test_acc=0.6892\n",
      "epoch=24, train_loss=0.0585, test_acc=0.6895\n",
      "epoch=25, train_loss=0.0584, test_acc=0.6894\n",
      "epoch=26, train_loss=0.0584, test_acc=0.6884\n",
      "epoch=27, train_loss=0.0585, test_acc=0.6891\n",
      "epoch=28, train_loss=0.0584, test_acc=0.6894\n",
      "epoch=29, train_loss=0.0584, test_acc=0.6891\n",
      "epoch=30, train_loss=0.0585, test_acc=0.6901\n",
      "epoch=31, train_loss=0.0582, test_acc=0.6898\n",
      "epoch=32, train_loss=0.0582, test_acc=0.6893\n",
      "epoch=33, train_loss=0.0582, test_acc=0.6887\n",
      "epoch=34, train_loss=0.0581, test_acc=0.6896\n",
      "epoch=35, train_loss=0.0580, test_acc=0.6889\n",
      "epoch=36, train_loss=0.0581, test_acc=0.6893\n",
      "epoch=37, train_loss=0.0579, test_acc=0.6895\n",
      "epoch=38, train_loss=0.0579, test_acc=0.6896\n",
      "epoch=39, train_loss=0.0578, test_acc=0.6889\n",
      "epoch=40, train_loss=0.0578, test_acc=0.6883\n",
      "epoch=41, train_loss=0.0578, test_acc=0.6896\n",
      "epoch=42, train_loss=0.0577, test_acc=0.6886\n",
      "epoch=43, train_loss=0.0579, test_acc=0.6899\n",
      "epoch=44, train_loss=0.0577, test_acc=0.6892\n",
      "epoch=45, train_loss=0.0578, test_acc=0.6890\n",
      "epoch=46, train_loss=0.0579, test_acc=0.6889\n",
      "epoch=47, train_loss=0.0578, test_acc=0.6887\n",
      "epoch=48, train_loss=0.0577, test_acc=0.6897\n",
      "epoch=49, train_loss=0.0577, test_acc=0.6893\n",
      "epoch=50, train_loss=0.0577, test_acc=0.6894\n",
      "epoch=51, train_loss=0.0578, test_acc=0.6882\n",
      "epoch=52, train_loss=0.0578, test_acc=0.6889\n",
      "epoch=53, train_loss=0.0578, test_acc=0.6900\n",
      "epoch=54, train_loss=0.0577, test_acc=0.6899\n",
      "epoch=55, train_loss=0.0577, test_acc=0.6901\n",
      "epoch=56, train_loss=0.0578, test_acc=0.6895\n",
      "epoch=57, train_loss=0.0577, test_acc=0.6890\n",
      "epoch=58, train_loss=0.0577, test_acc=0.6899\n",
      "epoch=59, train_loss=0.0576, test_acc=0.6890\n",
      "block 6 recasting...\n",
      "block 6 training started...\n",
      "epoch=0, train_loss=1.8442, test_acc=0.3569\n",
      "epoch=1, train_loss=0.7186, test_acc=0.6108\n",
      "epoch=2, train_loss=0.3285, test_acc=0.6788\n",
      "epoch=3, train_loss=0.1869, test_acc=0.6727\n",
      "epoch=4, train_loss=0.1478, test_acc=0.6759\n",
      "epoch=5, train_loss=0.1293, test_acc=0.6854\n",
      "epoch=6, train_loss=0.1119, test_acc=0.6856\n",
      "epoch=7, train_loss=0.1077, test_acc=0.6878\n",
      "epoch=8, train_loss=0.0958, test_acc=0.6850\n",
      "epoch=9, train_loss=0.0906, test_acc=0.6887\n",
      "epoch=10, train_loss=0.0887, test_acc=0.6843\n",
      "epoch=11, train_loss=0.0877, test_acc=0.6852\n",
      "epoch=12, train_loss=0.0872, test_acc=0.6701\n",
      "epoch=13, train_loss=0.0868, test_acc=0.6877\n",
      "epoch=14, train_loss=0.0867, test_acc=0.6907\n",
      "epoch=15, train_loss=0.0838, test_acc=0.6900\n",
      "epoch=16, train_loss=0.0833, test_acc=0.6869\n",
      "epoch=17, train_loss=0.0828, test_acc=0.6910\n",
      "epoch=18, train_loss=0.0825, test_acc=0.6901\n",
      "epoch=19, train_loss=0.0820, test_acc=0.6879\n",
      "epoch=20, train_loss=0.0804, test_acc=0.6902\n",
      "epoch=21, train_loss=0.0806, test_acc=0.6900\n",
      "epoch=22, train_loss=0.0804, test_acc=0.6902\n",
      "epoch=23, train_loss=0.0802, test_acc=0.6891\n",
      "epoch=24, train_loss=0.0802, test_acc=0.6902\n",
      "epoch=25, train_loss=0.0803, test_acc=0.6902\n",
      "epoch=26, train_loss=0.0807, test_acc=0.6897\n",
      "epoch=27, train_loss=0.0802, test_acc=0.6898\n",
      "epoch=28, train_loss=0.0806, test_acc=0.6901\n",
      "epoch=29, train_loss=0.0802, test_acc=0.6900\n",
      "epoch=30, train_loss=0.0801, test_acc=0.6896\n",
      "epoch=31, train_loss=0.0800, test_acc=0.6904\n",
      "epoch=32, train_loss=0.0800, test_acc=0.6912\n",
      "epoch=33, train_loss=0.0800, test_acc=0.6888\n",
      "epoch=34, train_loss=0.0799, test_acc=0.6906\n",
      "epoch=35, train_loss=0.0798, test_acc=0.6882\n",
      "epoch=36, train_loss=0.0799, test_acc=0.6904\n",
      "epoch=37, train_loss=0.0801, test_acc=0.6883\n",
      "epoch=38, train_loss=0.0799, test_acc=0.6887\n",
      "epoch=39, train_loss=0.0800, test_acc=0.6907\n",
      "epoch=40, train_loss=0.0795, test_acc=0.6903\n",
      "epoch=41, train_loss=0.0796, test_acc=0.6903\n",
      "epoch=42, train_loss=0.0798, test_acc=0.6893\n",
      "epoch=43, train_loss=0.0796, test_acc=0.6914\n",
      "epoch=44, train_loss=0.0796, test_acc=0.6890\n",
      "epoch=45, train_loss=0.0793, test_acc=0.6906\n",
      "epoch=46, train_loss=0.0795, test_acc=0.6899\n",
      "epoch=47, train_loss=0.0795, test_acc=0.6905\n",
      "epoch=48, train_loss=0.0794, test_acc=0.6898\n",
      "epoch=49, train_loss=0.0796, test_acc=0.6914\n",
      "epoch=50, train_loss=0.0794, test_acc=0.6899\n",
      "epoch=51, train_loss=0.0795, test_acc=0.6888\n",
      "epoch=52, train_loss=0.0793, test_acc=0.6907\n",
      "epoch=53, train_loss=0.0796, test_acc=0.6897\n",
      "epoch=54, train_loss=0.0796, test_acc=0.6911\n",
      "epoch=55, train_loss=0.0796, test_acc=0.6904\n",
      "epoch=56, train_loss=0.0795, test_acc=0.6902\n",
      "epoch=57, train_loss=0.0792, test_acc=0.6896\n",
      "epoch=58, train_loss=0.0794, test_acc=0.6906\n",
      "epoch=59, train_loss=0.0797, test_acc=0.6898\n",
      "block 7 recasting...\n",
      "block 7 training started...\n",
      "epoch=0, train_loss=2.2907, test_acc=0.2169\n",
      "epoch=1, train_loss=0.9306, test_acc=0.5869\n",
      "epoch=2, train_loss=0.4278, test_acc=0.6318\n",
      "epoch=3, train_loss=0.2231, test_acc=0.6767\n",
      "epoch=4, train_loss=0.1607, test_acc=0.6737\n",
      "epoch=5, train_loss=0.1402, test_acc=0.6874\n",
      "epoch=6, train_loss=0.1285, test_acc=0.6664\n",
      "epoch=7, train_loss=0.1247, test_acc=0.6840\n",
      "epoch=8, train_loss=0.1174, test_acc=0.6854\n",
      "epoch=9, train_loss=0.1098, test_acc=0.6848\n",
      "epoch=10, train_loss=0.1109, test_acc=0.6849\n",
      "epoch=11, train_loss=0.1075, test_acc=0.6845\n",
      "epoch=12, train_loss=0.1064, test_acc=0.6836\n",
      "epoch=13, train_loss=0.1057, test_acc=0.6809\n",
      "epoch=14, train_loss=0.1052, test_acc=0.6828\n",
      "epoch=15, train_loss=0.1045, test_acc=0.6806\n",
      "epoch=16, train_loss=0.1048, test_acc=0.6840\n",
      "epoch=17, train_loss=0.1041, test_acc=0.6867\n",
      "epoch=18, train_loss=0.1029, test_acc=0.6808\n",
      "epoch=19, train_loss=0.1024, test_acc=0.6821\n",
      "epoch=20, train_loss=0.1001, test_acc=0.6854\n",
      "epoch=21, train_loss=0.1000, test_acc=0.6885\n",
      "epoch=22, train_loss=0.0999, test_acc=0.6863\n",
      "epoch=23, train_loss=0.1003, test_acc=0.6853\n",
      "epoch=24, train_loss=0.1004, test_acc=0.6875\n",
      "epoch=25, train_loss=0.0998, test_acc=0.6851\n",
      "epoch=26, train_loss=0.0994, test_acc=0.6856\n",
      "epoch=27, train_loss=0.0996, test_acc=0.6870\n",
      "epoch=28, train_loss=0.0994, test_acc=0.6874\n",
      "epoch=29, train_loss=0.0992, test_acc=0.6871\n",
      "epoch=30, train_loss=0.0992, test_acc=0.6843\n",
      "epoch=31, train_loss=0.0992, test_acc=0.6876\n",
      "epoch=32, train_loss=0.0990, test_acc=0.6885\n",
      "epoch=33, train_loss=0.0991, test_acc=0.6843\n",
      "epoch=34, train_loss=0.0999, test_acc=0.6901\n",
      "epoch=35, train_loss=0.0993, test_acc=0.6855\n",
      "epoch=36, train_loss=0.0991, test_acc=0.6869\n",
      "epoch=37, train_loss=0.0988, test_acc=0.6845\n",
      "epoch=38, train_loss=0.0991, test_acc=0.6847\n",
      "epoch=39, train_loss=0.0988, test_acc=0.6861\n",
      "epoch=40, train_loss=0.0989, test_acc=0.6860\n",
      "epoch=41, train_loss=0.0985, test_acc=0.6856\n",
      "epoch=42, train_loss=0.0989, test_acc=0.6884\n",
      "epoch=43, train_loss=0.0987, test_acc=0.6856\n",
      "epoch=44, train_loss=0.0987, test_acc=0.6857\n",
      "epoch=45, train_loss=0.0990, test_acc=0.6858\n",
      "epoch=46, train_loss=0.0992, test_acc=0.6854\n",
      "epoch=47, train_loss=0.0989, test_acc=0.6884\n",
      "epoch=48, train_loss=0.0989, test_acc=0.6867\n",
      "epoch=49, train_loss=0.0986, test_acc=0.6872\n",
      "epoch=50, train_loss=0.0987, test_acc=0.6860\n",
      "epoch=51, train_loss=0.0987, test_acc=0.6880\n",
      "epoch=52, train_loss=0.0986, test_acc=0.6874\n",
      "epoch=53, train_loss=0.0987, test_acc=0.6862\n",
      "epoch=54, train_loss=0.0987, test_acc=0.6862\n",
      "epoch=55, train_loss=0.0993, test_acc=0.6882\n",
      "epoch=56, train_loss=0.0985, test_acc=0.6851\n",
      "epoch=57, train_loss=0.0988, test_acc=0.6850\n",
      "epoch=58, train_loss=0.0993, test_acc=0.6871\n",
      "epoch=59, train_loss=0.0987, test_acc=0.6863\n",
      "block 8 recasting...\n",
      "block 8 training started...\n",
      "epoch=0, train_loss=2.5059, test_acc=0.1537\n",
      "epoch=1, train_loss=1.0469, test_acc=0.4714\n",
      "epoch=2, train_loss=0.5042, test_acc=0.5477\n",
      "epoch=3, train_loss=0.2809, test_acc=0.6345\n",
      "epoch=4, train_loss=0.2205, test_acc=0.6722\n",
      "epoch=5, train_loss=0.1933, test_acc=0.6745\n",
      "epoch=6, train_loss=0.1733, test_acc=0.6770\n",
      "epoch=7, train_loss=0.1567, test_acc=0.6783\n",
      "epoch=8, train_loss=0.1492, test_acc=0.6798\n",
      "epoch=9, train_loss=0.1475, test_acc=0.6755\n",
      "epoch=10, train_loss=0.1439, test_acc=0.6544\n",
      "epoch=11, train_loss=0.1435, test_acc=0.6824\n",
      "epoch=12, train_loss=0.1411, test_acc=0.6830\n",
      "epoch=13, train_loss=0.1361, test_acc=0.6702\n",
      "epoch=14, train_loss=0.1185, test_acc=0.6811\n",
      "epoch=15, train_loss=0.1087, test_acc=0.6784\n",
      "epoch=16, train_loss=0.1072, test_acc=0.6819\n",
      "epoch=17, train_loss=0.0940, test_acc=0.6536\n",
      "epoch=18, train_loss=0.0915, test_acc=0.6674\n",
      "epoch=19, train_loss=0.0909, test_acc=0.6808\n",
      "epoch=20, train_loss=0.0881, test_acc=0.6870\n",
      "epoch=21, train_loss=0.0879, test_acc=0.6852\n",
      "epoch=22, train_loss=0.0878, test_acc=0.6861\n",
      "epoch=23, train_loss=0.0876, test_acc=0.6854\n",
      "epoch=24, train_loss=0.0873, test_acc=0.6849\n",
      "epoch=25, train_loss=0.0876, test_acc=0.6865\n",
      "epoch=26, train_loss=0.0874, test_acc=0.6841\n",
      "epoch=27, train_loss=0.0871, test_acc=0.6854\n",
      "epoch=28, train_loss=0.0871, test_acc=0.6863\n",
      "epoch=29, train_loss=0.0871, test_acc=0.6865\n",
      "epoch=30, train_loss=0.0868, test_acc=0.6835\n",
      "epoch=31, train_loss=0.0867, test_acc=0.6856\n",
      "epoch=32, train_loss=0.0866, test_acc=0.6857\n",
      "epoch=33, train_loss=0.0862, test_acc=0.6856\n",
      "epoch=34, train_loss=0.0865, test_acc=0.6864\n",
      "epoch=35, train_loss=0.0865, test_acc=0.6859\n",
      "epoch=36, train_loss=0.0864, test_acc=0.6853\n",
      "epoch=37, train_loss=0.0862, test_acc=0.6836\n",
      "epoch=38, train_loss=0.0863, test_acc=0.6857\n",
      "epoch=39, train_loss=0.0862, test_acc=0.6846\n",
      "epoch=40, train_loss=0.0860, test_acc=0.6856\n",
      "epoch=41, train_loss=0.0858, test_acc=0.6858\n",
      "epoch=42, train_loss=0.0858, test_acc=0.6863\n",
      "epoch=43, train_loss=0.0856, test_acc=0.6849\n",
      "epoch=44, train_loss=0.0857, test_acc=0.6857\n",
      "epoch=45, train_loss=0.0856, test_acc=0.6854\n",
      "epoch=46, train_loss=0.0857, test_acc=0.6853\n",
      "epoch=47, train_loss=0.0857, test_acc=0.6851\n",
      "epoch=48, train_loss=0.0855, test_acc=0.6860\n",
      "epoch=49, train_loss=0.0857, test_acc=0.6853\n",
      "epoch=50, train_loss=0.0854, test_acc=0.6850\n",
      "epoch=51, train_loss=0.0858, test_acc=0.6861\n",
      "epoch=52, train_loss=0.0858, test_acc=0.6851\n",
      "epoch=53, train_loss=0.0856, test_acc=0.6864\n",
      "epoch=54, train_loss=0.0857, test_acc=0.6858\n",
      "epoch=55, train_loss=0.0857, test_acc=0.6862\n",
      "epoch=56, train_loss=0.0858, test_acc=0.6852\n",
      "epoch=57, train_loss=0.0863, test_acc=0.6865\n",
      "epoch=58, train_loss=0.0856, test_acc=0.6850\n",
      "epoch=59, train_loss=0.0855, test_acc=0.6863\n",
      "block 9 recasting...\n",
      "block 9 training started...\n",
      "epoch=0, train_loss=0.4305, test_acc=0.5774\n",
      "epoch=1, train_loss=0.1343, test_acc=0.6221\n",
      "epoch=2, train_loss=0.0863, test_acc=0.6605\n",
      "epoch=3, train_loss=0.0724, test_acc=0.6783\n",
      "epoch=4, train_loss=0.0667, test_acc=0.6798\n",
      "epoch=5, train_loss=0.0628, test_acc=0.6697\n",
      "epoch=6, train_loss=0.0608, test_acc=0.6791\n",
      "epoch=7, train_loss=0.0587, test_acc=0.6731\n",
      "epoch=8, train_loss=0.0572, test_acc=0.6768\n",
      "epoch=9, train_loss=0.0554, test_acc=0.6745\n",
      "epoch=10, train_loss=0.0538, test_acc=0.6826\n",
      "epoch=11, train_loss=0.0526, test_acc=0.6798\n",
      "epoch=12, train_loss=0.0518, test_acc=0.6750\n",
      "epoch=13, train_loss=0.0513, test_acc=0.6834\n",
      "epoch=14, train_loss=0.0511, test_acc=0.6559\n",
      "epoch=15, train_loss=0.0506, test_acc=0.6683\n",
      "epoch=16, train_loss=0.0504, test_acc=0.6848\n",
      "epoch=17, train_loss=0.0498, test_acc=0.6691\n",
      "epoch=18, train_loss=0.0495, test_acc=0.6583\n",
      "epoch=19, train_loss=0.0493, test_acc=0.6791\n",
      "epoch=20, train_loss=0.0479, test_acc=0.6857\n",
      "epoch=21, train_loss=0.0475, test_acc=0.6857\n",
      "epoch=22, train_loss=0.0475, test_acc=0.6864\n",
      "epoch=23, train_loss=0.0474, test_acc=0.6852\n",
      "epoch=24, train_loss=0.0475, test_acc=0.6860\n",
      "epoch=25, train_loss=0.0475, test_acc=0.6804\n",
      "epoch=26, train_loss=0.0475, test_acc=0.6860\n",
      "epoch=27, train_loss=0.0474, test_acc=0.6854\n",
      "epoch=28, train_loss=0.0471, test_acc=0.6858\n",
      "epoch=29, train_loss=0.0472, test_acc=0.6873\n",
      "epoch=30, train_loss=0.0473, test_acc=0.6856\n",
      "epoch=31, train_loss=0.0472, test_acc=0.6845\n",
      "epoch=32, train_loss=0.0473, test_acc=0.6869\n",
      "epoch=33, train_loss=0.0472, test_acc=0.6857\n",
      "epoch=34, train_loss=0.0471, test_acc=0.6871\n",
      "epoch=35, train_loss=0.0473, test_acc=0.6828\n",
      "epoch=36, train_loss=0.0471, test_acc=0.6844\n",
      "epoch=37, train_loss=0.0471, test_acc=0.6833\n",
      "epoch=38, train_loss=0.0469, test_acc=0.6845\n",
      "epoch=39, train_loss=0.0469, test_acc=0.6840\n",
      "epoch=40, train_loss=0.0467, test_acc=0.6858\n",
      "epoch=41, train_loss=0.0466, test_acc=0.6852\n",
      "epoch=42, train_loss=0.0466, test_acc=0.6846\n",
      "epoch=43, train_loss=0.0468, test_acc=0.6856\n",
      "epoch=44, train_loss=0.0467, test_acc=0.6848\n",
      "epoch=45, train_loss=0.0469, test_acc=0.6844\n",
      "epoch=46, train_loss=0.0467, test_acc=0.6861\n",
      "epoch=47, train_loss=0.0467, test_acc=0.6852\n",
      "epoch=48, train_loss=0.0468, test_acc=0.6854\n",
      "epoch=49, train_loss=0.0467, test_acc=0.6857\n",
      "epoch=50, train_loss=0.0468, test_acc=0.6854\n",
      "epoch=51, train_loss=0.0468, test_acc=0.6855\n",
      "epoch=52, train_loss=0.0467, test_acc=0.6852\n",
      "epoch=53, train_loss=0.0467, test_acc=0.6862\n",
      "epoch=54, train_loss=0.0466, test_acc=0.6862\n",
      "epoch=55, train_loss=0.0467, test_acc=0.6843\n",
      "epoch=56, train_loss=0.0466, test_acc=0.6858\n",
      "epoch=57, train_loss=0.0467, test_acc=0.6864\n",
      "epoch=58, train_loss=0.0466, test_acc=0.6860\n",
      "epoch=59, train_loss=0.0466, test_acc=0.6859\n",
      "block 10 recasting...\n",
      "block 10 training started...\n",
      "epoch=0, train_loss=0.5386, test_acc=0.5986\n",
      "epoch=1, train_loss=0.1707, test_acc=0.6637\n",
      "epoch=2, train_loss=0.1078, test_acc=0.6676\n",
      "epoch=3, train_loss=0.0867, test_acc=0.6797\n",
      "epoch=4, train_loss=0.0762, test_acc=0.6692\n",
      "epoch=5, train_loss=0.0724, test_acc=0.6690\n",
      "epoch=6, train_loss=0.0701, test_acc=0.6811\n",
      "epoch=7, train_loss=0.0690, test_acc=0.6732\n",
      "epoch=8, train_loss=0.0681, test_acc=0.6787\n",
      "epoch=9, train_loss=0.0679, test_acc=0.6756\n",
      "epoch=10, train_loss=0.0669, test_acc=0.6441\n",
      "epoch=11, train_loss=0.0671, test_acc=0.6778\n",
      "epoch=12, train_loss=0.0662, test_acc=0.6807\n",
      "epoch=13, train_loss=0.0658, test_acc=0.6719\n",
      "epoch=14, train_loss=0.0654, test_acc=0.6823\n",
      "epoch=15, train_loss=0.0653, test_acc=0.6765\n",
      "epoch=16, train_loss=0.0645, test_acc=0.6752\n",
      "epoch=17, train_loss=0.0646, test_acc=0.6739\n",
      "epoch=18, train_loss=0.0640, test_acc=0.6762\n",
      "epoch=19, train_loss=0.0638, test_acc=0.6768\n",
      "epoch=20, train_loss=0.0617, test_acc=0.6873\n",
      "epoch=21, train_loss=0.0618, test_acc=0.6856\n",
      "epoch=22, train_loss=0.0616, test_acc=0.6883\n",
      "epoch=23, train_loss=0.0617, test_acc=0.6855\n",
      "epoch=24, train_loss=0.0617, test_acc=0.6854\n",
      "epoch=25, train_loss=0.0617, test_acc=0.6879\n",
      "epoch=26, train_loss=0.0613, test_acc=0.6887\n",
      "epoch=27, train_loss=0.0615, test_acc=0.6881\n",
      "epoch=28, train_loss=0.0614, test_acc=0.6877\n",
      "epoch=29, train_loss=0.0616, test_acc=0.6870\n",
      "epoch=30, train_loss=0.0614, test_acc=0.6900\n",
      "epoch=31, train_loss=0.0613, test_acc=0.6843\n",
      "epoch=32, train_loss=0.0613, test_acc=0.6880\n",
      "epoch=33, train_loss=0.0612, test_acc=0.6867\n",
      "epoch=34, train_loss=0.0611, test_acc=0.6887\n",
      "epoch=35, train_loss=0.0612, test_acc=0.6880\n",
      "epoch=36, train_loss=0.0615, test_acc=0.6881\n",
      "epoch=37, train_loss=0.0611, test_acc=0.6866\n",
      "epoch=38, train_loss=0.0612, test_acc=0.6867\n",
      "epoch=39, train_loss=0.0610, test_acc=0.6864\n",
      "epoch=40, train_loss=0.0607, test_acc=0.6895\n",
      "epoch=41, train_loss=0.0607, test_acc=0.6898\n",
      "epoch=42, train_loss=0.0607, test_acc=0.6874\n",
      "epoch=43, train_loss=0.0607, test_acc=0.6893\n",
      "epoch=44, train_loss=0.0608, test_acc=0.6886\n",
      "epoch=45, train_loss=0.0608, test_acc=0.6889\n",
      "epoch=46, train_loss=0.0608, test_acc=0.6883\n",
      "epoch=47, train_loss=0.0609, test_acc=0.6887\n",
      "epoch=48, train_loss=0.0607, test_acc=0.6904\n",
      "epoch=49, train_loss=0.0608, test_acc=0.6882\n",
      "epoch=50, train_loss=0.0609, test_acc=0.6870\n",
      "epoch=51, train_loss=0.0609, test_acc=0.6881\n",
      "epoch=52, train_loss=0.0608, test_acc=0.6885\n",
      "epoch=53, train_loss=0.0608, test_acc=0.6891\n",
      "epoch=54, train_loss=0.0608, test_acc=0.6880\n",
      "epoch=55, train_loss=0.0607, test_acc=0.6880\n",
      "epoch=56, train_loss=0.0607, test_acc=0.6889\n",
      "epoch=57, train_loss=0.0608, test_acc=0.6887\n",
      "epoch=58, train_loss=0.0608, test_acc=0.6896\n",
      "epoch=59, train_loss=0.0608, test_acc=0.6878\n",
      "block 11 recasting...\n",
      "block 11 training started...\n",
      "epoch=0, train_loss=0.6407, test_acc=0.5305\n",
      "epoch=1, train_loss=0.2090, test_acc=0.6426\n",
      "epoch=2, train_loss=0.1317, test_acc=0.6702\n",
      "epoch=3, train_loss=0.1097, test_acc=0.6788\n",
      "epoch=4, train_loss=0.0999, test_acc=0.6724\n",
      "epoch=5, train_loss=0.0935, test_acc=0.6726\n",
      "epoch=6, train_loss=0.0903, test_acc=0.6703\n",
      "epoch=7, train_loss=0.0885, test_acc=0.6490\n",
      "epoch=8, train_loss=0.0875, test_acc=0.6670\n",
      "epoch=9, train_loss=0.0866, test_acc=0.6783\n",
      "epoch=10, train_loss=0.0862, test_acc=0.6749\n",
      "epoch=11, train_loss=0.0853, test_acc=0.6789\n",
      "epoch=12, train_loss=0.0846, test_acc=0.6748\n",
      "epoch=13, train_loss=0.0838, test_acc=0.6736\n",
      "epoch=14, train_loss=0.0832, test_acc=0.6840\n",
      "epoch=15, train_loss=0.0827, test_acc=0.6826\n",
      "epoch=16, train_loss=0.0824, test_acc=0.6736\n",
      "epoch=17, train_loss=0.0819, test_acc=0.6710\n",
      "epoch=18, train_loss=0.0817, test_acc=0.6610\n",
      "epoch=19, train_loss=0.0815, test_acc=0.6693\n",
      "epoch=20, train_loss=0.0792, test_acc=0.6884\n",
      "epoch=21, train_loss=0.0791, test_acc=0.6857\n",
      "epoch=22, train_loss=0.0788, test_acc=0.6859\n",
      "epoch=23, train_loss=0.0792, test_acc=0.6872\n",
      "epoch=24, train_loss=0.0789, test_acc=0.6853\n",
      "epoch=25, train_loss=0.0789, test_acc=0.6878\n",
      "epoch=26, train_loss=0.0786, test_acc=0.6888\n",
      "epoch=27, train_loss=0.0785, test_acc=0.6886\n",
      "epoch=28, train_loss=0.0784, test_acc=0.6873\n",
      "epoch=29, train_loss=0.0786, test_acc=0.6851\n",
      "epoch=30, train_loss=0.0783, test_acc=0.6880\n",
      "epoch=31, train_loss=0.0783, test_acc=0.6882\n",
      "epoch=32, train_loss=0.0783, test_acc=0.6862\n",
      "epoch=33, train_loss=0.0782, test_acc=0.6863\n",
      "epoch=34, train_loss=0.0780, test_acc=0.6873\n",
      "epoch=35, train_loss=0.0782, test_acc=0.6855\n",
      "epoch=36, train_loss=0.0782, test_acc=0.6872\n",
      "epoch=37, train_loss=0.0781, test_acc=0.6851\n",
      "epoch=38, train_loss=0.0780, test_acc=0.6857\n",
      "epoch=39, train_loss=0.0781, test_acc=0.6866\n",
      "epoch=40, train_loss=0.0776, test_acc=0.6876\n",
      "epoch=41, train_loss=0.0776, test_acc=0.6873\n",
      "epoch=42, train_loss=0.0776, test_acc=0.6875\n",
      "epoch=43, train_loss=0.0777, test_acc=0.6873\n",
      "epoch=44, train_loss=0.0776, test_acc=0.6875\n",
      "epoch=45, train_loss=0.0776, test_acc=0.6849\n",
      "epoch=46, train_loss=0.0778, test_acc=0.6884\n",
      "epoch=47, train_loss=0.0776, test_acc=0.6880\n",
      "epoch=48, train_loss=0.0777, test_acc=0.6879\n",
      "epoch=49, train_loss=0.0774, test_acc=0.6866\n",
      "epoch=50, train_loss=0.0777, test_acc=0.6875\n",
      "epoch=51, train_loss=0.0777, test_acc=0.6878\n",
      "epoch=52, train_loss=0.0776, test_acc=0.6892\n",
      "epoch=53, train_loss=0.0777, test_acc=0.6878\n",
      "epoch=54, train_loss=0.0777, test_acc=0.6868\n",
      "epoch=55, train_loss=0.0776, test_acc=0.6871\n",
      "epoch=56, train_loss=0.0776, test_acc=0.6883\n",
      "epoch=57, train_loss=0.0776, test_acc=0.6889\n",
      "epoch=58, train_loss=0.0776, test_acc=0.6869\n",
      "epoch=59, train_loss=0.0778, test_acc=0.6889\n",
      "block 12 recasting...\n",
      "block 12 training started...\n",
      "epoch=0, train_loss=0.7603, test_acc=0.5514\n",
      "epoch=1, train_loss=0.2636, test_acc=0.6318\n",
      "epoch=2, train_loss=0.1651, test_acc=0.6435\n",
      "epoch=3, train_loss=0.1344, test_acc=0.6631\n",
      "epoch=4, train_loss=0.1221, test_acc=0.6729\n",
      "epoch=5, train_loss=0.1152, test_acc=0.6626\n",
      "epoch=6, train_loss=0.1119, test_acc=0.6655\n",
      "epoch=7, train_loss=0.1106, test_acc=0.6636\n",
      "epoch=8, train_loss=0.1094, test_acc=0.6732\n",
      "epoch=9, train_loss=0.1084, test_acc=0.6571\n",
      "epoch=10, train_loss=0.1077, test_acc=0.6823\n",
      "epoch=11, train_loss=0.1069, test_acc=0.6746\n",
      "epoch=12, train_loss=0.1054, test_acc=0.6675\n",
      "epoch=13, train_loss=0.1044, test_acc=0.6730\n",
      "epoch=14, train_loss=0.1035, test_acc=0.6735\n",
      "epoch=15, train_loss=0.1029, test_acc=0.6756\n",
      "epoch=16, train_loss=0.1025, test_acc=0.6726\n",
      "epoch=17, train_loss=0.1018, test_acc=0.6848\n",
      "epoch=18, train_loss=0.1014, test_acc=0.6849\n",
      "epoch=19, train_loss=0.1007, test_acc=0.6759\n",
      "epoch=20, train_loss=0.0979, test_acc=0.6844\n",
      "epoch=21, train_loss=0.0979, test_acc=0.6854\n",
      "epoch=22, train_loss=0.0979, test_acc=0.6854\n",
      "epoch=23, train_loss=0.0978, test_acc=0.6869\n",
      "epoch=24, train_loss=0.0977, test_acc=0.6856\n",
      "epoch=25, train_loss=0.0975, test_acc=0.6837\n",
      "epoch=26, train_loss=0.0973, test_acc=0.6833\n",
      "epoch=27, train_loss=0.0973, test_acc=0.6845\n",
      "epoch=28, train_loss=0.0971, test_acc=0.6843\n",
      "epoch=29, train_loss=0.0966, test_acc=0.6853\n",
      "epoch=30, train_loss=0.0966, test_acc=0.6863\n",
      "epoch=31, train_loss=0.0963, test_acc=0.6856\n",
      "epoch=32, train_loss=0.0964, test_acc=0.6852\n",
      "epoch=33, train_loss=0.0963, test_acc=0.6858\n",
      "epoch=34, train_loss=0.0962, test_acc=0.6833\n",
      "epoch=35, train_loss=0.0962, test_acc=0.6847\n",
      "epoch=36, train_loss=0.0960, test_acc=0.6810\n",
      "epoch=37, train_loss=0.0961, test_acc=0.6850\n",
      "epoch=38, train_loss=0.0960, test_acc=0.6836\n",
      "epoch=39, train_loss=0.0957, test_acc=0.6865\n",
      "epoch=40, train_loss=0.0954, test_acc=0.6872\n",
      "epoch=41, train_loss=0.0956, test_acc=0.6861\n",
      "epoch=42, train_loss=0.0956, test_acc=0.6871\n",
      "epoch=43, train_loss=0.0954, test_acc=0.6864\n",
      "epoch=44, train_loss=0.0955, test_acc=0.6856\n",
      "epoch=45, train_loss=0.0955, test_acc=0.6868\n",
      "epoch=46, train_loss=0.0955, test_acc=0.6875\n",
      "epoch=47, train_loss=0.0956, test_acc=0.6851\n",
      "epoch=48, train_loss=0.0956, test_acc=0.6823\n",
      "epoch=49, train_loss=0.0956, test_acc=0.6856\n",
      "epoch=50, train_loss=0.0956, test_acc=0.6838\n",
      "epoch=51, train_loss=0.0955, test_acc=0.6863\n",
      "epoch=52, train_loss=0.0956, test_acc=0.6865\n",
      "epoch=53, train_loss=0.0955, test_acc=0.6845\n",
      "epoch=54, train_loss=0.0955, test_acc=0.6853\n",
      "epoch=55, train_loss=0.0955, test_acc=0.6871\n",
      "epoch=56, train_loss=0.0953, test_acc=0.6854\n",
      "epoch=57, train_loss=0.0954, test_acc=0.6854\n",
      "epoch=58, train_loss=0.0955, test_acc=0.6857\n",
      "epoch=59, train_loss=0.0953, test_acc=0.6876\n",
      "block 13 recasting...\n",
      "block 13 training started...\n",
      "epoch=0, train_loss=0.8922, test_acc=0.5298\n",
      "epoch=1, train_loss=0.3127, test_acc=0.6414\n",
      "epoch=2, train_loss=0.1988, test_acc=0.6140\n",
      "epoch=3, train_loss=0.1610, test_acc=0.6693\n",
      "epoch=4, train_loss=0.1470, test_acc=0.6597\n",
      "epoch=5, train_loss=0.1420, test_acc=0.6724\n",
      "epoch=6, train_loss=0.1368, test_acc=0.6722\n",
      "epoch=7, train_loss=0.1329, test_acc=0.6601\n",
      "epoch=8, train_loss=0.1304, test_acc=0.6506\n",
      "epoch=9, train_loss=0.1278, test_acc=0.6738\n",
      "epoch=10, train_loss=0.1261, test_acc=0.6644\n",
      "epoch=11, train_loss=0.1253, test_acc=0.6731\n",
      "epoch=12, train_loss=0.1243, test_acc=0.6702\n",
      "epoch=13, train_loss=0.1234, test_acc=0.6597\n",
      "epoch=14, train_loss=0.1229, test_acc=0.6738\n",
      "epoch=15, train_loss=0.1220, test_acc=0.6742\n",
      "epoch=16, train_loss=0.1216, test_acc=0.6739\n",
      "epoch=17, train_loss=0.1212, test_acc=0.6701\n",
      "epoch=18, train_loss=0.1210, test_acc=0.6512\n",
      "epoch=19, train_loss=0.1206, test_acc=0.6734\n",
      "epoch=20, train_loss=0.1175, test_acc=0.6817\n",
      "epoch=21, train_loss=0.1172, test_acc=0.6828\n",
      "epoch=22, train_loss=0.1172, test_acc=0.6813\n",
      "epoch=23, train_loss=0.1170, test_acc=0.6779\n",
      "epoch=24, train_loss=0.1170, test_acc=0.6807\n",
      "epoch=25, train_loss=0.1168, test_acc=0.6791\n",
      "epoch=26, train_loss=0.1168, test_acc=0.6818\n",
      "epoch=27, train_loss=0.1166, test_acc=0.6813\n",
      "epoch=28, train_loss=0.1167, test_acc=0.6851\n",
      "epoch=29, train_loss=0.1168, test_acc=0.6814\n",
      "epoch=30, train_loss=0.1165, test_acc=0.6797\n",
      "epoch=31, train_loss=0.1165, test_acc=0.6836\n",
      "epoch=32, train_loss=0.1166, test_acc=0.6836\n",
      "epoch=33, train_loss=0.1165, test_acc=0.6840\n",
      "epoch=34, train_loss=0.1162, test_acc=0.6845\n",
      "epoch=35, train_loss=0.1162, test_acc=0.6800\n",
      "epoch=36, train_loss=0.1163, test_acc=0.6836\n",
      "epoch=37, train_loss=0.1161, test_acc=0.6809\n",
      "epoch=38, train_loss=0.1161, test_acc=0.6808\n",
      "epoch=39, train_loss=0.1162, test_acc=0.6842\n",
      "epoch=40, train_loss=0.1155, test_acc=0.6829\n",
      "epoch=41, train_loss=0.1158, test_acc=0.6834\n",
      "epoch=42, train_loss=0.1157, test_acc=0.6848\n",
      "epoch=43, train_loss=0.1157, test_acc=0.6809\n",
      "epoch=44, train_loss=0.1156, test_acc=0.6825\n",
      "epoch=45, train_loss=0.1156, test_acc=0.6825\n",
      "epoch=46, train_loss=0.1155, test_acc=0.6825\n",
      "epoch=47, train_loss=0.1155, test_acc=0.6834\n",
      "epoch=48, train_loss=0.1157, test_acc=0.6837\n",
      "epoch=49, train_loss=0.1157, test_acc=0.6850\n",
      "epoch=50, train_loss=0.1156, test_acc=0.6838\n",
      "epoch=51, train_loss=0.1155, test_acc=0.6833\n",
      "epoch=52, train_loss=0.1155, test_acc=0.6834\n",
      "epoch=53, train_loss=0.1157, test_acc=0.6847\n",
      "epoch=54, train_loss=0.1156, test_acc=0.6838\n",
      "epoch=55, train_loss=0.1155, test_acc=0.6835\n",
      "epoch=56, train_loss=0.1155, test_acc=0.6821\n",
      "epoch=57, train_loss=0.1154, test_acc=0.6825\n",
      "epoch=58, train_loss=0.1156, test_acc=0.6826\n",
      "epoch=59, train_loss=0.1155, test_acc=0.6843\n",
      "block 14 recasting...\n",
      "block 14 training started...\n",
      "epoch=0, train_loss=1.0254, test_acc=0.4690\n",
      "epoch=1, train_loss=0.3738, test_acc=0.6282\n",
      "epoch=2, train_loss=0.2396, test_acc=0.6400\n",
      "epoch=3, train_loss=0.1923, test_acc=0.6710\n",
      "epoch=4, train_loss=0.1729, test_acc=0.6529\n",
      "epoch=5, train_loss=0.1647, test_acc=0.5556\n",
      "epoch=6, train_loss=0.1582, test_acc=0.6574\n",
      "epoch=7, train_loss=0.1553, test_acc=0.6718\n",
      "epoch=8, train_loss=0.1515, test_acc=0.6637\n",
      "epoch=9, train_loss=0.1502, test_acc=0.6645\n",
      "epoch=10, train_loss=0.1494, test_acc=0.6647\n",
      "epoch=11, train_loss=0.1485, test_acc=0.6608\n",
      "epoch=12, train_loss=0.1477, test_acc=0.6621\n",
      "epoch=13, train_loss=0.1469, test_acc=0.6475\n",
      "epoch=14, train_loss=0.1465, test_acc=0.6551\n",
      "epoch=15, train_loss=0.1473, test_acc=0.6629\n",
      "epoch=16, train_loss=0.1457, test_acc=0.6665\n",
      "epoch=17, train_loss=0.1450, test_acc=0.6583\n",
      "epoch=18, train_loss=0.1444, test_acc=0.6660\n",
      "epoch=19, train_loss=0.1444, test_acc=0.6589\n",
      "epoch=20, train_loss=0.1407, test_acc=0.6822\n",
      "epoch=21, train_loss=0.1404, test_acc=0.6817\n",
      "epoch=22, train_loss=0.1404, test_acc=0.6820\n",
      "epoch=23, train_loss=0.1404, test_acc=0.6836\n",
      "epoch=24, train_loss=0.1405, test_acc=0.6824\n",
      "epoch=25, train_loss=0.1403, test_acc=0.6838\n",
      "epoch=26, train_loss=0.1400, test_acc=0.6832\n",
      "epoch=27, train_loss=0.1401, test_acc=0.6823\n",
      "epoch=28, train_loss=0.1401, test_acc=0.6829\n",
      "epoch=29, train_loss=0.1399, test_acc=0.6800\n",
      "epoch=30, train_loss=0.1404, test_acc=0.6755\n",
      "epoch=31, train_loss=0.1402, test_acc=0.6833\n",
      "epoch=32, train_loss=0.1400, test_acc=0.6832\n",
      "epoch=33, train_loss=0.1399, test_acc=0.6812\n",
      "epoch=34, train_loss=0.1399, test_acc=0.6799\n",
      "epoch=35, train_loss=0.1397, test_acc=0.6823\n",
      "epoch=36, train_loss=0.1399, test_acc=0.6804\n",
      "epoch=37, train_loss=0.1397, test_acc=0.6832\n",
      "epoch=38, train_loss=0.1396, test_acc=0.6827\n",
      "epoch=39, train_loss=0.1396, test_acc=0.6811\n",
      "epoch=40, train_loss=0.1394, test_acc=0.6826\n",
      "epoch=41, train_loss=0.1389, test_acc=0.6837\n",
      "epoch=42, train_loss=0.1393, test_acc=0.6824\n",
      "epoch=43, train_loss=0.1392, test_acc=0.6830\n",
      "epoch=44, train_loss=0.1389, test_acc=0.6838\n",
      "epoch=45, train_loss=0.1390, test_acc=0.6825\n",
      "epoch=46, train_loss=0.1391, test_acc=0.6849\n",
      "epoch=47, train_loss=0.1391, test_acc=0.6828\n",
      "epoch=48, train_loss=0.1392, test_acc=0.6827\n",
      "epoch=49, train_loss=0.1391, test_acc=0.6847\n",
      "epoch=50, train_loss=0.1391, test_acc=0.6828\n",
      "epoch=51, train_loss=0.1390, test_acc=0.6832\n",
      "epoch=52, train_loss=0.1391, test_acc=0.6836\n",
      "epoch=53, train_loss=0.1391, test_acc=0.6833\n",
      "epoch=54, train_loss=0.1389, test_acc=0.6837\n",
      "epoch=55, train_loss=0.1390, test_acc=0.6835\n",
      "epoch=56, train_loss=0.1391, test_acc=0.6846\n",
      "epoch=57, train_loss=0.1390, test_acc=0.6827\n",
      "epoch=58, train_loss=0.1390, test_acc=0.6836\n",
      "epoch=59, train_loss=0.1391, test_acc=0.6824\n",
      "block 15 recasting...\n",
      "block 15 training started...\n",
      "epoch=0, train_loss=1.1410, test_acc=0.4516\n",
      "epoch=1, train_loss=0.4226, test_acc=0.5668\n",
      "epoch=2, train_loss=0.2728, test_acc=0.6307\n",
      "epoch=3, train_loss=0.2236, test_acc=0.6619\n",
      "epoch=4, train_loss=0.2040, test_acc=0.6335\n",
      "epoch=5, train_loss=0.1923, test_acc=0.5913\n",
      "epoch=6, train_loss=0.1857, test_acc=0.6650\n",
      "epoch=7, train_loss=0.1830, test_acc=0.6469\n",
      "epoch=8, train_loss=0.1800, test_acc=0.6672\n",
      "epoch=9, train_loss=0.1781, test_acc=0.6606\n",
      "epoch=10, train_loss=0.1771, test_acc=0.6505\n",
      "epoch=11, train_loss=0.1769, test_acc=0.6635\n",
      "epoch=12, train_loss=0.1762, test_acc=0.6398\n",
      "epoch=13, train_loss=0.1753, test_acc=0.6490\n",
      "epoch=14, train_loss=0.1743, test_acc=0.6553\n",
      "epoch=15, train_loss=0.1739, test_acc=0.6616\n",
      "epoch=16, train_loss=0.1760, test_acc=0.6574\n",
      "epoch=17, train_loss=0.1730, test_acc=0.6718\n",
      "epoch=18, train_loss=0.1720, test_acc=0.6621\n",
      "epoch=19, train_loss=0.1732, test_acc=0.6543\n",
      "epoch=20, train_loss=0.1681, test_acc=0.6788\n",
      "epoch=21, train_loss=0.1673, test_acc=0.6768\n",
      "epoch=22, train_loss=0.1672, test_acc=0.6780\n",
      "epoch=23, train_loss=0.1670, test_acc=0.6764\n",
      "epoch=24, train_loss=0.1673, test_acc=0.6729\n",
      "epoch=25, train_loss=0.1668, test_acc=0.6801\n",
      "epoch=26, train_loss=0.1666, test_acc=0.6754\n",
      "epoch=27, train_loss=0.1666, test_acc=0.6774\n",
      "epoch=28, train_loss=0.1665, test_acc=0.6785\n",
      "epoch=29, train_loss=0.1665, test_acc=0.6798\n",
      "epoch=30, train_loss=0.1663, test_acc=0.6796\n",
      "epoch=31, train_loss=0.1662, test_acc=0.6806\n",
      "epoch=32, train_loss=0.1660, test_acc=0.6815\n",
      "epoch=33, train_loss=0.1660, test_acc=0.6817\n",
      "epoch=34, train_loss=0.1659, test_acc=0.6831\n",
      "epoch=35, train_loss=0.1658, test_acc=0.6786\n",
      "epoch=36, train_loss=0.1660, test_acc=0.6752\n",
      "epoch=37, train_loss=0.1657, test_acc=0.6776\n",
      "epoch=38, train_loss=0.1657, test_acc=0.6809\n",
      "epoch=39, train_loss=0.1655, test_acc=0.6806\n",
      "epoch=40, train_loss=0.1649, test_acc=0.6792\n",
      "epoch=41, train_loss=0.1651, test_acc=0.6794\n",
      "epoch=42, train_loss=0.1649, test_acc=0.6817\n",
      "epoch=43, train_loss=0.1646, test_acc=0.6793\n",
      "epoch=44, train_loss=0.1649, test_acc=0.6795\n",
      "epoch=45, train_loss=0.1649, test_acc=0.6801\n",
      "epoch=46, train_loss=0.1647, test_acc=0.6808\n",
      "epoch=47, train_loss=0.1649, test_acc=0.6806\n",
      "epoch=48, train_loss=0.1653, test_acc=0.6804\n",
      "epoch=49, train_loss=0.1649, test_acc=0.6808\n",
      "epoch=50, train_loss=0.1650, test_acc=0.6799\n",
      "epoch=51, train_loss=0.1649, test_acc=0.6796\n",
      "epoch=52, train_loss=0.1649, test_acc=0.6817\n",
      "epoch=53, train_loss=0.1650, test_acc=0.6808\n",
      "epoch=54, train_loss=0.1647, test_acc=0.6822\n",
      "epoch=55, train_loss=0.1654, test_acc=0.6758\n",
      "epoch=56, train_loss=0.1647, test_acc=0.6813\n",
      "epoch=57, train_loss=0.1649, test_acc=0.6787\n",
      "epoch=58, train_loss=0.1647, test_acc=0.6802\n",
      "epoch=59, train_loss=0.1650, test_acc=0.6789\n",
      "block 16 recasting...\n",
      "block 16 training started...\n",
      "epoch=0, train_loss=1.2586, test_acc=0.4156\n",
      "epoch=1, train_loss=0.4717, test_acc=0.5899\n",
      "epoch=2, train_loss=0.3047, test_acc=0.5993\n",
      "epoch=3, train_loss=0.2577, test_acc=0.6336\n",
      "epoch=4, train_loss=0.2363, test_acc=0.5593\n",
      "epoch=5, train_loss=0.2228, test_acc=0.6566\n",
      "epoch=6, train_loss=0.2120, test_acc=0.6366\n",
      "epoch=7, train_loss=0.2088, test_acc=0.5004\n",
      "epoch=8, train_loss=0.2150, test_acc=0.6466\n",
      "epoch=9, train_loss=0.2146, test_acc=0.6180\n",
      "epoch=10, train_loss=0.2096, test_acc=0.6520\n",
      "epoch=11, train_loss=0.2054, test_acc=0.6582\n",
      "epoch=12, train_loss=0.2032, test_acc=0.6605\n",
      "epoch=13, train_loss=0.2027, test_acc=0.5453\n",
      "epoch=14, train_loss=0.2030, test_acc=0.6309\n",
      "epoch=15, train_loss=0.2010, test_acc=0.6569\n",
      "epoch=16, train_loss=0.2002, test_acc=0.6348\n",
      "epoch=17, train_loss=0.1994, test_acc=0.6526\n",
      "epoch=18, train_loss=0.1990, test_acc=0.6614\n",
      "epoch=19, train_loss=0.1983, test_acc=0.5244\n",
      "epoch=20, train_loss=0.1939, test_acc=0.6740\n",
      "epoch=21, train_loss=0.1925, test_acc=0.6773\n",
      "epoch=22, train_loss=0.1924, test_acc=0.6749\n",
      "epoch=23, train_loss=0.1924, test_acc=0.6758\n",
      "epoch=24, train_loss=0.1921, test_acc=0.6803\n",
      "epoch=25, train_loss=0.1924, test_acc=0.6774\n",
      "epoch=26, train_loss=0.1921, test_acc=0.6725\n",
      "epoch=27, train_loss=0.1925, test_acc=0.6789\n",
      "epoch=28, train_loss=0.1921, test_acc=0.6771\n",
      "epoch=29, train_loss=0.1920, test_acc=0.6761\n",
      "epoch=30, train_loss=0.1921, test_acc=0.6754\n",
      "epoch=31, train_loss=0.1918, test_acc=0.6775\n",
      "epoch=32, train_loss=0.1916, test_acc=0.6747\n",
      "epoch=33, train_loss=0.1913, test_acc=0.6782\n",
      "epoch=34, train_loss=0.1914, test_acc=0.6757\n",
      "epoch=35, train_loss=0.1916, test_acc=0.6773\n",
      "epoch=36, train_loss=0.1917, test_acc=0.6797\n",
      "epoch=37, train_loss=0.1915, test_acc=0.6791\n",
      "epoch=38, train_loss=0.1916, test_acc=0.6790\n",
      "epoch=39, train_loss=0.1912, test_acc=0.6746\n",
      "epoch=40, train_loss=0.1906, test_acc=0.6804\n",
      "epoch=41, train_loss=0.1905, test_acc=0.6785\n",
      "epoch=42, train_loss=0.1909, test_acc=0.6777\n",
      "epoch=43, train_loss=0.1903, test_acc=0.6781\n",
      "epoch=44, train_loss=0.1905, test_acc=0.6808\n",
      "epoch=45, train_loss=0.1905, test_acc=0.6809\n",
      "epoch=46, train_loss=0.1906, test_acc=0.6808\n",
      "epoch=47, train_loss=0.1903, test_acc=0.6808\n",
      "epoch=48, train_loss=0.1907, test_acc=0.6794\n",
      "epoch=49, train_loss=0.1903, test_acc=0.6794\n",
      "epoch=50, train_loss=0.1904, test_acc=0.6781\n",
      "epoch=51, train_loss=0.1904, test_acc=0.6782\n",
      "epoch=52, train_loss=0.1902, test_acc=0.6805\n",
      "epoch=53, train_loss=0.1902, test_acc=0.6793\n",
      "epoch=54, train_loss=0.1902, test_acc=0.6807\n",
      "epoch=55, train_loss=0.1903, test_acc=0.6788\n",
      "epoch=56, train_loss=0.1905, test_acc=0.6778\n",
      "epoch=57, train_loss=0.1903, test_acc=0.6786\n",
      "epoch=58, train_loss=0.1902, test_acc=0.6788\n",
      "epoch=59, train_loss=0.1904, test_acc=0.6795\n",
      "block 17 recasting...\n",
      "block 17 training started...\n",
      "epoch=0, train_loss=1.4197, test_acc=0.3805\n",
      "epoch=1, train_loss=0.5474, test_acc=0.5630\n",
      "epoch=2, train_loss=0.3507, test_acc=0.6146\n",
      "epoch=3, train_loss=0.2956, test_acc=0.6433\n",
      "epoch=4, train_loss=0.2678, test_acc=0.6100\n",
      "epoch=5, train_loss=0.2525, test_acc=0.5639\n",
      "epoch=6, train_loss=0.2454, test_acc=0.6382\n",
      "epoch=7, train_loss=0.2452, test_acc=0.6311\n",
      "epoch=8, train_loss=0.2412, test_acc=0.6263\n",
      "epoch=9, train_loss=0.2394, test_acc=0.6249\n",
      "epoch=10, train_loss=0.2385, test_acc=0.6329\n",
      "epoch=11, train_loss=0.2406, test_acc=0.5684\n",
      "epoch=12, train_loss=0.2388, test_acc=0.5862\n",
      "epoch=13, train_loss=0.2379, test_acc=0.5996\n",
      "epoch=14, train_loss=0.2349, test_acc=0.5592\n",
      "epoch=15, train_loss=0.2344, test_acc=0.6335\n",
      "epoch=16, train_loss=0.2338, test_acc=0.5406\n",
      "epoch=17, train_loss=0.2417, test_acc=0.6178\n",
      "epoch=18, train_loss=0.2345, test_acc=0.6325\n",
      "epoch=19, train_loss=0.2327, test_acc=0.6439\n",
      "epoch=20, train_loss=0.2264, test_acc=0.6770\n",
      "epoch=21, train_loss=0.2263, test_acc=0.6769\n",
      "epoch=22, train_loss=0.2259, test_acc=0.6768\n",
      "epoch=23, train_loss=0.2257, test_acc=0.6758\n",
      "epoch=24, train_loss=0.2255, test_acc=0.6715\n",
      "epoch=25, train_loss=0.2255, test_acc=0.6707\n",
      "epoch=26, train_loss=0.2252, test_acc=0.6764\n",
      "epoch=27, train_loss=0.2253, test_acc=0.6752\n",
      "epoch=28, train_loss=0.2247, test_acc=0.6745\n",
      "epoch=29, train_loss=0.2251, test_acc=0.6727\n",
      "epoch=30, train_loss=0.2248, test_acc=0.6749\n",
      "epoch=31, train_loss=0.2247, test_acc=0.6735\n",
      "epoch=32, train_loss=0.2244, test_acc=0.6743\n",
      "epoch=33, train_loss=0.2244, test_acc=0.6720\n",
      "epoch=34, train_loss=0.2243, test_acc=0.6742\n",
      "epoch=35, train_loss=0.2242, test_acc=0.6740\n",
      "epoch=36, train_loss=0.2241, test_acc=0.6779\n",
      "epoch=37, train_loss=0.2240, test_acc=0.6769\n",
      "epoch=38, train_loss=0.2239, test_acc=0.6741\n",
      "epoch=39, train_loss=0.2237, test_acc=0.6710\n",
      "epoch=40, train_loss=0.2229, test_acc=0.6791\n",
      "epoch=41, train_loss=0.2228, test_acc=0.6781\n",
      "epoch=42, train_loss=0.2229, test_acc=0.6779\n",
      "epoch=43, train_loss=0.2228, test_acc=0.6783\n",
      "epoch=44, train_loss=0.2233, test_acc=0.6771\n",
      "epoch=45, train_loss=0.2228, test_acc=0.6783\n",
      "epoch=46, train_loss=0.2228, test_acc=0.6770\n",
      "epoch=47, train_loss=0.2227, test_acc=0.6770\n",
      "epoch=48, train_loss=0.2230, test_acc=0.6770\n",
      "epoch=49, train_loss=0.2228, test_acc=0.6762\n",
      "epoch=50, train_loss=0.2228, test_acc=0.6775\n",
      "epoch=51, train_loss=0.2226, test_acc=0.6778\n",
      "epoch=52, train_loss=0.2228, test_acc=0.6774\n",
      "epoch=53, train_loss=0.2228, test_acc=0.6765\n",
      "epoch=54, train_loss=0.2230, test_acc=0.6779\n",
      "epoch=55, train_loss=0.2229, test_acc=0.6773\n",
      "epoch=56, train_loss=0.2228, test_acc=0.6778\n",
      "epoch=57, train_loss=0.2227, test_acc=0.6772\n",
      "epoch=58, train_loss=0.2228, test_acc=0.6781\n",
      "epoch=59, train_loss=0.2230, test_acc=0.6763\n",
      "block 18 recasting...\n",
      "block 18 training started...\n",
      "epoch=0, train_loss=0.3661, test_acc=0.6250\n",
      "epoch=1, train_loss=0.1887, test_acc=0.6459\n",
      "epoch=2, train_loss=0.1767, test_acc=0.6273\n",
      "epoch=3, train_loss=0.1720, test_acc=0.6239\n",
      "epoch=4, train_loss=0.1689, test_acc=0.6509\n",
      "epoch=5, train_loss=0.1669, test_acc=0.6533\n",
      "epoch=6, train_loss=0.1652, test_acc=0.6378\n",
      "epoch=7, train_loss=0.1634, test_acc=0.6241\n",
      "epoch=8, train_loss=0.1624, test_acc=0.6398\n",
      "epoch=9, train_loss=0.1626, test_acc=0.6491\n",
      "epoch=10, train_loss=0.1597, test_acc=0.6572\n",
      "epoch=11, train_loss=0.1591, test_acc=0.6495\n",
      "epoch=12, train_loss=0.1580, test_acc=0.6548\n",
      "epoch=13, train_loss=0.1575, test_acc=0.6363\n",
      "epoch=14, train_loss=0.1568, test_acc=0.6404\n",
      "epoch=15, train_loss=0.1563, test_acc=0.6131\n",
      "epoch=16, train_loss=0.1556, test_acc=0.6291\n",
      "epoch=17, train_loss=0.1551, test_acc=0.6424\n",
      "epoch=18, train_loss=0.1538, test_acc=0.6590\n",
      "epoch=19, train_loss=0.1536, test_acc=0.6256\n",
      "epoch=20, train_loss=0.1475, test_acc=0.6770\n",
      "epoch=21, train_loss=0.1475, test_acc=0.6785\n",
      "epoch=22, train_loss=0.1472, test_acc=0.6781\n",
      "epoch=23, train_loss=0.1470, test_acc=0.6785\n",
      "epoch=24, train_loss=0.1469, test_acc=0.6765\n",
      "epoch=25, train_loss=0.1468, test_acc=0.6767\n",
      "epoch=26, train_loss=0.1469, test_acc=0.6766\n",
      "epoch=27, train_loss=0.1467, test_acc=0.6777\n",
      "epoch=28, train_loss=0.1465, test_acc=0.6790\n",
      "epoch=29, train_loss=0.1466, test_acc=0.6776\n",
      "epoch=30, train_loss=0.1465, test_acc=0.6771\n",
      "epoch=31, train_loss=0.1464, test_acc=0.6790\n",
      "epoch=32, train_loss=0.1461, test_acc=0.6783\n",
      "epoch=33, train_loss=0.1461, test_acc=0.6738\n",
      "epoch=34, train_loss=0.1459, test_acc=0.6791\n",
      "epoch=35, train_loss=0.1460, test_acc=0.6755\n",
      "epoch=36, train_loss=0.1458, test_acc=0.6784\n",
      "epoch=37, train_loss=0.1456, test_acc=0.6763\n",
      "epoch=38, train_loss=0.1459, test_acc=0.6747\n",
      "epoch=39, train_loss=0.1460, test_acc=0.6764\n",
      "epoch=40, train_loss=0.1450, test_acc=0.6794\n",
      "epoch=41, train_loss=0.1448, test_acc=0.6811\n",
      "epoch=42, train_loss=0.1446, test_acc=0.6809\n",
      "epoch=43, train_loss=0.1447, test_acc=0.6794\n",
      "epoch=44, train_loss=0.1449, test_acc=0.6791\n",
      "epoch=45, train_loss=0.1447, test_acc=0.6802\n",
      "epoch=46, train_loss=0.1448, test_acc=0.6796\n",
      "epoch=47, train_loss=0.1452, test_acc=0.6777\n",
      "epoch=48, train_loss=0.1451, test_acc=0.6788\n",
      "epoch=49, train_loss=0.1449, test_acc=0.6795\n",
      "epoch=50, train_loss=0.1448, test_acc=0.6801\n",
      "epoch=51, train_loss=0.1449, test_acc=0.6816\n",
      "epoch=52, train_loss=0.1448, test_acc=0.6800\n",
      "epoch=53, train_loss=0.1448, test_acc=0.6790\n",
      "epoch=54, train_loss=0.1448, test_acc=0.6795\n",
      "epoch=55, train_loss=0.1445, test_acc=0.6792\n",
      "epoch=56, train_loss=0.1448, test_acc=0.6797\n",
      "epoch=57, train_loss=0.1448, test_acc=0.6800\n",
      "epoch=58, train_loss=0.1448, test_acc=0.6791\n",
      "epoch=59, train_loss=0.1447, test_acc=0.6803\n",
      "block 19 recasting...\n",
      "block 19 training started...\n",
      "epoch=0, train_loss=0.5108, test_acc=0.5910\n",
      "epoch=1, train_loss=0.2877, test_acc=0.6337\n",
      "epoch=2, train_loss=0.2696, test_acc=0.6320\n",
      "epoch=3, train_loss=0.2628, test_acc=0.6474\n",
      "epoch=4, train_loss=0.2586, test_acc=0.6523\n",
      "epoch=5, train_loss=0.2557, test_acc=0.6381\n",
      "epoch=6, train_loss=0.2535, test_acc=0.6355\n",
      "epoch=7, train_loss=0.2519, test_acc=0.6235\n",
      "epoch=8, train_loss=0.2503, test_acc=0.6456\n",
      "epoch=9, train_loss=0.2490, test_acc=0.6442\n",
      "epoch=10, train_loss=0.2478, test_acc=0.6341\n",
      "epoch=11, train_loss=0.2465, test_acc=0.6445\n",
      "epoch=12, train_loss=0.2460, test_acc=0.6508\n",
      "epoch=13, train_loss=0.2449, test_acc=0.6281\n",
      "epoch=14, train_loss=0.2444, test_acc=0.6611\n",
      "epoch=15, train_loss=0.2427, test_acc=0.6429\n",
      "epoch=16, train_loss=0.2426, test_acc=0.6622\n",
      "epoch=17, train_loss=0.2415, test_acc=0.6174\n",
      "epoch=18, train_loss=0.2409, test_acc=0.6432\n",
      "epoch=19, train_loss=0.2398, test_acc=0.6350\n",
      "epoch=20, train_loss=0.2330, test_acc=0.6789\n",
      "epoch=21, train_loss=0.2330, test_acc=0.6774\n",
      "epoch=22, train_loss=0.2326, test_acc=0.6763\n",
      "epoch=23, train_loss=0.2324, test_acc=0.6780\n",
      "epoch=24, train_loss=0.2326, test_acc=0.6792\n",
      "epoch=25, train_loss=0.2326, test_acc=0.6808\n",
      "epoch=26, train_loss=0.2322, test_acc=0.6765\n",
      "epoch=27, train_loss=0.2323, test_acc=0.6767\n",
      "epoch=28, train_loss=0.2322, test_acc=0.6806\n",
      "epoch=29, train_loss=0.2321, test_acc=0.6784\n",
      "epoch=30, train_loss=0.2324, test_acc=0.6786\n",
      "epoch=31, train_loss=0.2318, test_acc=0.6779\n",
      "epoch=32, train_loss=0.2318, test_acc=0.6788\n",
      "epoch=33, train_loss=0.2318, test_acc=0.6760\n",
      "epoch=34, train_loss=0.2316, test_acc=0.6793\n",
      "epoch=35, train_loss=0.2315, test_acc=0.6765\n",
      "epoch=36, train_loss=0.2315, test_acc=0.6758\n",
      "epoch=37, train_loss=0.2317, test_acc=0.6785\n",
      "epoch=38, train_loss=0.2316, test_acc=0.6787\n",
      "epoch=39, train_loss=0.2310, test_acc=0.6806\n",
      "epoch=40, train_loss=0.2306, test_acc=0.6800\n",
      "epoch=41, train_loss=0.2305, test_acc=0.6804\n",
      "epoch=42, train_loss=0.2301, test_acc=0.6812\n",
      "epoch=43, train_loss=0.2303, test_acc=0.6815\n",
      "epoch=44, train_loss=0.2301, test_acc=0.6801\n",
      "epoch=45, train_loss=0.2302, test_acc=0.6804\n",
      "epoch=46, train_loss=0.2303, test_acc=0.6785\n",
      "epoch=47, train_loss=0.2301, test_acc=0.6806\n",
      "epoch=48, train_loss=0.2304, test_acc=0.6806\n",
      "epoch=49, train_loss=0.2303, test_acc=0.6797\n",
      "epoch=50, train_loss=0.2302, test_acc=0.6799\n",
      "epoch=51, train_loss=0.2303, test_acc=0.6782\n",
      "epoch=52, train_loss=0.2301, test_acc=0.6801\n",
      "epoch=53, train_loss=0.2302, test_acc=0.6805\n",
      "epoch=54, train_loss=0.2303, test_acc=0.6784\n",
      "epoch=55, train_loss=0.2300, test_acc=0.6800\n",
      "epoch=56, train_loss=0.2302, test_acc=0.6820\n",
      "epoch=57, train_loss=0.2301, test_acc=0.6802\n",
      "epoch=58, train_loss=0.2302, test_acc=0.6763\n",
      "epoch=59, train_loss=0.2303, test_acc=0.6789\n",
      "block 20 recasting...\n",
      "block 20 training started...\n",
      "epoch=0, train_loss=0.6236, test_acc=0.6158\n",
      "epoch=1, train_loss=0.3651, test_acc=0.6243\n",
      "epoch=2, train_loss=0.3453, test_acc=0.6446\n",
      "epoch=3, train_loss=0.3374, test_acc=0.6529\n",
      "epoch=4, train_loss=0.3328, test_acc=0.6299\n",
      "epoch=5, train_loss=0.3297, test_acc=0.6531\n",
      "epoch=6, train_loss=0.3276, test_acc=0.6391\n",
      "epoch=7, train_loss=0.3253, test_acc=0.6519\n",
      "epoch=8, train_loss=0.3235, test_acc=0.6362\n",
      "epoch=9, train_loss=0.3221, test_acc=0.6493\n",
      "epoch=10, train_loss=0.3209, test_acc=0.6298\n",
      "epoch=11, train_loss=0.3190, test_acc=0.6418\n",
      "epoch=12, train_loss=0.3186, test_acc=0.6504\n",
      "epoch=13, train_loss=0.3176, test_acc=0.6574\n",
      "epoch=14, train_loss=0.3163, test_acc=0.6486\n",
      "epoch=15, train_loss=0.3156, test_acc=0.6521\n",
      "epoch=16, train_loss=0.3149, test_acc=0.6458\n",
      "epoch=17, train_loss=0.3139, test_acc=0.6305\n",
      "epoch=18, train_loss=0.3135, test_acc=0.6551\n",
      "epoch=19, train_loss=0.3126, test_acc=0.6574\n",
      "epoch=20, train_loss=0.3038, test_acc=0.6739\n",
      "epoch=21, train_loss=0.3037, test_acc=0.6706\n",
      "epoch=22, train_loss=0.3035, test_acc=0.6690\n",
      "epoch=23, train_loss=0.3033, test_acc=0.6729\n",
      "epoch=24, train_loss=0.3033, test_acc=0.6708\n",
      "epoch=25, train_loss=0.3032, test_acc=0.6713\n",
      "epoch=26, train_loss=0.3029, test_acc=0.6706\n",
      "epoch=27, train_loss=0.3027, test_acc=0.6739\n",
      "epoch=28, train_loss=0.3026, test_acc=0.6718\n",
      "epoch=29, train_loss=0.3027, test_acc=0.6731\n",
      "epoch=30, train_loss=0.3025, test_acc=0.6729\n",
      "epoch=31, train_loss=0.3025, test_acc=0.6703\n",
      "epoch=32, train_loss=0.3023, test_acc=0.6684\n",
      "epoch=33, train_loss=0.3020, test_acc=0.6717\n",
      "epoch=34, train_loss=0.3021, test_acc=0.6727\n",
      "epoch=35, train_loss=0.3023, test_acc=0.6731\n",
      "epoch=36, train_loss=0.3019, test_acc=0.6720\n",
      "epoch=37, train_loss=0.3018, test_acc=0.6715\n",
      "epoch=38, train_loss=0.3017, test_acc=0.6724\n",
      "epoch=39, train_loss=0.3019, test_acc=0.6729\n",
      "epoch=40, train_loss=0.3010, test_acc=0.6746\n",
      "epoch=41, train_loss=0.3005, test_acc=0.6731\n",
      "epoch=42, train_loss=0.3008, test_acc=0.6751\n",
      "epoch=43, train_loss=0.3006, test_acc=0.6741\n",
      "epoch=44, train_loss=0.3003, test_acc=0.6758\n",
      "epoch=45, train_loss=0.3007, test_acc=0.6721\n",
      "epoch=46, train_loss=0.3008, test_acc=0.6728\n",
      "epoch=47, train_loss=0.3006, test_acc=0.6734\n",
      "epoch=48, train_loss=0.3005, test_acc=0.6739\n",
      "epoch=49, train_loss=0.3006, test_acc=0.6734\n",
      "epoch=50, train_loss=0.3006, test_acc=0.6750\n",
      "epoch=51, train_loss=0.3005, test_acc=0.6732\n",
      "epoch=52, train_loss=0.3005, test_acc=0.6713\n",
      "epoch=53, train_loss=0.3008, test_acc=0.6741\n",
      "epoch=54, train_loss=0.3004, test_acc=0.6753\n",
      "epoch=55, train_loss=0.3006, test_acc=0.6732\n",
      "epoch=56, train_loss=0.3004, test_acc=0.6746\n",
      "epoch=57, train_loss=0.3005, test_acc=0.6742\n",
      "epoch=58, train_loss=0.3002, test_acc=0.6725\n",
      "epoch=59, train_loss=0.3003, test_acc=0.6732\n",
      "block 21 recasting...\n",
      "block 21 training started...\n",
      "epoch=0, train_loss=0.7065, test_acc=0.6096\n",
      "epoch=1, train_loss=0.4390, test_acc=0.6044\n",
      "epoch=2, train_loss=0.4188, test_acc=0.6241\n",
      "epoch=3, train_loss=0.4108, test_acc=0.6345\n",
      "epoch=4, train_loss=0.4060, test_acc=0.6027\n",
      "epoch=5, train_loss=0.4030, test_acc=0.6179\n",
      "epoch=6, train_loss=0.4003, test_acc=0.6298\n",
      "epoch=7, train_loss=0.3988, test_acc=0.6049\n",
      "epoch=8, train_loss=0.3968, test_acc=0.6090\n",
      "epoch=9, train_loss=0.3956, test_acc=0.6276\n",
      "epoch=10, train_loss=0.3942, test_acc=0.6132\n",
      "epoch=11, train_loss=0.3930, test_acc=0.6411\n",
      "epoch=12, train_loss=0.3922, test_acc=0.6202\n",
      "epoch=13, train_loss=0.3913, test_acc=0.6409\n",
      "epoch=14, train_loss=0.3901, test_acc=0.6327\n",
      "epoch=15, train_loss=0.3892, test_acc=0.6069\n",
      "epoch=16, train_loss=0.3883, test_acc=0.6467\n",
      "epoch=17, train_loss=0.3876, test_acc=0.6109\n",
      "epoch=18, train_loss=0.3868, test_acc=0.6512\n",
      "epoch=19, train_loss=0.3861, test_acc=0.6343\n",
      "epoch=20, train_loss=0.3755, test_acc=0.6704\n",
      "epoch=21, train_loss=0.3752, test_acc=0.6661\n",
      "epoch=22, train_loss=0.3751, test_acc=0.6676\n",
      "epoch=23, train_loss=0.3745, test_acc=0.6695\n",
      "epoch=24, train_loss=0.3744, test_acc=0.6693\n",
      "epoch=25, train_loss=0.3744, test_acc=0.6683\n",
      "epoch=26, train_loss=0.3744, test_acc=0.6672\n",
      "epoch=27, train_loss=0.3746, test_acc=0.6647\n",
      "epoch=28, train_loss=0.3743, test_acc=0.6690\n",
      "epoch=29, train_loss=0.3737, test_acc=0.6642\n",
      "epoch=30, train_loss=0.3737, test_acc=0.6661\n",
      "epoch=31, train_loss=0.3736, test_acc=0.6660\n",
      "epoch=32, train_loss=0.3735, test_acc=0.6667\n",
      "epoch=33, train_loss=0.3738, test_acc=0.6701\n",
      "epoch=34, train_loss=0.3736, test_acc=0.6669\n",
      "epoch=35, train_loss=0.3733, test_acc=0.6641\n",
      "epoch=36, train_loss=0.3735, test_acc=0.6680\n",
      "epoch=37, train_loss=0.3732, test_acc=0.6673\n",
      "epoch=38, train_loss=0.3731, test_acc=0.6668\n",
      "epoch=39, train_loss=0.3733, test_acc=0.6672\n",
      "epoch=40, train_loss=0.3716, test_acc=0.6695\n",
      "epoch=41, train_loss=0.3718, test_acc=0.6693\n",
      "epoch=42, train_loss=0.3717, test_acc=0.6712\n",
      "epoch=43, train_loss=0.3716, test_acc=0.6716\n",
      "epoch=44, train_loss=0.3717, test_acc=0.6718\n",
      "epoch=45, train_loss=0.3717, test_acc=0.6712\n",
      "epoch=46, train_loss=0.3716, test_acc=0.6704\n",
      "epoch=47, train_loss=0.3718, test_acc=0.6666\n",
      "epoch=48, train_loss=0.3718, test_acc=0.6679\n",
      "epoch=49, train_loss=0.3719, test_acc=0.6705\n",
      "epoch=50, train_loss=0.3713, test_acc=0.6703\n",
      "epoch=51, train_loss=0.3713, test_acc=0.6675\n",
      "epoch=52, train_loss=0.3715, test_acc=0.6694\n",
      "epoch=53, train_loss=0.3714, test_acc=0.6714\n",
      "epoch=54, train_loss=0.3717, test_acc=0.6706\n",
      "epoch=55, train_loss=0.3711, test_acc=0.6696\n",
      "epoch=56, train_loss=0.3715, test_acc=0.6673\n",
      "epoch=57, train_loss=0.3715, test_acc=0.6691\n",
      "epoch=58, train_loss=0.3716, test_acc=0.6704\n",
      "epoch=59, train_loss=0.3714, test_acc=0.6710\n",
      "block 22 recasting...\n",
      "block 22 training started...\n",
      "epoch=0, train_loss=0.7863, test_acc=0.6011\n",
      "epoch=1, train_loss=0.5193, test_acc=0.6171\n",
      "epoch=2, train_loss=0.4981, test_acc=0.6017\n",
      "epoch=3, train_loss=0.4890, test_acc=0.6144\n",
      "epoch=4, train_loss=0.4839, test_acc=0.6107\n",
      "epoch=5, train_loss=0.4809, test_acc=0.6389\n",
      "epoch=6, train_loss=0.4781, test_acc=0.6295\n",
      "epoch=7, train_loss=0.4754, test_acc=0.6154\n",
      "epoch=8, train_loss=0.4737, test_acc=0.6342\n",
      "epoch=9, train_loss=0.4718, test_acc=0.6100\n",
      "epoch=10, train_loss=0.4705, test_acc=0.6171\n",
      "epoch=11, train_loss=0.4692, test_acc=0.6247\n",
      "epoch=12, train_loss=0.4682, test_acc=0.6318\n",
      "epoch=13, train_loss=0.4670, test_acc=0.6149\n",
      "epoch=14, train_loss=0.4666, test_acc=0.6315\n",
      "epoch=15, train_loss=0.4656, test_acc=0.6255\n",
      "epoch=16, train_loss=0.4648, test_acc=0.6219\n",
      "epoch=17, train_loss=0.4640, test_acc=0.6102\n",
      "epoch=18, train_loss=0.4631, test_acc=0.6165\n",
      "epoch=19, train_loss=0.4629, test_acc=0.6331\n",
      "epoch=20, train_loss=0.4507, test_acc=0.6639\n",
      "epoch=21, train_loss=0.4497, test_acc=0.6612\n",
      "epoch=22, train_loss=0.4498, test_acc=0.6613\n",
      "epoch=23, train_loss=0.4494, test_acc=0.6611\n",
      "epoch=24, train_loss=0.4492, test_acc=0.6656\n",
      "epoch=25, train_loss=0.4494, test_acc=0.6598\n",
      "epoch=26, train_loss=0.4489, test_acc=0.6629\n",
      "epoch=27, train_loss=0.4493, test_acc=0.6585\n",
      "epoch=28, train_loss=0.4485, test_acc=0.6629\n",
      "epoch=29, train_loss=0.4488, test_acc=0.6615\n",
      "epoch=30, train_loss=0.4484, test_acc=0.6662\n",
      "epoch=31, train_loss=0.4485, test_acc=0.6594\n",
      "epoch=32, train_loss=0.4484, test_acc=0.6597\n",
      "epoch=33, train_loss=0.4484, test_acc=0.6609\n",
      "epoch=34, train_loss=0.4483, test_acc=0.6662\n",
      "epoch=35, train_loss=0.4483, test_acc=0.6650\n",
      "epoch=36, train_loss=0.4480, test_acc=0.6594\n",
      "epoch=37, train_loss=0.4482, test_acc=0.6613\n",
      "epoch=38, train_loss=0.4475, test_acc=0.6658\n",
      "epoch=39, train_loss=0.4477, test_acc=0.6587\n",
      "epoch=40, train_loss=0.4467, test_acc=0.6657\n",
      "epoch=41, train_loss=0.4462, test_acc=0.6645\n",
      "epoch=42, train_loss=0.4462, test_acc=0.6657\n",
      "epoch=43, train_loss=0.4464, test_acc=0.6646\n",
      "epoch=44, train_loss=0.4463, test_acc=0.6631\n",
      "epoch=45, train_loss=0.4460, test_acc=0.6615\n",
      "epoch=46, train_loss=0.4458, test_acc=0.6638\n",
      "epoch=47, train_loss=0.4463, test_acc=0.6659\n",
      "epoch=48, train_loss=0.4458, test_acc=0.6651\n",
      "epoch=49, train_loss=0.4463, test_acc=0.6642\n",
      "epoch=50, train_loss=0.4462, test_acc=0.6631\n",
      "epoch=51, train_loss=0.4463, test_acc=0.6651\n",
      "epoch=52, train_loss=0.4460, test_acc=0.6645\n",
      "epoch=53, train_loss=0.4460, test_acc=0.6643\n",
      "epoch=54, train_loss=0.4459, test_acc=0.6636\n",
      "epoch=55, train_loss=0.4460, test_acc=0.6655\n",
      "epoch=56, train_loss=0.4461, test_acc=0.6636\n",
      "epoch=57, train_loss=0.4462, test_acc=0.6649\n",
      "epoch=58, train_loss=0.4464, test_acc=0.6661\n",
      "epoch=59, train_loss=0.4460, test_acc=0.6655\n",
      "block 23 recasting...\n",
      "block 23 training started...\n",
      "epoch=0, train_loss=0.9381, test_acc=0.5864\n",
      "epoch=1, train_loss=0.6520, test_acc=0.5832\n",
      "epoch=2, train_loss=0.6294, test_acc=0.5835\n",
      "epoch=3, train_loss=0.6205, test_acc=0.6022\n",
      "epoch=4, train_loss=0.6144, test_acc=0.6099\n",
      "epoch=5, train_loss=0.6101, test_acc=0.5864\n",
      "epoch=6, train_loss=0.6063, test_acc=0.6353\n",
      "epoch=7, train_loss=0.6054, test_acc=0.6134\n",
      "epoch=8, train_loss=0.6030, test_acc=0.6164\n",
      "epoch=9, train_loss=0.6002, test_acc=0.6152\n",
      "epoch=10, train_loss=0.5986, test_acc=0.6153\n",
      "epoch=11, train_loss=0.5980, test_acc=0.6101\n",
      "epoch=12, train_loss=0.5961, test_acc=0.6162\n",
      "epoch=13, train_loss=0.5956, test_acc=0.6144\n",
      "epoch=14, train_loss=0.5940, test_acc=0.5957\n",
      "epoch=15, train_loss=0.5936, test_acc=0.6353\n",
      "epoch=16, train_loss=0.5922, test_acc=0.6123\n",
      "epoch=17, train_loss=0.5914, test_acc=0.6205\n",
      "epoch=18, train_loss=0.5905, test_acc=0.6334\n",
      "epoch=19, train_loss=0.5899, test_acc=0.6139\n",
      "epoch=20, train_loss=0.5752, test_acc=0.6571\n",
      "epoch=21, train_loss=0.5741, test_acc=0.6557\n",
      "epoch=22, train_loss=0.5741, test_acc=0.6578\n",
      "epoch=23, train_loss=0.5734, test_acc=0.6548\n",
      "epoch=24, train_loss=0.5738, test_acc=0.6568\n",
      "epoch=25, train_loss=0.5730, test_acc=0.6585\n",
      "epoch=26, train_loss=0.5733, test_acc=0.6546\n",
      "epoch=27, train_loss=0.5721, test_acc=0.6556\n",
      "epoch=28, train_loss=0.5728, test_acc=0.6585\n",
      "epoch=29, train_loss=0.5722, test_acc=0.6604\n",
      "epoch=30, train_loss=0.5726, test_acc=0.6561\n",
      "epoch=31, train_loss=0.5728, test_acc=0.6579\n",
      "epoch=32, train_loss=0.5720, test_acc=0.6575\n",
      "epoch=33, train_loss=0.5716, test_acc=0.6594\n",
      "epoch=34, train_loss=0.5720, test_acc=0.6588\n",
      "epoch=35, train_loss=0.5718, test_acc=0.6586\n",
      "epoch=36, train_loss=0.5720, test_acc=0.6604\n",
      "epoch=37, train_loss=0.5717, test_acc=0.6597\n",
      "epoch=38, train_loss=0.5718, test_acc=0.6585\n",
      "epoch=39, train_loss=0.5719, test_acc=0.6568\n",
      "epoch=40, train_loss=0.5697, test_acc=0.6623\n",
      "epoch=41, train_loss=0.5696, test_acc=0.6589\n",
      "epoch=42, train_loss=0.5702, test_acc=0.6613\n",
      "epoch=43, train_loss=0.5696, test_acc=0.6591\n",
      "epoch=44, train_loss=0.5700, test_acc=0.6607\n",
      "epoch=45, train_loss=0.5691, test_acc=0.6600\n",
      "epoch=46, train_loss=0.5694, test_acc=0.6616\n",
      "epoch=47, train_loss=0.5695, test_acc=0.6616\n",
      "epoch=48, train_loss=0.5691, test_acc=0.6590\n",
      "epoch=49, train_loss=0.5695, test_acc=0.6590\n",
      "epoch=50, train_loss=0.5701, test_acc=0.6575\n",
      "epoch=51, train_loss=0.5694, test_acc=0.6587\n",
      "epoch=52, train_loss=0.5695, test_acc=0.6626\n",
      "epoch=53, train_loss=0.5686, test_acc=0.6591\n",
      "epoch=54, train_loss=0.5692, test_acc=0.6612\n",
      "epoch=55, train_loss=0.5692, test_acc=0.6614\n",
      "epoch=56, train_loss=0.5696, test_acc=0.6628\n",
      "epoch=57, train_loss=0.5697, test_acc=0.6590\n",
      "epoch=58, train_loss=0.5690, test_acc=0.6609\n",
      "epoch=59, train_loss=0.5696, test_acc=0.6586\n",
      "block 24 recasting...\n",
      "block 24 training started...\n",
      "epoch=0, train_loss=1.1446, test_acc=0.5674\n",
      "epoch=1, train_loss=0.8164, test_acc=0.5551\n",
      "epoch=2, train_loss=0.7894, test_acc=0.5844\n",
      "epoch=3, train_loss=0.7793, test_acc=0.5925\n",
      "epoch=4, train_loss=0.7729, test_acc=0.5813\n",
      "epoch=5, train_loss=0.7688, test_acc=0.5836\n",
      "epoch=6, train_loss=0.7642, test_acc=0.6034\n",
      "epoch=7, train_loss=0.7625, test_acc=0.5915\n",
      "epoch=8, train_loss=0.7587, test_acc=0.5913\n",
      "epoch=9, train_loss=0.7569, test_acc=0.6042\n",
      "epoch=10, train_loss=0.7550, test_acc=0.5734\n",
      "epoch=11, train_loss=0.7533, test_acc=0.6007\n",
      "epoch=12, train_loss=0.7506, test_acc=0.5729\n",
      "epoch=13, train_loss=0.7501, test_acc=0.6102\n",
      "epoch=14, train_loss=0.7491, test_acc=0.6040\n",
      "epoch=15, train_loss=0.7480, test_acc=0.5981\n",
      "epoch=16, train_loss=0.7472, test_acc=0.6208\n",
      "epoch=17, train_loss=0.7454, test_acc=0.6174\n",
      "epoch=18, train_loss=0.7442, test_acc=0.5863\n",
      "epoch=19, train_loss=0.7435, test_acc=0.6166\n",
      "epoch=20, train_loss=0.7243, test_acc=0.6490\n",
      "epoch=21, train_loss=0.7227, test_acc=0.6489\n",
      "epoch=22, train_loss=0.7217, test_acc=0.6464\n",
      "epoch=23, train_loss=0.7219, test_acc=0.6457\n",
      "epoch=24, train_loss=0.7209, test_acc=0.6465\n",
      "epoch=25, train_loss=0.7213, test_acc=0.6458\n",
      "epoch=26, train_loss=0.7217, test_acc=0.6471\n",
      "epoch=27, train_loss=0.7204, test_acc=0.6448\n",
      "epoch=28, train_loss=0.7202, test_acc=0.6451\n",
      "epoch=29, train_loss=0.7201, test_acc=0.6463\n",
      "epoch=30, train_loss=0.7206, test_acc=0.6459\n",
      "epoch=31, train_loss=0.7202, test_acc=0.6468\n",
      "epoch=32, train_loss=0.7203, test_acc=0.6453\n",
      "epoch=33, train_loss=0.7203, test_acc=0.6459\n",
      "epoch=34, train_loss=0.7200, test_acc=0.6461\n",
      "epoch=35, train_loss=0.7201, test_acc=0.6445\n",
      "epoch=36, train_loss=0.7200, test_acc=0.6476\n",
      "epoch=37, train_loss=0.7195, test_acc=0.6478\n",
      "epoch=38, train_loss=0.7194, test_acc=0.6454\n",
      "epoch=39, train_loss=0.7189, test_acc=0.6491\n",
      "epoch=40, train_loss=0.7169, test_acc=0.6502\n",
      "epoch=41, train_loss=0.7166, test_acc=0.6487\n",
      "epoch=42, train_loss=0.7167, test_acc=0.6469\n",
      "epoch=43, train_loss=0.7167, test_acc=0.6480\n",
      "epoch=44, train_loss=0.7169, test_acc=0.6490\n",
      "epoch=45, train_loss=0.7165, test_acc=0.6492\n",
      "epoch=46, train_loss=0.7168, test_acc=0.6453\n",
      "epoch=47, train_loss=0.7171, test_acc=0.6486\n",
      "epoch=48, train_loss=0.7170, test_acc=0.6510\n",
      "epoch=49, train_loss=0.7168, test_acc=0.6492\n",
      "epoch=50, train_loss=0.7167, test_acc=0.6502\n",
      "epoch=51, train_loss=0.7170, test_acc=0.6501\n",
      "epoch=52, train_loss=0.7163, test_acc=0.6472\n",
      "epoch=53, train_loss=0.7172, test_acc=0.6488\n",
      "epoch=54, train_loss=0.7164, test_acc=0.6487\n",
      "epoch=55, train_loss=0.7171, test_acc=0.6461\n",
      "epoch=56, train_loss=0.7162, test_acc=0.6482\n",
      "epoch=57, train_loss=0.7166, test_acc=0.6491\n",
      "epoch=58, train_loss=0.7165, test_acc=0.6485\n",
      "epoch=59, train_loss=0.7167, test_acc=0.6480\n",
      "block 25 recasting...\n",
      "block 25 training started...\n",
      "epoch=0, train_loss=2.3008, test_acc=0.5513\n",
      "epoch=1, train_loss=1.5263, test_acc=0.5702\n",
      "epoch=2, train_loss=1.4358, test_acc=0.5865\n",
      "epoch=3, train_loss=1.4096, test_acc=0.6086\n",
      "epoch=4, train_loss=1.3939, test_acc=0.5913\n",
      "epoch=5, train_loss=1.3835, test_acc=0.5828\n",
      "epoch=6, train_loss=1.3771, test_acc=0.5879\n",
      "epoch=7, train_loss=1.3687, test_acc=0.6092\n",
      "epoch=8, train_loss=1.3661, test_acc=0.6031\n",
      "epoch=9, train_loss=1.3627, test_acc=0.6094\n",
      "epoch=10, train_loss=1.3566, test_acc=0.6220\n",
      "epoch=11, train_loss=1.3546, test_acc=0.5936\n",
      "epoch=12, train_loss=1.3508, test_acc=0.5892\n",
      "epoch=13, train_loss=1.3476, test_acc=0.6003\n",
      "epoch=14, train_loss=1.3456, test_acc=0.5965\n",
      "epoch=15, train_loss=1.3420, test_acc=0.6209\n",
      "epoch=16, train_loss=1.3422, test_acc=0.5928\n",
      "epoch=17, train_loss=1.3390, test_acc=0.6110\n",
      "epoch=18, train_loss=1.3369, test_acc=0.6001\n",
      "epoch=19, train_loss=1.3350, test_acc=0.6042\n",
      "epoch=20, train_loss=1.2960, test_acc=0.6521\n",
      "epoch=21, train_loss=1.2910, test_acc=0.6530\n",
      "epoch=22, train_loss=1.2889, test_acc=0.6509\n",
      "epoch=23, train_loss=1.2885, test_acc=0.6486\n",
      "epoch=24, train_loss=1.2866, test_acc=0.6523\n",
      "epoch=25, train_loss=1.2877, test_acc=0.6537\n",
      "epoch=26, train_loss=1.2870, test_acc=0.6541\n",
      "epoch=27, train_loss=1.2870, test_acc=0.6508\n",
      "epoch=28, train_loss=1.2870, test_acc=0.6527\n",
      "epoch=29, train_loss=1.2849, test_acc=0.6535\n",
      "epoch=30, train_loss=1.2860, test_acc=0.6547\n",
      "epoch=31, train_loss=1.2859, test_acc=0.6501\n",
      "epoch=32, train_loss=1.2843, test_acc=0.6533\n",
      "epoch=33, train_loss=1.2842, test_acc=0.6517\n",
      "epoch=34, train_loss=1.2835, test_acc=0.6553\n",
      "epoch=35, train_loss=1.2842, test_acc=0.6545\n",
      "epoch=36, train_loss=1.2839, test_acc=0.6543\n",
      "epoch=37, train_loss=1.2839, test_acc=0.6549\n",
      "epoch=38, train_loss=1.2828, test_acc=0.6564\n",
      "epoch=39, train_loss=1.2847, test_acc=0.6533\n",
      "epoch=40, train_loss=1.2803, test_acc=0.6525\n",
      "epoch=41, train_loss=1.2790, test_acc=0.6528\n",
      "epoch=42, train_loss=1.2791, test_acc=0.6546\n",
      "epoch=43, train_loss=1.2776, test_acc=0.6539\n",
      "epoch=44, train_loss=1.2790, test_acc=0.6557\n",
      "epoch=45, train_loss=1.2777, test_acc=0.6532\n",
      "epoch=46, train_loss=1.2775, test_acc=0.6564\n",
      "epoch=47, train_loss=1.2774, test_acc=0.6550\n",
      "epoch=48, train_loss=1.2780, test_acc=0.6533\n",
      "epoch=49, train_loss=1.2778, test_acc=0.6542\n",
      "epoch=50, train_loss=1.2767, test_acc=0.6555\n",
      "epoch=51, train_loss=1.2785, test_acc=0.6582\n",
      "epoch=52, train_loss=1.2781, test_acc=0.6546\n",
      "epoch=53, train_loss=1.2794, test_acc=0.6537\n",
      "epoch=54, train_loss=1.2789, test_acc=0.6566\n",
      "epoch=55, train_loss=1.2780, test_acc=0.6551\n",
      "epoch=56, train_loss=1.2776, test_acc=0.6540\n",
      "epoch=57, train_loss=1.2787, test_acc=0.6523\n",
      "epoch=58, train_loss=1.2796, test_acc=0.6547\n",
      "epoch=59, train_loss=1.2772, test_acc=0.6549\n",
      "block 26 recasting...\n",
      "block 26 training started...\n",
      "epoch=0, train_loss=6.7056, test_acc=0.5899\n",
      "epoch=1, train_loss=4.3508, test_acc=0.5760\n",
      "epoch=2, train_loss=3.6573, test_acc=0.5908\n",
      "epoch=3, train_loss=3.4703, test_acc=0.6081\n",
      "epoch=4, train_loss=3.4058, test_acc=0.5810\n",
      "epoch=5, train_loss=3.3793, test_acc=0.5207\n",
      "epoch=6, train_loss=3.3609, test_acc=0.5924\n",
      "epoch=7, train_loss=3.3417, test_acc=0.6129\n",
      "epoch=8, train_loss=3.3362, test_acc=0.6089\n",
      "epoch=9, train_loss=3.3209, test_acc=0.6341\n",
      "epoch=10, train_loss=3.3123, test_acc=0.6238\n",
      "epoch=11, train_loss=3.3096, test_acc=0.5876\n",
      "epoch=12, train_loss=3.3011, test_acc=0.6277\n",
      "epoch=13, train_loss=3.2924, test_acc=0.6106\n",
      "epoch=14, train_loss=3.2860, test_acc=0.6289\n",
      "epoch=15, train_loss=3.2844, test_acc=0.6250\n",
      "epoch=16, train_loss=3.2786, test_acc=0.5920\n",
      "epoch=17, train_loss=3.2728, test_acc=0.6226\n",
      "epoch=18, train_loss=3.2640, test_acc=0.6262\n",
      "epoch=19, train_loss=3.2619, test_acc=0.6413\n",
      "epoch=20, train_loss=3.1401, test_acc=0.6657\n",
      "epoch=21, train_loss=3.1253, test_acc=0.6654\n",
      "epoch=22, train_loss=3.1210, test_acc=0.6657\n",
      "epoch=23, train_loss=3.1140, test_acc=0.6688\n",
      "epoch=24, train_loss=3.1123, test_acc=0.6680\n",
      "epoch=25, train_loss=3.1127, test_acc=0.6689\n",
      "epoch=26, train_loss=3.1082, test_acc=0.6681\n",
      "epoch=27, train_loss=3.1074, test_acc=0.6672\n",
      "epoch=28, train_loss=3.1112, test_acc=0.6692\n",
      "epoch=29, train_loss=3.1026, test_acc=0.6707\n",
      "epoch=30, train_loss=3.1075, test_acc=0.6701\n",
      "epoch=31, train_loss=3.1051, test_acc=0.6671\n",
      "epoch=32, train_loss=3.1023, test_acc=0.6658\n",
      "epoch=33, train_loss=3.1059, test_acc=0.6696\n",
      "epoch=34, train_loss=3.1032, test_acc=0.6692\n",
      "epoch=35, train_loss=3.1008, test_acc=0.6694\n",
      "epoch=36, train_loss=3.1050, test_acc=0.6669\n",
      "epoch=37, train_loss=3.0982, test_acc=0.6662\n",
      "epoch=38, train_loss=3.0980, test_acc=0.6708\n",
      "epoch=39, train_loss=3.0974, test_acc=0.6633\n",
      "epoch=40, train_loss=3.0838, test_acc=0.6679\n",
      "epoch=41, train_loss=3.0840, test_acc=0.6710\n",
      "epoch=42, train_loss=3.0829, test_acc=0.6697\n",
      "epoch=43, train_loss=3.0809, test_acc=0.6708\n",
      "epoch=44, train_loss=3.0856, test_acc=0.6693\n",
      "epoch=45, train_loss=3.0838, test_acc=0.6683\n",
      "epoch=46, train_loss=3.0825, test_acc=0.6683\n",
      "epoch=47, train_loss=3.0822, test_acc=0.6699\n",
      "epoch=48, train_loss=3.0843, test_acc=0.6701\n",
      "epoch=49, train_loss=3.0774, test_acc=0.6696\n",
      "epoch=50, train_loss=3.0770, test_acc=0.6705\n",
      "epoch=51, train_loss=3.0887, test_acc=0.6708\n",
      "epoch=52, train_loss=3.0780, test_acc=0.6714\n",
      "epoch=53, train_loss=3.0808, test_acc=0.6697\n",
      "epoch=54, train_loss=3.0791, test_acc=0.6710\n",
      "epoch=55, train_loss=3.0780, test_acc=0.6706\n",
      "epoch=56, train_loss=3.0776, test_acc=0.6702\n",
      "epoch=57, train_loss=3.0805, test_acc=0.6707\n",
      "epoch=58, train_loss=3.0809, test_acc=0.6702\n",
      "epoch=59, train_loss=3.0820, test_acc=0.6712\n"
     ]
    }
   ],
   "source": [
    "history = dict()\n",
    "for idx in range(len(student.layers)):\n",
    "    history[idx] = dict(train_loss=[], test_acc=[], train_time=[], test_time=[])\n",
    "    \n",
    "    # recasting\n",
    "    print(f'block {idx} recasting...')\n",
    "    target_block = student.layers[idx]\n",
    "    in_channels = target_block.conv1.in_channels\n",
    "    stride = target_block.conv1.stride\n",
    "    out_channels = target_block.conv2.out_channels\n",
    "    \n",
    "    student.layers[idx] = ConvBlock(in_channels, out_channels, stride).to(device)\n",
    "    for m in student.layers[idx].modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    params = []\n",
    "    for i in range(idx + 1):\n",
    "        params.extend(student.layers[i].parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size)\n",
    "\n",
    "    print(f'block {idx} training started...')\n",
    "    for ep in range(epoch):\n",
    "        # train step\n",
    "        train_loss = 0.0\n",
    "        student.train()\n",
    "        s_time = time.time()\n",
    "        for i, (image, _) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "\n",
    "            target = teacher(image, idx)\n",
    "            pred = student(image, idx)\n",
    "\n",
    "            loss = mse_loss(pred, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        e_time = time.time()\n",
    "        history[idx]['train_loss'].append(train_loss/len(train_loader))\n",
    "        history[idx]['train_time'].append(e_time - s_time)\n",
    "\n",
    "        # test step\n",
    "        test_acc = 0.0\n",
    "        student.eval()\n",
    "        s_time = time.time()\n",
    "        for image, target in test_loader:\n",
    "            image = image.to(device)\n",
    "            target = f.one_hot(target, num_class).float().to(device)\n",
    "\n",
    "            pred = student(image)\n",
    "            test_acc += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(target, dim=1)).item()\n",
    "        e_time = time.time()\n",
    "        history[idx]['test_acc'].append(test_acc/len(test_dataset))\n",
    "        history[idx]['test_time'].append(e_time - s_time)\n",
    "        print(f'epoch={ep:d}, train_loss={train_loss/len(train_loader):.4f}, test_acc={test_acc/len(test_dataset):.4f}')\n",
    "\n",
    "        checkpoint = dict(\n",
    "            model=student.state_dict(),\n",
    "            optimizer=optimizer.state_dict(),\n",
    "            history=history,\n",
    "            epoch=ep\n",
    "        )\n",
    "        torch.save(checkpoint, f'./result/{dataset_name}_{student_name}.pt')\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b1785c2d10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "student = CustomResNet(block=ConvBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=num_class).to(device)\n",
    "checkpoint = torch.load(f'./result/{dataset_name}_{student_name}.pt')\n",
    "student.load_state_dict(checkpoint['model'])\n",
    "\n",
    "total_params = sum(p.numel() for p in student.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(student)\n",
    "\n",
    "checkpoint['history'][0]['test_acc']\n",
    "\n",
    "x = np.arange(len(checkpoint['history']))\n",
    "y = list(checkpoint['history'][i]['test_acc'][-1] for i in range(len(checkpoint['history'])))\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
