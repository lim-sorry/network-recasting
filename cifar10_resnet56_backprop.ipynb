{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "from model import CustomResNet, ConvBlock\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import ToTensor, Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "student_name = 'resnet56_backprop'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 128\n",
    "epoch = 360\n",
    "gamma = 0.2\n",
    "milestones = [60, 120, 180, 240, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(size=[32, 32], padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR10(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 415546\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): ConvBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): ConvBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (23): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (24): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (25): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (26): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CustomResNet(block=ConvBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=10).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(params=model.parameters(), lr=0.1, nesterov=True, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0, train_loss=1.8141, test_acc=0.388\n",
      "epoch=  1, train_loss=1.5649, test_acc=0.399\n",
      "epoch=  2, train_loss=1.3506, test_acc=0.512\n",
      "epoch=  3, train_loss=1.1581, test_acc=0.539\n",
      "epoch=  4, train_loss=0.9983, test_acc=0.619\n",
      "epoch=  5, train_loss=0.8915, test_acc=0.627\n",
      "epoch=  6, train_loss=0.8168, test_acc=0.654\n",
      "epoch=  7, train_loss=0.7593, test_acc=0.694\n",
      "epoch=  8, train_loss=0.7205, test_acc=0.716\n",
      "epoch=  9, train_loss=0.6818, test_acc=0.743\n",
      "epoch= 10, train_loss=0.6543, test_acc=0.728\n",
      "epoch= 11, train_loss=0.6323, test_acc=0.749\n",
      "epoch= 12, train_loss=0.6049, test_acc=0.734\n",
      "epoch= 13, train_loss=0.5889, test_acc=0.713\n",
      "epoch= 14, train_loss=0.5735, test_acc=0.709\n",
      "epoch= 15, train_loss=0.5605, test_acc=0.776\n",
      "epoch= 16, train_loss=0.5447, test_acc=0.692\n",
      "epoch= 17, train_loss=0.5291, test_acc=0.614\n",
      "epoch= 18, train_loss=0.5231, test_acc=0.763\n",
      "epoch= 19, train_loss=0.5113, test_acc=0.785\n",
      "epoch= 20, train_loss=0.5001, test_acc=0.732\n",
      "epoch= 21, train_loss=0.4912, test_acc=0.795\n",
      "epoch= 22, train_loss=0.4820, test_acc=0.777\n",
      "epoch= 23, train_loss=0.4776, test_acc=0.714\n",
      "epoch= 24, train_loss=0.4688, test_acc=0.782\n",
      "epoch= 25, train_loss=0.4658, test_acc=0.774\n",
      "epoch= 26, train_loss=0.4588, test_acc=0.810\n",
      "epoch= 27, train_loss=0.4483, test_acc=0.711\n",
      "epoch= 28, train_loss=0.4472, test_acc=0.813\n",
      "epoch= 29, train_loss=0.4423, test_acc=0.785\n",
      "epoch= 30, train_loss=0.4391, test_acc=0.787\n",
      "epoch= 31, train_loss=0.4350, test_acc=0.808\n",
      "epoch= 32, train_loss=0.4296, test_acc=0.772\n",
      "epoch= 33, train_loss=0.4231, test_acc=0.752\n",
      "epoch= 34, train_loss=0.4172, test_acc=0.809\n",
      "epoch= 35, train_loss=0.4182, test_acc=0.698\n",
      "epoch= 36, train_loss=0.4176, test_acc=0.759\n",
      "epoch= 37, train_loss=0.4048, test_acc=0.709\n",
      "epoch= 38, train_loss=0.4022, test_acc=0.787\n",
      "epoch= 39, train_loss=0.4004, test_acc=0.813\n",
      "epoch= 40, train_loss=0.3980, test_acc=0.787\n",
      "epoch= 41, train_loss=0.3978, test_acc=0.793\n",
      "epoch= 42, train_loss=0.3959, test_acc=0.821\n",
      "epoch= 43, train_loss=0.3868, test_acc=0.833\n",
      "epoch= 44, train_loss=0.3809, test_acc=0.825\n",
      "epoch= 45, train_loss=0.3815, test_acc=0.811\n",
      "epoch= 46, train_loss=0.3808, test_acc=0.835\n",
      "epoch= 47, train_loss=0.3795, test_acc=0.809\n",
      "epoch= 48, train_loss=0.3707, test_acc=0.817\n",
      "epoch= 49, train_loss=0.3743, test_acc=0.805\n",
      "epoch= 50, train_loss=0.3752, test_acc=0.837\n",
      "epoch= 51, train_loss=0.3674, test_acc=0.815\n",
      "epoch= 52, train_loss=0.3650, test_acc=0.834\n",
      "epoch= 53, train_loss=0.3670, test_acc=0.805\n",
      "epoch= 54, train_loss=0.3704, test_acc=0.798\n",
      "epoch= 55, train_loss=0.3610, test_acc=0.799\n",
      "epoch= 56, train_loss=0.3573, test_acc=0.792\n",
      "epoch= 57, train_loss=0.3581, test_acc=0.807\n",
      "epoch= 58, train_loss=0.3580, test_acc=0.824\n",
      "epoch= 59, train_loss=0.3587, test_acc=0.829\n",
      "epoch= 60, train_loss=0.2400, test_acc=0.889\n",
      "epoch= 61, train_loss=0.2061, test_acc=0.887\n",
      "epoch= 62, train_loss=0.1951, test_acc=0.889\n",
      "epoch= 63, train_loss=0.1872, test_acc=0.887\n",
      "epoch= 64, train_loss=0.1796, test_acc=0.886\n",
      "epoch= 65, train_loss=0.1777, test_acc=0.888\n",
      "epoch= 66, train_loss=0.1703, test_acc=0.886\n",
      "epoch= 67, train_loss=0.1674, test_acc=0.884\n",
      "epoch= 68, train_loss=0.1633, test_acc=0.887\n",
      "epoch= 69, train_loss=0.1592, test_acc=0.889\n",
      "epoch= 70, train_loss=0.1606, test_acc=0.884\n",
      "epoch= 71, train_loss=0.1569, test_acc=0.889\n",
      "epoch= 72, train_loss=0.1564, test_acc=0.885\n",
      "epoch= 73, train_loss=0.1522, test_acc=0.889\n",
      "epoch= 74, train_loss=0.1493, test_acc=0.890\n",
      "epoch= 75, train_loss=0.1467, test_acc=0.881\n",
      "epoch= 76, train_loss=0.1469, test_acc=0.884\n",
      "epoch= 77, train_loss=0.1492, test_acc=0.890\n",
      "epoch= 78, train_loss=0.1456, test_acc=0.884\n",
      "epoch= 79, train_loss=0.1411, test_acc=0.870\n",
      "epoch= 80, train_loss=0.1461, test_acc=0.886\n",
      "epoch= 81, train_loss=0.1419, test_acc=0.877\n",
      "epoch= 82, train_loss=0.1373, test_acc=0.882\n",
      "epoch= 83, train_loss=0.1372, test_acc=0.873\n",
      "epoch= 84, train_loss=0.1422, test_acc=0.878\n",
      "epoch= 85, train_loss=0.1428, test_acc=0.883\n",
      "epoch= 86, train_loss=0.1372, test_acc=0.883\n",
      "epoch= 87, train_loss=0.1380, test_acc=0.879\n",
      "epoch= 88, train_loss=0.1390, test_acc=0.883\n",
      "epoch= 89, train_loss=0.1361, test_acc=0.879\n",
      "epoch= 90, train_loss=0.1350, test_acc=0.884\n",
      "epoch= 91, train_loss=0.1354, test_acc=0.883\n",
      "epoch= 92, train_loss=0.1372, test_acc=0.882\n",
      "epoch= 93, train_loss=0.1377, test_acc=0.879\n",
      "epoch= 94, train_loss=0.1354, test_acc=0.879\n",
      "epoch= 95, train_loss=0.1325, test_acc=0.870\n",
      "epoch= 96, train_loss=0.1349, test_acc=0.862\n",
      "epoch= 97, train_loss=0.1359, test_acc=0.882\n",
      "epoch= 98, train_loss=0.1353, test_acc=0.876\n",
      "epoch= 99, train_loss=0.1376, test_acc=0.876\n",
      "epoch=100, train_loss=0.1337, test_acc=0.881\n",
      "epoch=101, train_loss=0.1340, test_acc=0.880\n",
      "epoch=102, train_loss=0.1342, test_acc=0.881\n",
      "epoch=103, train_loss=0.1353, test_acc=0.867\n",
      "epoch=104, train_loss=0.1343, test_acc=0.878\n",
      "epoch=105, train_loss=0.1351, test_acc=0.855\n",
      "epoch=106, train_loss=0.1338, test_acc=0.881\n",
      "epoch=107, train_loss=0.1352, test_acc=0.874\n",
      "epoch=108, train_loss=0.1288, test_acc=0.880\n",
      "epoch=109, train_loss=0.1331, test_acc=0.883\n",
      "epoch=110, train_loss=0.1341, test_acc=0.878\n",
      "epoch=111, train_loss=0.1295, test_acc=0.871\n",
      "epoch=112, train_loss=0.1328, test_acc=0.880\n",
      "epoch=113, train_loss=0.1329, test_acc=0.881\n",
      "epoch=114, train_loss=0.1313, test_acc=0.868\n",
      "epoch=115, train_loss=0.1352, test_acc=0.877\n",
      "epoch=116, train_loss=0.1312, test_acc=0.870\n",
      "epoch=117, train_loss=0.1266, test_acc=0.864\n",
      "epoch=118, train_loss=0.1295, test_acc=0.878\n",
      "epoch=119, train_loss=0.1312, test_acc=0.854\n",
      "epoch=120, train_loss=0.0803, test_acc=0.896\n",
      "epoch=121, train_loss=0.0622, test_acc=0.894\n",
      "epoch=122, train_loss=0.0559, test_acc=0.898\n",
      "epoch=123, train_loss=0.0531, test_acc=0.896\n",
      "epoch=124, train_loss=0.0486, test_acc=0.896\n",
      "epoch=125, train_loss=0.0465, test_acc=0.897\n",
      "epoch=126, train_loss=0.0431, test_acc=0.897\n",
      "epoch=127, train_loss=0.0431, test_acc=0.897\n",
      "epoch=128, train_loss=0.0395, test_acc=0.896\n",
      "epoch=129, train_loss=0.0404, test_acc=0.895\n",
      "epoch=130, train_loss=0.0394, test_acc=0.895\n",
      "epoch=131, train_loss=0.0368, test_acc=0.896\n",
      "epoch=132, train_loss=0.0350, test_acc=0.898\n",
      "epoch=133, train_loss=0.0380, test_acc=0.896\n",
      "epoch=134, train_loss=0.0360, test_acc=0.897\n",
      "epoch=135, train_loss=0.0363, test_acc=0.898\n",
      "epoch=136, train_loss=0.0339, test_acc=0.899\n",
      "epoch=137, train_loss=0.0334, test_acc=0.899\n",
      "epoch=138, train_loss=0.0335, test_acc=0.898\n",
      "epoch=139, train_loss=0.0324, test_acc=0.898\n",
      "epoch=140, train_loss=0.0297, test_acc=0.895\n",
      "epoch=141, train_loss=0.0315, test_acc=0.899\n",
      "epoch=142, train_loss=0.0314, test_acc=0.896\n",
      "epoch=143, train_loss=0.0316, test_acc=0.898\n",
      "epoch=144, train_loss=0.0305, test_acc=0.899\n",
      "epoch=145, train_loss=0.0304, test_acc=0.899\n",
      "epoch=146, train_loss=0.0320, test_acc=0.898\n",
      "epoch=147, train_loss=0.0300, test_acc=0.898\n",
      "epoch=148, train_loss=0.0306, test_acc=0.899\n",
      "epoch=149, train_loss=0.0291, test_acc=0.898\n",
      "epoch=150, train_loss=0.0285, test_acc=0.897\n",
      "epoch=151, train_loss=0.0266, test_acc=0.898\n",
      "epoch=152, train_loss=0.0263, test_acc=0.899\n",
      "epoch=153, train_loss=0.0281, test_acc=0.896\n",
      "epoch=154, train_loss=0.0293, test_acc=0.896\n",
      "epoch=155, train_loss=0.0268, test_acc=0.893\n",
      "epoch=156, train_loss=0.0274, test_acc=0.893\n",
      "epoch=157, train_loss=0.0280, test_acc=0.897\n",
      "epoch=158, train_loss=0.0274, test_acc=0.897\n",
      "epoch=159, train_loss=0.0242, test_acc=0.894\n",
      "epoch=160, train_loss=0.0251, test_acc=0.896\n",
      "epoch=161, train_loss=0.0273, test_acc=0.895\n",
      "epoch=162, train_loss=0.0252, test_acc=0.897\n",
      "epoch=163, train_loss=0.0260, test_acc=0.894\n",
      "epoch=164, train_loss=0.0251, test_acc=0.899\n",
      "epoch=165, train_loss=0.0269, test_acc=0.893\n",
      "epoch=166, train_loss=0.0262, test_acc=0.896\n",
      "epoch=167, train_loss=0.0273, test_acc=0.893\n",
      "epoch=168, train_loss=0.0265, test_acc=0.894\n",
      "epoch=169, train_loss=0.0245, test_acc=0.893\n",
      "epoch=170, train_loss=0.0243, test_acc=0.894\n",
      "epoch=171, train_loss=0.0263, test_acc=0.894\n",
      "epoch=172, train_loss=0.0259, test_acc=0.892\n",
      "epoch=173, train_loss=0.0243, test_acc=0.892\n",
      "epoch=174, train_loss=0.0261, test_acc=0.893\n",
      "epoch=175, train_loss=0.0252, test_acc=0.896\n",
      "epoch=176, train_loss=0.0222, test_acc=0.894\n",
      "epoch=177, train_loss=0.0245, test_acc=0.895\n",
      "epoch=178, train_loss=0.0261, test_acc=0.894\n",
      "epoch=179, train_loss=0.0243, test_acc=0.894\n",
      "epoch=180, train_loss=0.0200, test_acc=0.897\n",
      "epoch=181, train_loss=0.0171, test_acc=0.898\n",
      "epoch=182, train_loss=0.0168, test_acc=0.898\n",
      "epoch=183, train_loss=0.0156, test_acc=0.899\n",
      "epoch=184, train_loss=0.0147, test_acc=0.899\n",
      "epoch=185, train_loss=0.0153, test_acc=0.900\n",
      "epoch=186, train_loss=0.0143, test_acc=0.901\n",
      "epoch=187, train_loss=0.0141, test_acc=0.900\n",
      "epoch=188, train_loss=0.0135, test_acc=0.901\n",
      "epoch=189, train_loss=0.0131, test_acc=0.900\n",
      "epoch=190, train_loss=0.0140, test_acc=0.900\n",
      "epoch=191, train_loss=0.0140, test_acc=0.901\n",
      "epoch=192, train_loss=0.0132, test_acc=0.900\n",
      "epoch=193, train_loss=0.0130, test_acc=0.899\n",
      "epoch=194, train_loss=0.0128, test_acc=0.900\n",
      "epoch=195, train_loss=0.0135, test_acc=0.900\n",
      "epoch=196, train_loss=0.0133, test_acc=0.900\n",
      "epoch=197, train_loss=0.0126, test_acc=0.901\n",
      "epoch=198, train_loss=0.0114, test_acc=0.900\n",
      "epoch=199, train_loss=0.0119, test_acc=0.903\n",
      "epoch=200, train_loss=0.0124, test_acc=0.900\n",
      "epoch=201, train_loss=0.0133, test_acc=0.900\n",
      "epoch=202, train_loss=0.0125, test_acc=0.900\n",
      "epoch=203, train_loss=0.0119, test_acc=0.900\n",
      "epoch=204, train_loss=0.0125, test_acc=0.900\n",
      "epoch=205, train_loss=0.0123, test_acc=0.900\n",
      "epoch=206, train_loss=0.0118, test_acc=0.900\n",
      "epoch=207, train_loss=0.0121, test_acc=0.899\n",
      "epoch=208, train_loss=0.0118, test_acc=0.900\n",
      "epoch=209, train_loss=0.0111, test_acc=0.899\n",
      "epoch=210, train_loss=0.0107, test_acc=0.897\n",
      "epoch=211, train_loss=0.0119, test_acc=0.899\n",
      "epoch=212, train_loss=0.0111, test_acc=0.901\n",
      "epoch=213, train_loss=0.0106, test_acc=0.900\n",
      "epoch=214, train_loss=0.0115, test_acc=0.899\n",
      "epoch=215, train_loss=0.0111, test_acc=0.901\n",
      "epoch=216, train_loss=0.0110, test_acc=0.898\n",
      "epoch=217, train_loss=0.0106, test_acc=0.900\n",
      "epoch=218, train_loss=0.0104, test_acc=0.898\n",
      "epoch=219, train_loss=0.0111, test_acc=0.900\n",
      "epoch=220, train_loss=0.0108, test_acc=0.898\n",
      "epoch=221, train_loss=0.0105, test_acc=0.900\n",
      "epoch=222, train_loss=0.0106, test_acc=0.897\n",
      "epoch=223, train_loss=0.0102, test_acc=0.899\n",
      "epoch=224, train_loss=0.0112, test_acc=0.898\n",
      "epoch=225, train_loss=0.0115, test_acc=0.898\n",
      "epoch=226, train_loss=0.0111, test_acc=0.900\n",
      "epoch=227, train_loss=0.0111, test_acc=0.899\n",
      "epoch=228, train_loss=0.0107, test_acc=0.901\n",
      "epoch=229, train_loss=0.0105, test_acc=0.897\n",
      "epoch=230, train_loss=0.0094, test_acc=0.899\n",
      "epoch=231, train_loss=0.0098, test_acc=0.899\n",
      "epoch=232, train_loss=0.0101, test_acc=0.898\n",
      "epoch=233, train_loss=0.0104, test_acc=0.899\n",
      "epoch=234, train_loss=0.0107, test_acc=0.898\n",
      "epoch=235, train_loss=0.0101, test_acc=0.897\n",
      "epoch=236, train_loss=0.0101, test_acc=0.899\n",
      "epoch=237, train_loss=0.0100, test_acc=0.899\n",
      "epoch=238, train_loss=0.0107, test_acc=0.900\n",
      "epoch=239, train_loss=0.0098, test_acc=0.897\n",
      "epoch=240, train_loss=0.0106, test_acc=0.898\n",
      "epoch=241, train_loss=0.0096, test_acc=0.898\n",
      "epoch=242, train_loss=0.0098, test_acc=0.898\n",
      "epoch=243, train_loss=0.0104, test_acc=0.899\n",
      "epoch=244, train_loss=0.0091, test_acc=0.898\n",
      "epoch=245, train_loss=0.0098, test_acc=0.898\n",
      "epoch=246, train_loss=0.0092, test_acc=0.899\n",
      "epoch=247, train_loss=0.0100, test_acc=0.899\n",
      "epoch=248, train_loss=0.0094, test_acc=0.898\n",
      "epoch=249, train_loss=0.0105, test_acc=0.899\n",
      "epoch=250, train_loss=0.0087, test_acc=0.899\n",
      "epoch=251, train_loss=0.0097, test_acc=0.900\n",
      "epoch=252, train_loss=0.0099, test_acc=0.899\n",
      "epoch=253, train_loss=0.0097, test_acc=0.898\n",
      "epoch=254, train_loss=0.0090, test_acc=0.899\n",
      "epoch=255, train_loss=0.0091, test_acc=0.899\n",
      "epoch=256, train_loss=0.0098, test_acc=0.898\n",
      "epoch=257, train_loss=0.0093, test_acc=0.899\n",
      "epoch=258, train_loss=0.0093, test_acc=0.898\n",
      "epoch=259, train_loss=0.0088, test_acc=0.898\n",
      "epoch=260, train_loss=0.0090, test_acc=0.898\n",
      "epoch=261, train_loss=0.0097, test_acc=0.900\n",
      "epoch=262, train_loss=0.0099, test_acc=0.898\n",
      "epoch=263, train_loss=0.0092, test_acc=0.898\n",
      "epoch=264, train_loss=0.0088, test_acc=0.898\n",
      "epoch=265, train_loss=0.0079, test_acc=0.898\n",
      "epoch=266, train_loss=0.0087, test_acc=0.899\n",
      "epoch=267, train_loss=0.0093, test_acc=0.899\n",
      "epoch=268, train_loss=0.0087, test_acc=0.899\n",
      "epoch=269, train_loss=0.0093, test_acc=0.899\n",
      "epoch=270, train_loss=0.0090, test_acc=0.899\n",
      "epoch=271, train_loss=0.0090, test_acc=0.899\n",
      "epoch=272, train_loss=0.0093, test_acc=0.899\n",
      "epoch=273, train_loss=0.0088, test_acc=0.899\n",
      "epoch=274, train_loss=0.0092, test_acc=0.899\n",
      "epoch=275, train_loss=0.0087, test_acc=0.898\n",
      "epoch=276, train_loss=0.0081, test_acc=0.899\n",
      "epoch=277, train_loss=0.0082, test_acc=0.898\n",
      "epoch=278, train_loss=0.0093, test_acc=0.898\n",
      "epoch=279, train_loss=0.0084, test_acc=0.899\n",
      "epoch=280, train_loss=0.0091, test_acc=0.899\n",
      "epoch=281, train_loss=0.0085, test_acc=0.899\n",
      "epoch=282, train_loss=0.0090, test_acc=0.899\n",
      "epoch=283, train_loss=0.0091, test_acc=0.899\n",
      "epoch=284, train_loss=0.0088, test_acc=0.898\n",
      "epoch=285, train_loss=0.0089, test_acc=0.899\n",
      "epoch=286, train_loss=0.0094, test_acc=0.899\n",
      "epoch=287, train_loss=0.0092, test_acc=0.900\n",
      "epoch=288, train_loss=0.0086, test_acc=0.899\n",
      "epoch=289, train_loss=0.0091, test_acc=0.899\n",
      "epoch=290, train_loss=0.0090, test_acc=0.899\n",
      "epoch=291, train_loss=0.0089, test_acc=0.899\n",
      "epoch=292, train_loss=0.0091, test_acc=0.899\n",
      "epoch=293, train_loss=0.0087, test_acc=0.899\n",
      "epoch=294, train_loss=0.0085, test_acc=0.900\n",
      "epoch=295, train_loss=0.0086, test_acc=0.899\n",
      "epoch=296, train_loss=0.0088, test_acc=0.897\n",
      "epoch=297, train_loss=0.0092, test_acc=0.899\n",
      "epoch=298, train_loss=0.0099, test_acc=0.900\n",
      "epoch=299, train_loss=0.0087, test_acc=0.899\n",
      "epoch=300, train_loss=0.0086, test_acc=0.899\n",
      "epoch=301, train_loss=0.0089, test_acc=0.899\n",
      "epoch=302, train_loss=0.0082, test_acc=0.900\n",
      "epoch=303, train_loss=0.0085, test_acc=0.898\n",
      "epoch=304, train_loss=0.0088, test_acc=0.899\n",
      "epoch=305, train_loss=0.0085, test_acc=0.899\n",
      "epoch=306, train_loss=0.0090, test_acc=0.898\n",
      "epoch=307, train_loss=0.0089, test_acc=0.899\n",
      "epoch=308, train_loss=0.0092, test_acc=0.899\n",
      "epoch=309, train_loss=0.0084, test_acc=0.899\n",
      "epoch=310, train_loss=0.0084, test_acc=0.899\n",
      "epoch=311, train_loss=0.0081, test_acc=0.899\n",
      "epoch=312, train_loss=0.0086, test_acc=0.900\n",
      "epoch=313, train_loss=0.0089, test_acc=0.899\n",
      "epoch=314, train_loss=0.0082, test_acc=0.899\n",
      "epoch=315, train_loss=0.0085, test_acc=0.899\n",
      "epoch=316, train_loss=0.0078, test_acc=0.897\n",
      "epoch=317, train_loss=0.0092, test_acc=0.899\n",
      "epoch=318, train_loss=0.0082, test_acc=0.900\n",
      "epoch=319, train_loss=0.0085, test_acc=0.899\n",
      "epoch=320, train_loss=0.0081, test_acc=0.898\n",
      "epoch=321, train_loss=0.0084, test_acc=0.899\n",
      "epoch=322, train_loss=0.0081, test_acc=0.900\n",
      "epoch=323, train_loss=0.0078, test_acc=0.899\n",
      "epoch=324, train_loss=0.0090, test_acc=0.899\n",
      "epoch=325, train_loss=0.0087, test_acc=0.899\n",
      "epoch=326, train_loss=0.0092, test_acc=0.898\n",
      "epoch=327, train_loss=0.0091, test_acc=0.899\n",
      "epoch=328, train_loss=0.0086, test_acc=0.900\n",
      "epoch=329, train_loss=0.0086, test_acc=0.899\n",
      "epoch=330, train_loss=0.0088, test_acc=0.899\n",
      "epoch=331, train_loss=0.0083, test_acc=0.899\n",
      "epoch=332, train_loss=0.0082, test_acc=0.899\n",
      "epoch=333, train_loss=0.0085, test_acc=0.899\n",
      "epoch=334, train_loss=0.0090, test_acc=0.898\n",
      "epoch=335, train_loss=0.0083, test_acc=0.899\n",
      "epoch=336, train_loss=0.0086, test_acc=0.900\n",
      "epoch=337, train_loss=0.0082, test_acc=0.899\n",
      "epoch=338, train_loss=0.0091, test_acc=0.899\n",
      "epoch=339, train_loss=0.0088, test_acc=0.899\n",
      "epoch=340, train_loss=0.0089, test_acc=0.899\n",
      "epoch=341, train_loss=0.0085, test_acc=0.899\n",
      "epoch=342, train_loss=0.0080, test_acc=0.899\n",
      "epoch=343, train_loss=0.0084, test_acc=0.900\n",
      "epoch=344, train_loss=0.0082, test_acc=0.899\n",
      "epoch=345, train_loss=0.0090, test_acc=0.899\n",
      "epoch=346, train_loss=0.0083, test_acc=0.899\n",
      "epoch=347, train_loss=0.0079, test_acc=0.899\n",
      "epoch=348, train_loss=0.0079, test_acc=0.898\n",
      "epoch=349, train_loss=0.0082, test_acc=0.899\n",
      "epoch=350, train_loss=0.0076, test_acc=0.899\n",
      "epoch=351, train_loss=0.0083, test_acc=0.899\n",
      "epoch=352, train_loss=0.0079, test_acc=0.899\n",
      "epoch=353, train_loss=0.0082, test_acc=0.899\n",
      "epoch=354, train_loss=0.0089, test_acc=0.899\n",
      "epoch=355, train_loss=0.0088, test_acc=0.900\n",
      "epoch=356, train_loss=0.0083, test_acc=0.899\n",
      "epoch=357, train_loss=0.0089, test_acc=0.899\n",
      "epoch=358, train_loss=0.0088, test_acc=0.898\n",
      "epoch=359, train_loss=0.0087, test_acc=0.898\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], test_acc=[], train_time=[], test_time=[])\n",
    "for ep in range(epoch):\n",
    "    # train step\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    s_time = time.time()\n",
    "    for image, target in train_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, 10).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    e_time = time.time()\n",
    "    history['train_loss'].append(train_loss/len(train_loader))\n",
    "    history['train_time'].append(e_time - s_time)\n",
    "\n",
    "    # test step\n",
    "    test_acc = 0.0\n",
    "    model.eval()\n",
    "    s_time = time.time()\n",
    "    for image, target in test_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, 10).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        test_acc += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(target, dim=1)).item()\n",
    "    e_time = time.time()\n",
    "    history['test_acc'].append(test_acc/len(test_dataset))\n",
    "    history['test_time'].append(e_time - s_time)\n",
    "    print(f'epoch={ep:3d}, train_loss={train_loss/len(train_loader):.4f}, test_acc={test_acc/len(test_dataset):.3f}')\n",
    "\n",
    "    checkpoint = dict(\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "        history=history,\n",
    "        epoch=ep\n",
    "    )\n",
    "    torch.save(checkpoint, f'./result/{dataset_name}_{student_name}.pt')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
