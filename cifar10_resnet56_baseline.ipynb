{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "from model import CustomResNet\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import ToTensor, Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "student_name = 'resnet56_baseline'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 128\n",
    "epoch = 180\n",
    "gamma = 0.2\n",
    "milestones = [60, 120, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(size=[32, 32], padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR10(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 855770\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (24): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (25): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (27): FCBlock(\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CustomResNet(block=BasicBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=10).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(params=model.parameters(), lr=0.1, nesterov=True, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=gamma)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0, train_loss=2.1335, test_acc=0.306\n",
      "epoch=  1, train_loss=1.7103, test_acc=0.412\n",
      "epoch=  2, train_loss=1.4934, test_acc=0.485\n",
      "epoch=  3, train_loss=1.2722, test_acc=0.563\n",
      "epoch=  4, train_loss=1.0840, test_acc=0.630\n",
      "epoch=  5, train_loss=0.9232, test_acc=0.692\n",
      "epoch=  6, train_loss=0.7970, test_acc=0.644\n",
      "epoch=  7, train_loss=0.7057, test_acc=0.753\n",
      "epoch=  8, train_loss=0.6418, test_acc=0.763\n",
      "epoch=  9, train_loss=0.5888, test_acc=0.766\n",
      "epoch= 10, train_loss=0.5534, test_acc=0.793\n",
      "epoch= 11, train_loss=0.5189, test_acc=0.775\n",
      "epoch= 12, train_loss=0.4930, test_acc=0.766\n",
      "epoch= 13, train_loss=0.4690, test_acc=0.777\n",
      "epoch= 14, train_loss=0.4444, test_acc=0.825\n",
      "epoch= 15, train_loss=0.4287, test_acc=0.830\n",
      "epoch= 16, train_loss=0.4172, test_acc=0.828\n",
      "epoch= 17, train_loss=0.3969, test_acc=0.826\n",
      "epoch= 18, train_loss=0.3802, test_acc=0.839\n",
      "epoch= 19, train_loss=0.3707, test_acc=0.853\n",
      "epoch= 20, train_loss=0.3616, test_acc=0.843\n",
      "epoch= 21, train_loss=0.3476, test_acc=0.824\n",
      "epoch= 22, train_loss=0.3379, test_acc=0.831\n",
      "epoch= 23, train_loss=0.3328, test_acc=0.839\n",
      "epoch= 24, train_loss=0.3184, test_acc=0.836\n",
      "epoch= 25, train_loss=0.3152, test_acc=0.850\n",
      "epoch= 26, train_loss=0.3034, test_acc=0.848\n",
      "epoch= 27, train_loss=0.3013, test_acc=0.852\n",
      "epoch= 28, train_loss=0.2968, test_acc=0.831\n",
      "epoch= 29, train_loss=0.2864, test_acc=0.852\n",
      "epoch= 30, train_loss=0.2825, test_acc=0.854\n",
      "epoch= 31, train_loss=0.2744, test_acc=0.862\n",
      "epoch= 32, train_loss=0.2736, test_acc=0.859\n",
      "epoch= 33, train_loss=0.2657, test_acc=0.858\n",
      "epoch= 34, train_loss=0.2608, test_acc=0.849\n",
      "epoch= 35, train_loss=0.2558, test_acc=0.848\n",
      "epoch= 36, train_loss=0.2551, test_acc=0.852\n",
      "epoch= 37, train_loss=0.2486, test_acc=0.867\n",
      "epoch= 38, train_loss=0.2429, test_acc=0.856\n",
      "epoch= 39, train_loss=0.2399, test_acc=0.854\n",
      "epoch= 40, train_loss=0.2391, test_acc=0.859\n",
      "epoch= 41, train_loss=0.2352, test_acc=0.863\n",
      "epoch= 42, train_loss=0.2315, test_acc=0.861\n",
      "epoch= 43, train_loss=0.2278, test_acc=0.864\n",
      "epoch= 44, train_loss=0.2256, test_acc=0.859\n",
      "epoch= 45, train_loss=0.2229, test_acc=0.845\n",
      "epoch= 46, train_loss=0.2204, test_acc=0.879\n",
      "epoch= 47, train_loss=0.2130, test_acc=0.867\n",
      "epoch= 48, train_loss=0.2166, test_acc=0.878\n",
      "epoch= 49, train_loss=0.2118, test_acc=0.867\n",
      "epoch= 50, train_loss=0.2021, test_acc=0.879\n",
      "epoch= 51, train_loss=0.2073, test_acc=0.855\n",
      "epoch= 52, train_loss=0.2068, test_acc=0.873\n",
      "epoch= 53, train_loss=0.2030, test_acc=0.880\n",
      "epoch= 54, train_loss=0.2021, test_acc=0.872\n",
      "epoch= 55, train_loss=0.2042, test_acc=0.851\n",
      "epoch= 56, train_loss=0.2006, test_acc=0.859\n",
      "epoch= 57, train_loss=0.1948, test_acc=0.874\n",
      "epoch= 58, train_loss=0.1955, test_acc=0.873\n",
      "epoch= 59, train_loss=0.1879, test_acc=0.883\n",
      "epoch= 60, train_loss=0.1057, test_acc=0.918\n",
      "epoch= 61, train_loss=0.0732, test_acc=0.917\n",
      "epoch= 62, train_loss=0.0641, test_acc=0.920\n",
      "epoch= 63, train_loss=0.0553, test_acc=0.919\n",
      "epoch= 64, train_loss=0.0501, test_acc=0.920\n",
      "epoch= 65, train_loss=0.0468, test_acc=0.921\n",
      "epoch= 66, train_loss=0.0433, test_acc=0.920\n",
      "epoch= 67, train_loss=0.0411, test_acc=0.920\n",
      "epoch= 68, train_loss=0.0382, test_acc=0.918\n",
      "epoch= 69, train_loss=0.0348, test_acc=0.917\n",
      "epoch= 70, train_loss=0.0346, test_acc=0.920\n",
      "epoch= 71, train_loss=0.0338, test_acc=0.917\n",
      "epoch= 72, train_loss=0.0306, test_acc=0.919\n",
      "epoch= 73, train_loss=0.0316, test_acc=0.918\n",
      "epoch= 74, train_loss=0.0304, test_acc=0.919\n",
      "epoch= 75, train_loss=0.0298, test_acc=0.919\n",
      "epoch= 76, train_loss=0.0282, test_acc=0.918\n",
      "epoch= 77, train_loss=0.0282, test_acc=0.917\n",
      "epoch= 78, train_loss=0.0272, test_acc=0.919\n",
      "epoch= 79, train_loss=0.0251, test_acc=0.918\n",
      "epoch= 80, train_loss=0.0265, test_acc=0.916\n",
      "epoch= 81, train_loss=0.0271, test_acc=0.913\n",
      "epoch= 82, train_loss=0.0274, test_acc=0.920\n",
      "epoch= 83, train_loss=0.0256, test_acc=0.918\n",
      "epoch= 84, train_loss=0.0256, test_acc=0.920\n",
      "epoch= 85, train_loss=0.0261, test_acc=0.915\n",
      "epoch= 86, train_loss=0.0267, test_acc=0.915\n",
      "epoch= 87, train_loss=0.0271, test_acc=0.917\n",
      "epoch= 88, train_loss=0.0263, test_acc=0.916\n",
      "epoch= 89, train_loss=0.0285, test_acc=0.918\n",
      "epoch= 90, train_loss=0.0288, test_acc=0.916\n",
      "epoch= 91, train_loss=0.0279, test_acc=0.918\n",
      "epoch= 92, train_loss=0.0290, test_acc=0.915\n",
      "epoch= 93, train_loss=0.0292, test_acc=0.916\n",
      "epoch= 94, train_loss=0.0302, test_acc=0.914\n",
      "epoch= 95, train_loss=0.0290, test_acc=0.912\n",
      "epoch= 96, train_loss=0.0316, test_acc=0.915\n",
      "epoch= 97, train_loss=0.0296, test_acc=0.918\n",
      "epoch= 98, train_loss=0.0266, test_acc=0.917\n",
      "epoch= 99, train_loss=0.0264, test_acc=0.915\n",
      "epoch=100, train_loss=0.0320, test_acc=0.912\n",
      "epoch=101, train_loss=0.0279, test_acc=0.910\n",
      "epoch=102, train_loss=0.0297, test_acc=0.913\n",
      "epoch=103, train_loss=0.0298, test_acc=0.911\n",
      "epoch=104, train_loss=0.0280, test_acc=0.908\n",
      "epoch=105, train_loss=0.0331, test_acc=0.914\n",
      "epoch=106, train_loss=0.0315, test_acc=0.913\n",
      "epoch=107, train_loss=0.0314, test_acc=0.909\n",
      "epoch=108, train_loss=0.0291, test_acc=0.913\n",
      "epoch=109, train_loss=0.0330, test_acc=0.916\n",
      "epoch=110, train_loss=0.0366, test_acc=0.914\n",
      "epoch=111, train_loss=0.0321, test_acc=0.917\n",
      "epoch=112, train_loss=0.0334, test_acc=0.919\n",
      "epoch=113, train_loss=0.0349, test_acc=0.917\n",
      "epoch=114, train_loss=0.0368, test_acc=0.909\n",
      "epoch=115, train_loss=0.0331, test_acc=0.913\n",
      "epoch=116, train_loss=0.0362, test_acc=0.909\n",
      "epoch=117, train_loss=0.0325, test_acc=0.915\n",
      "epoch=118, train_loss=0.0340, test_acc=0.909\n",
      "epoch=119, train_loss=0.0391, test_acc=0.913\n",
      "epoch=120, train_loss=0.0188, test_acc=0.923\n",
      "epoch=121, train_loss=0.0120, test_acc=0.925\n",
      "epoch=122, train_loss=0.0100, test_acc=0.927\n",
      "epoch=123, train_loss=0.0078, test_acc=0.929\n",
      "epoch=124, train_loss=0.0077, test_acc=0.927\n",
      "epoch=125, train_loss=0.0067, test_acc=0.927\n",
      "epoch=126, train_loss=0.0059, test_acc=0.928\n",
      "epoch=127, train_loss=0.0062, test_acc=0.928\n",
      "epoch=128, train_loss=0.0053, test_acc=0.928\n",
      "epoch=129, train_loss=0.0054, test_acc=0.928\n",
      "epoch=130, train_loss=0.0051, test_acc=0.928\n",
      "epoch=131, train_loss=0.0050, test_acc=0.928\n",
      "epoch=132, train_loss=0.0046, test_acc=0.929\n",
      "epoch=133, train_loss=0.0042, test_acc=0.928\n",
      "epoch=134, train_loss=0.0039, test_acc=0.927\n",
      "epoch=135, train_loss=0.0040, test_acc=0.930\n",
      "epoch=136, train_loss=0.0037, test_acc=0.928\n",
      "epoch=137, train_loss=0.0041, test_acc=0.929\n",
      "epoch=138, train_loss=0.0041, test_acc=0.928\n",
      "epoch=139, train_loss=0.0038, test_acc=0.928\n",
      "epoch=140, train_loss=0.0036, test_acc=0.929\n",
      "epoch=141, train_loss=0.0033, test_acc=0.928\n",
      "epoch=142, train_loss=0.0037, test_acc=0.928\n",
      "epoch=143, train_loss=0.0034, test_acc=0.928\n",
      "epoch=144, train_loss=0.0033, test_acc=0.929\n",
      "epoch=145, train_loss=0.0032, test_acc=0.930\n",
      "epoch=146, train_loss=0.0031, test_acc=0.929\n",
      "epoch=147, train_loss=0.0034, test_acc=0.929\n",
      "epoch=148, train_loss=0.0029, test_acc=0.930\n",
      "epoch=149, train_loss=0.0031, test_acc=0.930\n",
      "epoch=150, train_loss=0.0034, test_acc=0.930\n",
      "epoch=151, train_loss=0.0029, test_acc=0.930\n",
      "epoch=152, train_loss=0.0027, test_acc=0.929\n",
      "epoch=153, train_loss=0.0027, test_acc=0.929\n",
      "epoch=154, train_loss=0.0027, test_acc=0.929\n",
      "epoch=155, train_loss=0.0026, test_acc=0.930\n",
      "epoch=156, train_loss=0.0025, test_acc=0.930\n",
      "epoch=157, train_loss=0.0025, test_acc=0.930\n",
      "epoch=158, train_loss=0.0024, test_acc=0.930\n",
      "epoch=159, train_loss=0.0024, test_acc=0.930\n",
      "epoch=160, train_loss=0.0026, test_acc=0.929\n",
      "epoch=161, train_loss=0.0024, test_acc=0.930\n",
      "epoch=162, train_loss=0.0024, test_acc=0.930\n",
      "epoch=163, train_loss=0.0024, test_acc=0.930\n",
      "epoch=164, train_loss=0.0023, test_acc=0.930\n",
      "epoch=165, train_loss=0.0024, test_acc=0.930\n",
      "epoch=166, train_loss=0.0023, test_acc=0.929\n",
      "epoch=167, train_loss=0.0022, test_acc=0.929\n",
      "epoch=168, train_loss=0.0023, test_acc=0.929\n",
      "epoch=169, train_loss=0.0024, test_acc=0.930\n",
      "epoch=170, train_loss=0.0022, test_acc=0.930\n",
      "epoch=171, train_loss=0.0022, test_acc=0.929\n",
      "epoch=172, train_loss=0.0022, test_acc=0.930\n",
      "epoch=173, train_loss=0.0022, test_acc=0.930\n",
      "epoch=174, train_loss=0.0023, test_acc=0.929\n",
      "epoch=175, train_loss=0.0021, test_acc=0.930\n",
      "epoch=176, train_loss=0.0021, test_acc=0.929\n",
      "epoch=177, train_loss=0.0021, test_acc=0.930\n",
      "epoch=178, train_loss=0.0021, test_acc=0.930\n",
      "epoch=179, train_loss=0.0022, test_acc=0.930\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], test_acc=[], train_time=[], test_time=[])\n",
    "for ep in range(epoch):\n",
    "    # train step\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    s_time = time.time()\n",
    "    for image, target in train_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, 10).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        loss = criterion(pred, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    e_time = time.time()\n",
    "    history['train_loss'].append(train_loss/len(train_loader))\n",
    "    history['train_time'].append(e_time - s_time)\n",
    "\n",
    "    # test step\n",
    "    test_acc = 0.0\n",
    "    model.eval()\n",
    "    s_time = time.time()\n",
    "    for image, target in test_loader:\n",
    "        image = image.to(device)\n",
    "        target = f.one_hot(target, 10).float().to(device)\n",
    "\n",
    "        pred = model(image)\n",
    "        test_acc += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(target, dim=1)).item()\n",
    "    e_time = time.time()\n",
    "    history['test_acc'].append(test_acc/len(test_dataset))\n",
    "    history['test_time'].append(e_time - s_time)\n",
    "    print(f'epoch={ep:3d}, train_loss={train_loss/len(train_loader):.4f}, test_acc={test_acc/len(test_dataset):.3f}')\n",
    "\n",
    "    checkpoint = dict(\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "        history=history,\n",
    "        epoch=ep\n",
    "    )\n",
    "    torch.save(checkpoint, f'./result/{dataset_name}_{student_name}.pt')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4625.111322402954"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./result/cifar10_resnet56_baseline.pt')\n",
    "sum(checkpoint['history']['train_time']) + sum(checkpoint['history']['test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033.6733675003052, 185.7128963470459)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(f'./result/cifar10_resnet56_recast.pt')\n",
    "sum(checkpoint['history'][0]['train_time']), sum(checkpoint['history'][0]['test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ConvBlock\n",
    "student_name = 'resnet56_recast'\n",
    "\n",
    "model = CustomResNet(block=BasicBlock,\n",
    "                layers=[9, 9, 9],\n",
    "                num_classes=10).to(device).eval()\n",
    "model.layers[0] = ConvBlock(16,16,2)\n",
    "state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layers.0.conv1.weight', 'layers.0.bn1.weight', 'layers.0.bn1.bias', 'layers.0.bn1.running_mean', 'layers.0.bn1.running_var', 'layers.0.bn1.num_batches_tracked', 'layers.1.conv1.weight', 'layers.1.bn1.weight', 'layers.1.bn1.bias', 'layers.1.bn1.running_mean', 'layers.1.bn1.running_var', 'layers.1.bn1.num_batches_tracked', 'layers.1.conv2.weight', 'layers.1.bn2.weight', 'layers.1.bn2.bias', 'layers.1.bn2.running_mean', 'layers.1.bn2.running_var', 'layers.1.bn2.num_batches_tracked', 'layers.2.conv1.weight', 'layers.2.bn1.weight', 'layers.2.bn1.bias', 'layers.2.bn1.running_mean', 'layers.2.bn1.running_var', 'layers.2.bn1.num_batches_tracked', 'layers.2.conv2.weight', 'layers.2.bn2.weight', 'layers.2.bn2.bias', 'layers.2.bn2.running_mean', 'layers.2.bn2.running_var', 'layers.2.bn2.num_batches_tracked', 'layers.3.conv1.weight', 'layers.3.bn1.weight', 'layers.3.bn1.bias', 'layers.3.bn1.running_mean', 'layers.3.bn1.running_var', 'layers.3.bn1.num_batches_tracked', 'layers.3.conv2.weight', 'layers.3.bn2.weight', 'layers.3.bn2.bias', 'layers.3.bn2.running_mean', 'layers.3.bn2.running_var', 'layers.3.bn2.num_batches_tracked', 'layers.4.conv1.weight', 'layers.4.bn1.weight', 'layers.4.bn1.bias', 'layers.4.bn1.running_mean', 'layers.4.bn1.running_var', 'layers.4.bn1.num_batches_tracked', 'layers.4.conv2.weight', 'layers.4.bn2.weight', 'layers.4.bn2.bias', 'layers.4.bn2.running_mean', 'layers.4.bn2.running_var', 'layers.4.bn2.num_batches_tracked', 'layers.5.conv1.weight', 'layers.5.bn1.weight', 'layers.5.bn1.bias', 'layers.5.bn1.running_mean', 'layers.5.bn1.running_var', 'layers.5.bn1.num_batches_tracked', 'layers.5.conv2.weight', 'layers.5.bn2.weight', 'layers.5.bn2.bias', 'layers.5.bn2.running_mean', 'layers.5.bn2.running_var', 'layers.5.bn2.num_batches_tracked', 'layers.6.conv1.weight', 'layers.6.bn1.weight', 'layers.6.bn1.bias', 'layers.6.bn1.running_mean', 'layers.6.bn1.running_var', 'layers.6.bn1.num_batches_tracked', 'layers.6.conv2.weight', 'layers.6.bn2.weight', 'layers.6.bn2.bias', 'layers.6.bn2.running_mean', 'layers.6.bn2.running_var', 'layers.6.bn2.num_batches_tracked', 'layers.7.conv1.weight', 'layers.7.bn1.weight', 'layers.7.bn1.bias', 'layers.7.bn1.running_mean', 'layers.7.bn1.running_var', 'layers.7.bn1.num_batches_tracked', 'layers.7.conv2.weight', 'layers.7.bn2.weight', 'layers.7.bn2.bias', 'layers.7.bn2.running_mean', 'layers.7.bn2.running_var', 'layers.7.bn2.num_batches_tracked', 'layers.8.conv1.weight', 'layers.8.bn1.weight', 'layers.8.bn1.bias', 'layers.8.bn1.running_mean', 'layers.8.bn1.running_var', 'layers.8.bn1.num_batches_tracked', 'layers.8.conv2.weight', 'layers.8.bn2.weight', 'layers.8.bn2.bias', 'layers.8.bn2.running_mean', 'layers.8.bn2.running_var', 'layers.8.bn2.num_batches_tracked', 'layers.9.conv1.weight', 'layers.9.bn1.weight', 'layers.9.bn1.bias', 'layers.9.bn1.running_mean', 'layers.9.bn1.running_var', 'layers.9.bn1.num_batches_tracked', 'layers.9.conv2.weight', 'layers.9.bn2.weight', 'layers.9.bn2.bias', 'layers.9.bn2.running_mean', 'layers.9.bn2.running_var', 'layers.9.bn2.num_batches_tracked', 'layers.9.downsample.0.weight', 'layers.9.downsample.1.weight', 'layers.9.downsample.1.bias', 'layers.9.downsample.1.running_mean', 'layers.9.downsample.1.running_var', 'layers.9.downsample.1.num_batches_tracked', 'layers.10.conv1.weight', 'layers.10.bn1.weight', 'layers.10.bn1.bias', 'layers.10.bn1.running_mean', 'layers.10.bn1.running_var', 'layers.10.bn1.num_batches_tracked', 'layers.10.conv2.weight', 'layers.10.bn2.weight', 'layers.10.bn2.bias', 'layers.10.bn2.running_mean', 'layers.10.bn2.running_var', 'layers.10.bn2.num_batches_tracked', 'layers.11.conv1.weight', 'layers.11.bn1.weight', 'layers.11.bn1.bias', 'layers.11.bn1.running_mean', 'layers.11.bn1.running_var', 'layers.11.bn1.num_batches_tracked', 'layers.11.conv2.weight', 'layers.11.bn2.weight', 'layers.11.bn2.bias', 'layers.11.bn2.running_mean', 'layers.11.bn2.running_var', 'layers.11.bn2.num_batches_tracked', 'layers.12.conv1.weight', 'layers.12.bn1.weight', 'layers.12.bn1.bias', 'layers.12.bn1.running_mean', 'layers.12.bn1.running_var', 'layers.12.bn1.num_batches_tracked', 'layers.12.conv2.weight', 'layers.12.bn2.weight', 'layers.12.bn2.bias', 'layers.12.bn2.running_mean', 'layers.12.bn2.running_var', 'layers.12.bn2.num_batches_tracked', 'layers.13.conv1.weight', 'layers.13.bn1.weight', 'layers.13.bn1.bias', 'layers.13.bn1.running_mean', 'layers.13.bn1.running_var', 'layers.13.bn1.num_batches_tracked', 'layers.13.conv2.weight', 'layers.13.bn2.weight', 'layers.13.bn2.bias', 'layers.13.bn2.running_mean', 'layers.13.bn2.running_var', 'layers.13.bn2.num_batches_tracked', 'layers.14.conv1.weight', 'layers.14.bn1.weight', 'layers.14.bn1.bias', 'layers.14.bn1.running_mean', 'layers.14.bn1.running_var', 'layers.14.bn1.num_batches_tracked', 'layers.14.conv2.weight', 'layers.14.bn2.weight', 'layers.14.bn2.bias', 'layers.14.bn2.running_mean', 'layers.14.bn2.running_var', 'layers.14.bn2.num_batches_tracked', 'layers.15.conv1.weight', 'layers.15.bn1.weight', 'layers.15.bn1.bias', 'layers.15.bn1.running_mean', 'layers.15.bn1.running_var', 'layers.15.bn1.num_batches_tracked', 'layers.15.conv2.weight', 'layers.15.bn2.weight', 'layers.15.bn2.bias', 'layers.15.bn2.running_mean', 'layers.15.bn2.running_var', 'layers.15.bn2.num_batches_tracked', 'layers.16.conv1.weight', 'layers.16.bn1.weight', 'layers.16.bn1.bias', 'layers.16.bn1.running_mean', 'layers.16.bn1.running_var', 'layers.16.bn1.num_batches_tracked', 'layers.16.conv2.weight', 'layers.16.bn2.weight', 'layers.16.bn2.bias', 'layers.16.bn2.running_mean', 'layers.16.bn2.running_var', 'layers.16.bn2.num_batches_tracked', 'layers.17.conv1.weight', 'layers.17.bn1.weight', 'layers.17.bn1.bias', 'layers.17.bn1.running_mean', 'layers.17.bn1.running_var', 'layers.17.bn1.num_batches_tracked', 'layers.17.conv2.weight', 'layers.17.bn2.weight', 'layers.17.bn2.bias', 'layers.17.bn2.running_mean', 'layers.17.bn2.running_var', 'layers.17.bn2.num_batches_tracked', 'layers.18.conv1.weight', 'layers.18.bn1.weight', 'layers.18.bn1.bias', 'layers.18.bn1.running_mean', 'layers.18.bn1.running_var', 'layers.18.bn1.num_batches_tracked', 'layers.18.conv2.weight', 'layers.18.bn2.weight', 'layers.18.bn2.bias', 'layers.18.bn2.running_mean', 'layers.18.bn2.running_var', 'layers.18.bn2.num_batches_tracked', 'layers.18.downsample.0.weight', 'layers.18.downsample.1.weight', 'layers.18.downsample.1.bias', 'layers.18.downsample.1.running_mean', 'layers.18.downsample.1.running_var', 'layers.18.downsample.1.num_batches_tracked', 'layers.19.conv1.weight', 'layers.19.bn1.weight', 'layers.19.bn1.bias', 'layers.19.bn1.running_mean', 'layers.19.bn1.running_var', 'layers.19.bn1.num_batches_tracked', 'layers.19.conv2.weight', 'layers.19.bn2.weight', 'layers.19.bn2.bias', 'layers.19.bn2.running_mean', 'layers.19.bn2.running_var', 'layers.19.bn2.num_batches_tracked', 'layers.20.conv1.weight', 'layers.20.bn1.weight', 'layers.20.bn1.bias', 'layers.20.bn1.running_mean', 'layers.20.bn1.running_var', 'layers.20.bn1.num_batches_tracked', 'layers.20.conv2.weight', 'layers.20.bn2.weight', 'layers.20.bn2.bias', 'layers.20.bn2.running_mean', 'layers.20.bn2.running_var', 'layers.20.bn2.num_batches_tracked', 'layers.21.conv1.weight', 'layers.21.bn1.weight', 'layers.21.bn1.bias', 'layers.21.bn1.running_mean', 'layers.21.bn1.running_var', 'layers.21.bn1.num_batches_tracked', 'layers.21.conv2.weight', 'layers.21.bn2.weight', 'layers.21.bn2.bias', 'layers.21.bn2.running_mean', 'layers.21.bn2.running_var', 'layers.21.bn2.num_batches_tracked', 'layers.22.conv1.weight', 'layers.22.bn1.weight', 'layers.22.bn1.bias', 'layers.22.bn1.running_mean', 'layers.22.bn1.running_var', 'layers.22.bn1.num_batches_tracked', 'layers.22.conv2.weight', 'layers.22.bn2.weight', 'layers.22.bn2.bias', 'layers.22.bn2.running_mean', 'layers.22.bn2.running_var', 'layers.22.bn2.num_batches_tracked', 'layers.23.conv1.weight', 'layers.23.bn1.weight', 'layers.23.bn1.bias', 'layers.23.bn1.running_mean', 'layers.23.bn1.running_var', 'layers.23.bn1.num_batches_tracked', 'layers.23.conv2.weight', 'layers.23.bn2.weight', 'layers.23.bn2.bias', 'layers.23.bn2.running_mean', 'layers.23.bn2.running_var', 'layers.23.bn2.num_batches_tracked', 'layers.24.conv1.weight', 'layers.24.bn1.weight', 'layers.24.bn1.bias', 'layers.24.bn1.running_mean', 'layers.24.bn1.running_var', 'layers.24.bn1.num_batches_tracked', 'layers.24.conv2.weight', 'layers.24.bn2.weight', 'layers.24.bn2.bias', 'layers.24.bn2.running_mean', 'layers.24.bn2.running_var', 'layers.24.bn2.num_batches_tracked', 'layers.25.conv1.weight', 'layers.25.bn1.weight', 'layers.25.bn1.bias', 'layers.25.bn1.running_mean', 'layers.25.bn1.running_var', 'layers.25.bn1.num_batches_tracked', 'layers.25.conv2.weight', 'layers.25.bn2.weight', 'layers.25.bn2.bias', 'layers.25.bn2.running_mean', 'layers.25.bn2.running_var', 'layers.25.bn2.num_batches_tracked', 'layers.26.conv1.weight', 'layers.26.bn1.weight', 'layers.26.bn1.bias', 'layers.26.bn1.running_mean', 'layers.26.bn1.running_var', 'layers.26.bn1.num_batches_tracked', 'layers.26.conv2.weight', 'layers.26.bn2.weight', 'layers.26.bn2.bias', 'layers.26.bn2.running_mean', 'layers.26.bn2.running_var', 'layers.26.bn2.num_batches_tracked', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
