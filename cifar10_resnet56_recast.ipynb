{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import matplotlib as plt\n",
    "import time\n",
    "\n",
    "from model import CustomResNet, ConvBlock\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torchvision.transforms import ToTensor, Compose, RandomCrop, RandomHorizontalFlip, Normalize\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "teacher_name = 'resnet56_baseline'\n",
    "student_name = 'resnet56_recast'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_class = 10\n",
    "batch_size = 64\n",
    "epoch = 60\n",
    "lr = 0.001\n",
    "step_size = 20\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Validation dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomCrop(size=[32, 32], padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = CIFAR10(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 855770\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (24): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (25): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (27): FCBlock(\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "teacher = CustomResNet(block=BasicBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=10).to(device).eval()\n",
    "# checkpoint = torch.load(f'./result/{dataset_name}_{teacher_name}.pt')\n",
    "# teacher.load_state_dict(checkpoint['model'])\n",
    "\n",
    "total_params = sum(p.numel() for p in teacher.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 855770\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (18): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (19): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (20): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (21): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (22): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (23): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (24): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (25): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (26): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "student = CustomResNet(block=BasicBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=10).to(device)\n",
    "checkpoint = torch.load(f'./result/{dataset_name}_{teacher_name}.pt')\n",
    "student.load_state_dict(checkpoint['model'])\n",
    "\n",
    "total_params = sum(p.numel() for p in student.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 0 recasting...\n",
      "block 0 training started...\n",
      "epoch=0, train_loss=0.3284, test_acc=0.8994\n",
      "epoch=1, train_loss=0.1015, test_acc=0.9125\n",
      "epoch=2, train_loss=0.0434, test_acc=0.9156\n",
      "epoch=3, train_loss=0.0241, test_acc=0.9209\n",
      "epoch=4, train_loss=0.0167, test_acc=0.9250\n",
      "epoch=5, train_loss=0.0110, test_acc=0.9267\n",
      "epoch=6, train_loss=0.0078, test_acc=0.9275\n",
      "epoch=7, train_loss=0.0076, test_acc=0.9289\n",
      "epoch=8, train_loss=0.0075, test_acc=0.9277\n",
      "epoch=9, train_loss=0.0075, test_acc=0.9288\n",
      "epoch=10, train_loss=0.0075, test_acc=0.9283\n",
      "epoch=11, train_loss=0.0074, test_acc=0.9283\n",
      "epoch=12, train_loss=0.0073, test_acc=0.9283\n",
      "epoch=13, train_loss=0.0074, test_acc=0.9285\n",
      "epoch=14, train_loss=0.0075, test_acc=0.9276\n",
      "epoch=15, train_loss=0.0073, test_acc=0.9280\n",
      "epoch=16, train_loss=0.0073, test_acc=0.9278\n",
      "epoch=17, train_loss=0.0074, test_acc=0.9278\n",
      "epoch=18, train_loss=0.0075, test_acc=0.9288\n",
      "epoch=19, train_loss=0.0073, test_acc=0.9277\n",
      "epoch=20, train_loss=0.0072, test_acc=0.9279\n",
      "epoch=21, train_loss=0.0073, test_acc=0.9279\n",
      "epoch=22, train_loss=0.0073, test_acc=0.9281\n",
      "epoch=23, train_loss=0.0073, test_acc=0.9277\n",
      "epoch=24, train_loss=0.0072, test_acc=0.9283\n",
      "epoch=25, train_loss=0.0071, test_acc=0.9281\n",
      "epoch=26, train_loss=0.0072, test_acc=0.9280\n",
      "epoch=27, train_loss=0.0073, test_acc=0.9285\n",
      "epoch=28, train_loss=0.0072, test_acc=0.9279\n",
      "epoch=29, train_loss=0.0072, test_acc=0.9274\n",
      "epoch=30, train_loss=0.0073, test_acc=0.9285\n",
      "epoch=31, train_loss=0.0071, test_acc=0.9283\n",
      "epoch=32, train_loss=0.0073, test_acc=0.9281\n",
      "epoch=33, train_loss=0.0071, test_acc=0.9283\n",
      "epoch=34, train_loss=0.0072, test_acc=0.9283\n",
      "epoch=35, train_loss=0.0073, test_acc=0.9282\n",
      "epoch=36, train_loss=0.0072, test_acc=0.9288\n",
      "epoch=37, train_loss=0.0073, test_acc=0.9287\n",
      "epoch=38, train_loss=0.0072, test_acc=0.9284\n",
      "epoch=39, train_loss=0.0072, test_acc=0.9281\n",
      "epoch=40, train_loss=0.0073, test_acc=0.9292\n",
      "epoch=41, train_loss=0.0072, test_acc=0.9283\n",
      "epoch=42, train_loss=0.0072, test_acc=0.9279\n",
      "epoch=43, train_loss=0.0072, test_acc=0.9281\n",
      "epoch=44, train_loss=0.0071, test_acc=0.9286\n",
      "epoch=45, train_loss=0.0072, test_acc=0.9281\n",
      "epoch=46, train_loss=0.0071, test_acc=0.9281\n",
      "epoch=47, train_loss=0.0072, test_acc=0.9284\n",
      "epoch=48, train_loss=0.0071, test_acc=0.9276\n",
      "epoch=49, train_loss=0.0073, test_acc=0.9278\n",
      "epoch=50, train_loss=0.0072, test_acc=0.9281\n",
      "epoch=51, train_loss=0.0072, test_acc=0.9281\n",
      "epoch=52, train_loss=0.0072, test_acc=0.9276\n",
      "epoch=53, train_loss=0.0071, test_acc=0.9282\n",
      "epoch=54, train_loss=0.0072, test_acc=0.9285\n",
      "epoch=55, train_loss=0.0072, test_acc=0.9279\n",
      "epoch=56, train_loss=0.0074, test_acc=0.9282\n",
      "epoch=57, train_loss=0.0072, test_acc=0.9279\n",
      "epoch=58, train_loss=0.0072, test_acc=0.9283\n",
      "epoch=59, train_loss=0.0074, test_acc=0.9281\n",
      "block 1 recasting...\n",
      "block 1 training started...\n",
      "epoch=0, train_loss=0.3321, test_acc=0.9091\n",
      "epoch=1, train_loss=0.0948, test_acc=0.9236\n",
      "epoch=2, train_loss=0.0374, test_acc=0.9272\n",
      "epoch=3, train_loss=0.0204, test_acc=0.9287\n",
      "epoch=4, train_loss=0.0168, test_acc=0.9296\n",
      "epoch=5, train_loss=0.0139, test_acc=0.9291\n",
      "epoch=6, train_loss=0.0129, test_acc=0.9284\n",
      "epoch=7, train_loss=0.0120, test_acc=0.9285\n",
      "epoch=8, train_loss=0.0114, test_acc=0.9294\n",
      "epoch=9, train_loss=0.0109, test_acc=0.9290\n",
      "epoch=10, train_loss=0.0103, test_acc=0.9307\n",
      "epoch=11, train_loss=0.0100, test_acc=0.9291\n",
      "epoch=12, train_loss=0.0086, test_acc=0.9296\n",
      "epoch=13, train_loss=0.0079, test_acc=0.9293\n",
      "epoch=14, train_loss=0.0076, test_acc=0.9300\n",
      "epoch=15, train_loss=0.0076, test_acc=0.9295\n",
      "epoch=16, train_loss=0.0075, test_acc=0.9303\n",
      "epoch=17, train_loss=0.0075, test_acc=0.9298\n",
      "epoch=18, train_loss=0.0073, test_acc=0.9292\n",
      "epoch=19, train_loss=0.0073, test_acc=0.9302\n",
      "epoch=20, train_loss=0.0071, test_acc=0.9291\n",
      "epoch=21, train_loss=0.0070, test_acc=0.9298\n",
      "epoch=22, train_loss=0.0070, test_acc=0.9299\n",
      "epoch=23, train_loss=0.0069, test_acc=0.9296\n",
      "epoch=24, train_loss=0.0069, test_acc=0.9303\n",
      "epoch=25, train_loss=0.0070, test_acc=0.9292\n",
      "epoch=26, train_loss=0.0069, test_acc=0.9301\n",
      "epoch=27, train_loss=0.0069, test_acc=0.9302\n",
      "epoch=28, train_loss=0.0070, test_acc=0.9292\n",
      "epoch=29, train_loss=0.0070, test_acc=0.9297\n",
      "epoch=30, train_loss=0.0070, test_acc=0.9303\n",
      "epoch=31, train_loss=0.0069, test_acc=0.9294\n",
      "epoch=32, train_loss=0.0069, test_acc=0.9294\n",
      "epoch=33, train_loss=0.0069, test_acc=0.9297\n",
      "epoch=34, train_loss=0.0070, test_acc=0.9296\n",
      "epoch=35, train_loss=0.0068, test_acc=0.9299\n",
      "epoch=36, train_loss=0.0069, test_acc=0.9298\n",
      "epoch=37, train_loss=0.0069, test_acc=0.9301\n",
      "epoch=38, train_loss=0.0069, test_acc=0.9295\n",
      "epoch=39, train_loss=0.0069, test_acc=0.9296\n",
      "epoch=40, train_loss=0.0069, test_acc=0.9303\n",
      "epoch=41, train_loss=0.0068, test_acc=0.9299\n",
      "epoch=42, train_loss=0.0068, test_acc=0.9303\n",
      "epoch=43, train_loss=0.0068, test_acc=0.9296\n",
      "epoch=44, train_loss=0.0069, test_acc=0.9303\n",
      "epoch=45, train_loss=0.0068, test_acc=0.9297\n",
      "epoch=46, train_loss=0.0069, test_acc=0.9301\n",
      "epoch=47, train_loss=0.0068, test_acc=0.9303\n",
      "epoch=48, train_loss=0.0069, test_acc=0.9301\n",
      "epoch=49, train_loss=0.0068, test_acc=0.9298\n",
      "epoch=50, train_loss=0.0068, test_acc=0.9300\n",
      "epoch=51, train_loss=0.0068, test_acc=0.9300\n",
      "epoch=52, train_loss=0.0068, test_acc=0.9301\n",
      "epoch=53, train_loss=0.0069, test_acc=0.9299\n",
      "epoch=54, train_loss=0.0069, test_acc=0.9300\n",
      "epoch=55, train_loss=0.0068, test_acc=0.9302\n",
      "epoch=56, train_loss=0.0069, test_acc=0.9307\n",
      "epoch=57, train_loss=0.0069, test_acc=0.9296\n",
      "epoch=58, train_loss=0.0068, test_acc=0.9288\n",
      "epoch=59, train_loss=0.0069, test_acc=0.9304\n",
      "block 2 recasting...\n",
      "block 2 training started...\n",
      "epoch=0, train_loss=0.3585, test_acc=0.9103\n",
      "epoch=1, train_loss=0.1242, test_acc=0.9224\n",
      "epoch=2, train_loss=0.0652, test_acc=0.9274\n",
      "epoch=3, train_loss=0.0352, test_acc=0.9278\n",
      "epoch=4, train_loss=0.0147, test_acc=0.9283\n",
      "epoch=5, train_loss=0.0121, test_acc=0.9277\n",
      "epoch=6, train_loss=0.0105, test_acc=0.9287\n",
      "epoch=7, train_loss=0.0098, test_acc=0.9274\n",
      "epoch=8, train_loss=0.0094, test_acc=0.9272\n",
      "epoch=9, train_loss=0.0090, test_acc=0.9289\n",
      "epoch=10, train_loss=0.0087, test_acc=0.9288\n",
      "epoch=11, train_loss=0.0086, test_acc=0.9297\n",
      "epoch=12, train_loss=0.0069, test_acc=0.9291\n",
      "epoch=13, train_loss=0.0064, test_acc=0.9299\n",
      "epoch=14, train_loss=0.0061, test_acc=0.9292\n",
      "epoch=15, train_loss=0.0064, test_acc=0.9268\n",
      "epoch=16, train_loss=0.0065, test_acc=0.9279\n",
      "epoch=17, train_loss=0.0060, test_acc=0.9293\n",
      "epoch=18, train_loss=0.0061, test_acc=0.9287\n",
      "epoch=19, train_loss=0.0060, test_acc=0.9300\n",
      "epoch=20, train_loss=0.0056, test_acc=0.9289\n",
      "epoch=21, train_loss=0.0055, test_acc=0.9296\n",
      "epoch=22, train_loss=0.0054, test_acc=0.9297\n",
      "epoch=23, train_loss=0.0054, test_acc=0.9293\n",
      "epoch=24, train_loss=0.0054, test_acc=0.9294\n",
      "epoch=25, train_loss=0.0054, test_acc=0.9292\n",
      "epoch=26, train_loss=0.0055, test_acc=0.9291\n",
      "epoch=27, train_loss=0.0053, test_acc=0.9291\n",
      "epoch=28, train_loss=0.0054, test_acc=0.9292\n",
      "epoch=29, train_loss=0.0054, test_acc=0.9290\n",
      "epoch=30, train_loss=0.0053, test_acc=0.9293\n",
      "epoch=31, train_loss=0.0053, test_acc=0.9295\n",
      "epoch=32, train_loss=0.0054, test_acc=0.9297\n",
      "epoch=33, train_loss=0.0053, test_acc=0.9294\n",
      "epoch=34, train_loss=0.0052, test_acc=0.9289\n",
      "epoch=35, train_loss=0.0052, test_acc=0.9297\n",
      "epoch=36, train_loss=0.0052, test_acc=0.9290\n",
      "epoch=37, train_loss=0.0053, test_acc=0.9292\n",
      "epoch=38, train_loss=0.0052, test_acc=0.9292\n",
      "epoch=39, train_loss=0.0052, test_acc=0.9293\n",
      "epoch=40, train_loss=0.0052, test_acc=0.9295\n",
      "epoch=41, train_loss=0.0051, test_acc=0.9291\n",
      "epoch=42, train_loss=0.0052, test_acc=0.9291\n",
      "epoch=43, train_loss=0.0053, test_acc=0.9297\n",
      "epoch=44, train_loss=0.0051, test_acc=0.9290\n",
      "epoch=45, train_loss=0.0052, test_acc=0.9293\n",
      "epoch=46, train_loss=0.0051, test_acc=0.9292\n",
      "epoch=47, train_loss=0.0051, test_acc=0.9292\n",
      "epoch=48, train_loss=0.0052, test_acc=0.9298\n",
      "epoch=49, train_loss=0.0051, test_acc=0.9294\n",
      "epoch=50, train_loss=0.0052, test_acc=0.9290\n",
      "epoch=51, train_loss=0.0051, test_acc=0.9294\n",
      "epoch=52, train_loss=0.0052, test_acc=0.9291\n",
      "epoch=53, train_loss=0.0051, test_acc=0.9288\n",
      "epoch=54, train_loss=0.0051, test_acc=0.9286\n",
      "epoch=55, train_loss=0.0052, test_acc=0.9292\n",
      "epoch=56, train_loss=0.0051, test_acc=0.9292\n",
      "epoch=57, train_loss=0.0051, test_acc=0.9289\n",
      "epoch=58, train_loss=0.0051, test_acc=0.9292\n",
      "epoch=59, train_loss=0.0052, test_acc=0.9289\n",
      "block 3 recasting...\n",
      "block 3 training started...\n",
      "epoch=0, train_loss=0.3695, test_acc=0.9124\n",
      "epoch=1, train_loss=0.1202, test_acc=0.9233\n",
      "epoch=2, train_loss=0.0515, test_acc=0.9250\n",
      "epoch=3, train_loss=0.0303, test_acc=0.9253\n",
      "epoch=4, train_loss=0.0241, test_acc=0.9284\n",
      "epoch=5, train_loss=0.0221, test_acc=0.9278\n",
      "epoch=6, train_loss=0.0209, test_acc=0.9278\n",
      "epoch=7, train_loss=0.0206, test_acc=0.9271\n",
      "epoch=8, train_loss=0.0202, test_acc=0.9279\n",
      "epoch=9, train_loss=0.0197, test_acc=0.9271\n",
      "epoch=10, train_loss=0.0177, test_acc=0.9301\n",
      "epoch=11, train_loss=0.0090, test_acc=0.9272\n",
      "epoch=12, train_loss=0.0090, test_acc=0.9300\n",
      "epoch=13, train_loss=0.0085, test_acc=0.9293\n",
      "epoch=14, train_loss=0.0082, test_acc=0.9286\n",
      "epoch=15, train_loss=0.0082, test_acc=0.9294\n",
      "epoch=16, train_loss=0.0081, test_acc=0.9288\n",
      "epoch=17, train_loss=0.0079, test_acc=0.9302\n",
      "epoch=18, train_loss=0.0079, test_acc=0.9281\n",
      "epoch=19, train_loss=0.0076, test_acc=0.9276\n",
      "epoch=20, train_loss=0.0073, test_acc=0.9305\n",
      "epoch=21, train_loss=0.0072, test_acc=0.9308\n",
      "epoch=22, train_loss=0.0072, test_acc=0.9300\n",
      "epoch=23, train_loss=0.0072, test_acc=0.9300\n",
      "epoch=24, train_loss=0.0072, test_acc=0.9306\n",
      "epoch=25, train_loss=0.0073, test_acc=0.9306\n",
      "epoch=26, train_loss=0.0072, test_acc=0.9309\n",
      "epoch=27, train_loss=0.0072, test_acc=0.9305\n",
      "epoch=28, train_loss=0.0072, test_acc=0.9303\n",
      "epoch=29, train_loss=0.0071, test_acc=0.9298\n",
      "epoch=30, train_loss=0.0072, test_acc=0.9304\n",
      "epoch=31, train_loss=0.0071, test_acc=0.9300\n",
      "epoch=32, train_loss=0.0073, test_acc=0.9295\n",
      "epoch=33, train_loss=0.0072, test_acc=0.9296\n",
      "epoch=34, train_loss=0.0071, test_acc=0.9303\n",
      "epoch=35, train_loss=0.0072, test_acc=0.9298\n",
      "epoch=36, train_loss=0.0071, test_acc=0.9305\n",
      "epoch=37, train_loss=0.0071, test_acc=0.9302\n",
      "epoch=38, train_loss=0.0071, test_acc=0.9307\n",
      "epoch=39, train_loss=0.0071, test_acc=0.9306\n",
      "epoch=40, train_loss=0.0071, test_acc=0.9303\n",
      "epoch=41, train_loss=0.0070, test_acc=0.9301\n",
      "epoch=42, train_loss=0.0070, test_acc=0.9306\n",
      "epoch=43, train_loss=0.0070, test_acc=0.9302\n",
      "epoch=44, train_loss=0.0070, test_acc=0.9304\n",
      "epoch=45, train_loss=0.0070, test_acc=0.9305\n",
      "epoch=46, train_loss=0.0071, test_acc=0.9305\n",
      "epoch=47, train_loss=0.0070, test_acc=0.9307\n",
      "epoch=48, train_loss=0.0070, test_acc=0.9308\n",
      "epoch=49, train_loss=0.0069, test_acc=0.9304\n",
      "epoch=50, train_loss=0.0070, test_acc=0.9301\n",
      "epoch=51, train_loss=0.0070, test_acc=0.9304\n",
      "epoch=52, train_loss=0.0070, test_acc=0.9297\n",
      "epoch=53, train_loss=0.0069, test_acc=0.9303\n",
      "epoch=54, train_loss=0.0071, test_acc=0.9298\n",
      "epoch=55, train_loss=0.0070, test_acc=0.9301\n",
      "epoch=56, train_loss=0.0070, test_acc=0.9303\n",
      "epoch=57, train_loss=0.0070, test_acc=0.9306\n",
      "epoch=58, train_loss=0.0070, test_acc=0.9301\n",
      "epoch=59, train_loss=0.0071, test_acc=0.9304\n",
      "block 4 recasting...\n",
      "block 4 training started...\n",
      "epoch=0, train_loss=0.4239, test_acc=0.8974\n",
      "epoch=1, train_loss=0.1424, test_acc=0.9228\n",
      "epoch=2, train_loss=0.0598, test_acc=0.9257\n",
      "epoch=3, train_loss=0.0322, test_acc=0.9264\n",
      "epoch=4, train_loss=0.0199, test_acc=0.9259\n",
      "epoch=5, train_loss=0.0160, test_acc=0.9282\n",
      "epoch=6, train_loss=0.0148, test_acc=0.9298\n",
      "epoch=7, train_loss=0.0128, test_acc=0.9284\n",
      "epoch=8, train_loss=0.0122, test_acc=0.9283\n",
      "epoch=9, train_loss=0.0117, test_acc=0.9286\n",
      "epoch=10, train_loss=0.0117, test_acc=0.9306\n",
      "epoch=11, train_loss=0.0113, test_acc=0.9294\n",
      "epoch=12, train_loss=0.0110, test_acc=0.9302\n",
      "epoch=13, train_loss=0.0107, test_acc=0.9271\n",
      "epoch=14, train_loss=0.0104, test_acc=0.9298\n",
      "epoch=15, train_loss=0.0105, test_acc=0.9294\n",
      "epoch=16, train_loss=0.0100, test_acc=0.9285\n",
      "epoch=17, train_loss=0.0100, test_acc=0.9294\n",
      "epoch=18, train_loss=0.0097, test_acc=0.9304\n",
      "epoch=19, train_loss=0.0094, test_acc=0.9296\n",
      "epoch=20, train_loss=0.0090, test_acc=0.9295\n",
      "epoch=21, train_loss=0.0089, test_acc=0.9297\n",
      "epoch=22, train_loss=0.0089, test_acc=0.9293\n",
      "epoch=23, train_loss=0.0088, test_acc=0.9300\n",
      "epoch=24, train_loss=0.0088, test_acc=0.9291\n",
      "epoch=25, train_loss=0.0087, test_acc=0.9286\n",
      "epoch=26, train_loss=0.0087, test_acc=0.9302\n",
      "epoch=27, train_loss=0.0087, test_acc=0.9299\n",
      "epoch=28, train_loss=0.0087, test_acc=0.9302\n",
      "epoch=29, train_loss=0.0087, test_acc=0.9295\n",
      "epoch=30, train_loss=0.0087, test_acc=0.9298\n",
      "epoch=31, train_loss=0.0088, test_acc=0.9301\n",
      "epoch=32, train_loss=0.0087, test_acc=0.9297\n",
      "epoch=33, train_loss=0.0087, test_acc=0.9295\n",
      "epoch=34, train_loss=0.0086, test_acc=0.9289\n",
      "epoch=35, train_loss=0.0086, test_acc=0.9296\n",
      "epoch=36, train_loss=0.0086, test_acc=0.9293\n",
      "epoch=37, train_loss=0.0086, test_acc=0.9292\n",
      "epoch=38, train_loss=0.0086, test_acc=0.9297\n",
      "epoch=39, train_loss=0.0086, test_acc=0.9298\n",
      "epoch=40, train_loss=0.0085, test_acc=0.9297\n",
      "epoch=41, train_loss=0.0085, test_acc=0.9294\n",
      "epoch=42, train_loss=0.0085, test_acc=0.9296\n",
      "epoch=43, train_loss=0.0085, test_acc=0.9298\n",
      "epoch=44, train_loss=0.0086, test_acc=0.9297\n",
      "epoch=45, train_loss=0.0085, test_acc=0.9297\n",
      "epoch=46, train_loss=0.0085, test_acc=0.9293\n",
      "epoch=47, train_loss=0.0085, test_acc=0.9293\n",
      "epoch=48, train_loss=0.0085, test_acc=0.9298\n",
      "epoch=49, train_loss=0.0085, test_acc=0.9300\n",
      "epoch=50, train_loss=0.0085, test_acc=0.9290\n",
      "epoch=51, train_loss=0.0084, test_acc=0.9298\n",
      "epoch=52, train_loss=0.0085, test_acc=0.9302\n",
      "epoch=53, train_loss=0.0085, test_acc=0.9302\n",
      "epoch=54, train_loss=0.0085, test_acc=0.9297\n",
      "epoch=55, train_loss=0.0085, test_acc=0.9294\n",
      "epoch=56, train_loss=0.0085, test_acc=0.9298\n",
      "epoch=57, train_loss=0.0084, test_acc=0.9307\n",
      "epoch=58, train_loss=0.0085, test_acc=0.9296\n",
      "epoch=59, train_loss=0.0085, test_acc=0.9293\n",
      "block 5 recasting...\n",
      "block 5 training started...\n",
      "epoch=0, train_loss=0.5125, test_acc=0.9046\n",
      "epoch=1, train_loss=0.1740, test_acc=0.9205\n",
      "epoch=2, train_loss=0.0742, test_acc=0.9273\n",
      "epoch=3, train_loss=0.0349, test_acc=0.9266\n",
      "epoch=4, train_loss=0.0236, test_acc=0.9250\n",
      "epoch=5, train_loss=0.0197, test_acc=0.9287\n",
      "epoch=6, train_loss=0.0171, test_acc=0.9281\n",
      "epoch=7, train_loss=0.0151, test_acc=0.9269\n",
      "epoch=8, train_loss=0.0141, test_acc=0.9254\n",
      "epoch=9, train_loss=0.0137, test_acc=0.9272\n",
      "epoch=10, train_loss=0.0135, test_acc=0.9284\n",
      "epoch=11, train_loss=0.0131, test_acc=0.9238\n",
      "epoch=12, train_loss=0.0127, test_acc=0.9245\n",
      "epoch=13, train_loss=0.0123, test_acc=0.9249\n",
      "epoch=14, train_loss=0.0124, test_acc=0.9265\n",
      "epoch=15, train_loss=0.0121, test_acc=0.9254\n",
      "epoch=16, train_loss=0.0120, test_acc=0.9247\n",
      "epoch=17, train_loss=0.0120, test_acc=0.9297\n",
      "epoch=18, train_loss=0.0118, test_acc=0.9270\n",
      "epoch=19, train_loss=0.0116, test_acc=0.9273\n",
      "epoch=20, train_loss=0.0111, test_acc=0.9283\n",
      "epoch=21, train_loss=0.0111, test_acc=0.9271\n",
      "epoch=22, train_loss=0.0111, test_acc=0.9282\n",
      "epoch=23, train_loss=0.0111, test_acc=0.9273\n",
      "epoch=24, train_loss=0.0111, test_acc=0.9262\n",
      "epoch=25, train_loss=0.0111, test_acc=0.9280\n",
      "epoch=26, train_loss=0.0111, test_acc=0.9276\n",
      "epoch=27, train_loss=0.0109, test_acc=0.9267\n",
      "epoch=28, train_loss=0.0110, test_acc=0.9279\n",
      "epoch=29, train_loss=0.0110, test_acc=0.9289\n",
      "epoch=30, train_loss=0.0109, test_acc=0.9289\n",
      "epoch=31, train_loss=0.0109, test_acc=0.9273\n",
      "epoch=32, train_loss=0.0111, test_acc=0.9283\n",
      "epoch=33, train_loss=0.0109, test_acc=0.9281\n",
      "epoch=34, train_loss=0.0108, test_acc=0.9277\n",
      "epoch=35, train_loss=0.0109, test_acc=0.9266\n",
      "epoch=36, train_loss=0.0108, test_acc=0.9265\n",
      "epoch=37, train_loss=0.0109, test_acc=0.9278\n",
      "epoch=38, train_loss=0.0108, test_acc=0.9281\n",
      "epoch=39, train_loss=0.0109, test_acc=0.9270\n",
      "epoch=40, train_loss=0.0108, test_acc=0.9284\n",
      "epoch=41, train_loss=0.0107, test_acc=0.9272\n",
      "epoch=42, train_loss=0.0108, test_acc=0.9278\n",
      "epoch=43, train_loss=0.0107, test_acc=0.9277\n",
      "epoch=44, train_loss=0.0107, test_acc=0.9273\n",
      "epoch=45, train_loss=0.0108, test_acc=0.9279\n",
      "epoch=46, train_loss=0.0108, test_acc=0.9268\n",
      "epoch=47, train_loss=0.0107, test_acc=0.9274\n",
      "epoch=48, train_loss=0.0107, test_acc=0.9277\n",
      "epoch=49, train_loss=0.0107, test_acc=0.9280\n",
      "epoch=50, train_loss=0.0108, test_acc=0.9271\n",
      "epoch=51, train_loss=0.0107, test_acc=0.9275\n",
      "epoch=52, train_loss=0.0107, test_acc=0.9275\n",
      "epoch=53, train_loss=0.0107, test_acc=0.9276\n",
      "epoch=54, train_loss=0.0107, test_acc=0.9277\n",
      "epoch=55, train_loss=0.0107, test_acc=0.9280\n",
      "epoch=56, train_loss=0.0107, test_acc=0.9269\n",
      "epoch=57, train_loss=0.0107, test_acc=0.9277\n",
      "epoch=58, train_loss=0.0107, test_acc=0.9278\n",
      "epoch=59, train_loss=0.0107, test_acc=0.9273\n",
      "block 6 recasting...\n",
      "block 6 training started...\n",
      "epoch=0, train_loss=0.5607, test_acc=0.9043\n",
      "epoch=1, train_loss=0.1850, test_acc=0.9135\n",
      "epoch=2, train_loss=0.0844, test_acc=0.9255\n",
      "epoch=3, train_loss=0.0454, test_acc=0.9284\n",
      "epoch=4, train_loss=0.0338, test_acc=0.9237\n",
      "epoch=5, train_loss=0.0253, test_acc=0.9285\n",
      "epoch=6, train_loss=0.0220, test_acc=0.9286\n",
      "epoch=7, train_loss=0.0201, test_acc=0.9266\n",
      "epoch=8, train_loss=0.0195, test_acc=0.9272\n",
      "epoch=9, train_loss=0.0190, test_acc=0.9286\n",
      "epoch=10, train_loss=0.0185, test_acc=0.9275\n",
      "epoch=11, train_loss=0.0182, test_acc=0.9277\n",
      "epoch=12, train_loss=0.0180, test_acc=0.9277\n",
      "epoch=13, train_loss=0.0176, test_acc=0.9239\n",
      "epoch=14, train_loss=0.0174, test_acc=0.9265\n",
      "epoch=15, train_loss=0.0173, test_acc=0.9268\n",
      "epoch=16, train_loss=0.0170, test_acc=0.9263\n",
      "epoch=17, train_loss=0.0165, test_acc=0.9286\n",
      "epoch=18, train_loss=0.0162, test_acc=0.9293\n",
      "epoch=19, train_loss=0.0160, test_acc=0.9284\n",
      "epoch=20, train_loss=0.0154, test_acc=0.9291\n",
      "epoch=21, train_loss=0.0154, test_acc=0.9281\n",
      "epoch=22, train_loss=0.0153, test_acc=0.9284\n",
      "epoch=23, train_loss=0.0154, test_acc=0.9282\n",
      "epoch=24, train_loss=0.0154, test_acc=0.9287\n",
      "epoch=25, train_loss=0.0152, test_acc=0.9283\n",
      "epoch=26, train_loss=0.0153, test_acc=0.9287\n",
      "epoch=27, train_loss=0.0152, test_acc=0.9286\n",
      "epoch=28, train_loss=0.0153, test_acc=0.9285\n",
      "epoch=29, train_loss=0.0152, test_acc=0.9276\n",
      "epoch=30, train_loss=0.0152, test_acc=0.9289\n",
      "epoch=31, train_loss=0.0152, test_acc=0.9287\n",
      "epoch=32, train_loss=0.0152, test_acc=0.9283\n",
      "epoch=33, train_loss=0.0151, test_acc=0.9288\n",
      "epoch=34, train_loss=0.0152, test_acc=0.9289\n",
      "epoch=35, train_loss=0.0152, test_acc=0.9287\n",
      "epoch=36, train_loss=0.0152, test_acc=0.9278\n",
      "epoch=37, train_loss=0.0151, test_acc=0.9283\n",
      "epoch=38, train_loss=0.0151, test_acc=0.9287\n",
      "epoch=39, train_loss=0.0151, test_acc=0.9281\n",
      "epoch=40, train_loss=0.0150, test_acc=0.9289\n",
      "epoch=41, train_loss=0.0150, test_acc=0.9284\n",
      "epoch=42, train_loss=0.0150, test_acc=0.9284\n",
      "epoch=43, train_loss=0.0150, test_acc=0.9286\n",
      "epoch=44, train_loss=0.0151, test_acc=0.9287\n",
      "epoch=45, train_loss=0.0150, test_acc=0.9288\n",
      "epoch=46, train_loss=0.0149, test_acc=0.9285\n",
      "epoch=47, train_loss=0.0150, test_acc=0.9285\n",
      "epoch=48, train_loss=0.0150, test_acc=0.9285\n",
      "epoch=49, train_loss=0.0150, test_acc=0.9284\n",
      "epoch=50, train_loss=0.0150, test_acc=0.9282\n",
      "epoch=51, train_loss=0.0150, test_acc=0.9282\n",
      "epoch=52, train_loss=0.0150, test_acc=0.9284\n",
      "epoch=53, train_loss=0.0150, test_acc=0.9281\n",
      "epoch=54, train_loss=0.0150, test_acc=0.9283\n",
      "epoch=55, train_loss=0.0151, test_acc=0.9283\n",
      "epoch=56, train_loss=0.0150, test_acc=0.9286\n",
      "epoch=57, train_loss=0.0150, test_acc=0.9283\n",
      "epoch=58, train_loss=0.0150, test_acc=0.9288\n",
      "epoch=59, train_loss=0.0150, test_acc=0.9284\n",
      "block 7 recasting...\n",
      "block 7 training started...\n",
      "epoch=0, train_loss=0.6145, test_acc=0.8981\n",
      "epoch=1, train_loss=0.1836, test_acc=0.9196\n",
      "epoch=2, train_loss=0.0881, test_acc=0.9223\n",
      "epoch=3, train_loss=0.0584, test_acc=0.9269\n",
      "epoch=4, train_loss=0.0488, test_acc=0.9264\n",
      "epoch=5, train_loss=0.0423, test_acc=0.9273\n",
      "epoch=6, train_loss=0.0407, test_acc=0.9232\n",
      "epoch=7, train_loss=0.0402, test_acc=0.9231\n",
      "epoch=8, train_loss=0.0405, test_acc=0.9271\n",
      "epoch=9, train_loss=0.0389, test_acc=0.9257\n",
      "epoch=10, train_loss=0.0386, test_acc=0.9284\n",
      "epoch=11, train_loss=0.0382, test_acc=0.9263\n",
      "epoch=12, train_loss=0.0354, test_acc=0.9280\n",
      "epoch=13, train_loss=0.0336, test_acc=0.9237\n",
      "epoch=14, train_loss=0.0335, test_acc=0.9287\n",
      "epoch=15, train_loss=0.0316, test_acc=0.9268\n",
      "epoch=16, train_loss=0.0293, test_acc=0.9249\n",
      "epoch=17, train_loss=0.0291, test_acc=0.9271\n",
      "epoch=18, train_loss=0.0291, test_acc=0.9250\n",
      "epoch=19, train_loss=0.0287, test_acc=0.9244\n",
      "epoch=20, train_loss=0.0279, test_acc=0.9292\n",
      "epoch=21, train_loss=0.0278, test_acc=0.9291\n",
      "epoch=22, train_loss=0.0278, test_acc=0.9294\n",
      "epoch=23, train_loss=0.0278, test_acc=0.9287\n",
      "epoch=24, train_loss=0.0279, test_acc=0.9292\n",
      "epoch=25, train_loss=0.0278, test_acc=0.9284\n",
      "epoch=26, train_loss=0.0278, test_acc=0.9291\n",
      "epoch=27, train_loss=0.0278, test_acc=0.9281\n",
      "epoch=28, train_loss=0.0277, test_acc=0.9287\n",
      "epoch=29, train_loss=0.0277, test_acc=0.9297\n",
      "epoch=30, train_loss=0.0276, test_acc=0.9299\n",
      "epoch=31, train_loss=0.0276, test_acc=0.9295\n",
      "epoch=32, train_loss=0.0276, test_acc=0.9291\n",
      "epoch=33, train_loss=0.0276, test_acc=0.9293\n",
      "epoch=34, train_loss=0.0276, test_acc=0.9291\n",
      "epoch=35, train_loss=0.0276, test_acc=0.9294\n",
      "epoch=36, train_loss=0.0276, test_acc=0.9294\n",
      "epoch=37, train_loss=0.0276, test_acc=0.9293\n",
      "epoch=38, train_loss=0.0276, test_acc=0.9293\n",
      "epoch=39, train_loss=0.0275, test_acc=0.9297\n",
      "epoch=40, train_loss=0.0274, test_acc=0.9292\n",
      "epoch=41, train_loss=0.0274, test_acc=0.9298\n",
      "epoch=42, train_loss=0.0274, test_acc=0.9292\n",
      "epoch=43, train_loss=0.0275, test_acc=0.9297\n",
      "epoch=44, train_loss=0.0275, test_acc=0.9290\n",
      "epoch=45, train_loss=0.0274, test_acc=0.9291\n",
      "epoch=46, train_loss=0.0274, test_acc=0.9291\n",
      "epoch=47, train_loss=0.0275, test_acc=0.9287\n",
      "epoch=48, train_loss=0.0275, test_acc=0.9295\n",
      "epoch=49, train_loss=0.0274, test_acc=0.9292\n",
      "epoch=50, train_loss=0.0274, test_acc=0.9295\n",
      "epoch=51, train_loss=0.0275, test_acc=0.9300\n",
      "epoch=52, train_loss=0.0274, test_acc=0.9290\n",
      "epoch=53, train_loss=0.0274, test_acc=0.9288\n",
      "epoch=54, train_loss=0.0274, test_acc=0.9294\n",
      "epoch=55, train_loss=0.0274, test_acc=0.9296\n",
      "epoch=56, train_loss=0.0274, test_acc=0.9285\n",
      "epoch=57, train_loss=0.0274, test_acc=0.9295\n",
      "epoch=58, train_loss=0.0275, test_acc=0.9295\n",
      "epoch=59, train_loss=0.0275, test_acc=0.9299\n",
      "block 8 recasting...\n",
      "block 8 training started...\n",
      "epoch=0, train_loss=0.5975, test_acc=0.8202\n",
      "epoch=1, train_loss=0.1712, test_acc=0.9087\n",
      "epoch=2, train_loss=0.0895, test_acc=0.8057\n",
      "epoch=3, train_loss=0.0673, test_acc=0.9172\n",
      "epoch=4, train_loss=0.0558, test_acc=0.9213\n",
      "epoch=5, train_loss=0.0521, test_acc=0.9157\n",
      "epoch=6, train_loss=0.0511, test_acc=0.9223\n",
      "epoch=7, train_loss=0.0496, test_acc=0.9193\n",
      "epoch=8, train_loss=0.0492, test_acc=0.9183\n",
      "epoch=9, train_loss=0.0475, test_acc=0.9285\n",
      "epoch=10, train_loss=0.0468, test_acc=0.9261\n",
      "epoch=11, train_loss=0.0468, test_acc=0.9205\n",
      "epoch=12, train_loss=0.0459, test_acc=0.9254\n",
      "epoch=13, train_loss=0.0451, test_acc=0.9217\n",
      "epoch=14, train_loss=0.0446, test_acc=0.9196\n",
      "epoch=15, train_loss=0.0442, test_acc=0.9241\n",
      "epoch=16, train_loss=0.0434, test_acc=0.9237\n",
      "epoch=17, train_loss=0.0431, test_acc=0.9178\n",
      "epoch=18, train_loss=0.0426, test_acc=0.9196\n",
      "epoch=19, train_loss=0.0423, test_acc=0.9194\n",
      "epoch=20, train_loss=0.0410, test_acc=0.9281\n",
      "epoch=21, train_loss=0.0410, test_acc=0.9274\n",
      "epoch=22, train_loss=0.0411, test_acc=0.9270\n",
      "epoch=23, train_loss=0.0411, test_acc=0.9284\n",
      "epoch=24, train_loss=0.0409, test_acc=0.9286\n",
      "epoch=25, train_loss=0.0408, test_acc=0.9276\n",
      "epoch=26, train_loss=0.0409, test_acc=0.9262\n",
      "epoch=27, train_loss=0.0408, test_acc=0.9273\n",
      "epoch=28, train_loss=0.0407, test_acc=0.9272\n",
      "epoch=29, train_loss=0.0407, test_acc=0.9282\n",
      "epoch=30, train_loss=0.0406, test_acc=0.9290\n",
      "epoch=31, train_loss=0.0405, test_acc=0.9284\n",
      "epoch=32, train_loss=0.0405, test_acc=0.9283\n",
      "epoch=33, train_loss=0.0407, test_acc=0.9285\n",
      "epoch=34, train_loss=0.0406, test_acc=0.9279\n",
      "epoch=35, train_loss=0.0405, test_acc=0.9284\n",
      "epoch=36, train_loss=0.0404, test_acc=0.9281\n",
      "epoch=37, train_loss=0.0404, test_acc=0.9277\n",
      "epoch=38, train_loss=0.0403, test_acc=0.9280\n",
      "epoch=39, train_loss=0.0402, test_acc=0.9286\n",
      "epoch=40, train_loss=0.0402, test_acc=0.9278\n",
      "epoch=41, train_loss=0.0401, test_acc=0.9287\n",
      "epoch=42, train_loss=0.0401, test_acc=0.9287\n",
      "epoch=43, train_loss=0.0401, test_acc=0.9285\n",
      "epoch=44, train_loss=0.0401, test_acc=0.9278\n",
      "epoch=45, train_loss=0.0400, test_acc=0.9286\n",
      "epoch=46, train_loss=0.0402, test_acc=0.9281\n",
      "epoch=47, train_loss=0.0401, test_acc=0.9288\n",
      "epoch=48, train_loss=0.0400, test_acc=0.9285\n",
      "epoch=49, train_loss=0.0401, test_acc=0.9288\n",
      "epoch=50, train_loss=0.0400, test_acc=0.9282\n",
      "epoch=51, train_loss=0.0402, test_acc=0.9274\n",
      "epoch=52, train_loss=0.0401, test_acc=0.9285\n",
      "epoch=53, train_loss=0.0401, test_acc=0.9282\n",
      "epoch=54, train_loss=0.0401, test_acc=0.9282\n",
      "epoch=55, train_loss=0.0401, test_acc=0.9296\n",
      "epoch=56, train_loss=0.0400, test_acc=0.9281\n",
      "epoch=57, train_loss=0.0402, test_acc=0.9280\n",
      "epoch=58, train_loss=0.0401, test_acc=0.9288\n",
      "epoch=59, train_loss=0.0400, test_acc=0.9284\n",
      "block 9 recasting...\n",
      "block 9 training started...\n",
      "epoch=0, train_loss=0.1544, test_acc=0.9072\n",
      "epoch=1, train_loss=0.0502, test_acc=0.9101\n",
      "epoch=2, train_loss=0.0402, test_acc=0.9163\n",
      "epoch=3, train_loss=0.0367, test_acc=0.9178\n",
      "epoch=4, train_loss=0.0354, test_acc=0.9204\n",
      "epoch=5, train_loss=0.0343, test_acc=0.9147\n",
      "epoch=6, train_loss=0.0338, test_acc=0.9203\n",
      "epoch=7, train_loss=0.0328, test_acc=0.9170\n",
      "epoch=8, train_loss=0.0323, test_acc=0.9221\n",
      "epoch=9, train_loss=0.0320, test_acc=0.9234\n",
      "epoch=10, train_loss=0.0316, test_acc=0.9233\n",
      "epoch=11, train_loss=0.0314, test_acc=0.9244\n",
      "epoch=12, train_loss=0.0311, test_acc=0.9208\n",
      "epoch=13, train_loss=0.0309, test_acc=0.9207\n",
      "epoch=14, train_loss=0.0290, test_acc=0.9233\n",
      "epoch=15, train_loss=0.0256, test_acc=0.9156\n",
      "epoch=16, train_loss=0.0255, test_acc=0.9218\n",
      "epoch=17, train_loss=0.0253, test_acc=0.9214\n",
      "epoch=18, train_loss=0.0252, test_acc=0.9232\n",
      "epoch=19, train_loss=0.0250, test_acc=0.9254\n",
      "epoch=20, train_loss=0.0243, test_acc=0.9263\n",
      "epoch=21, train_loss=0.0243, test_acc=0.9269\n",
      "epoch=22, train_loss=0.0242, test_acc=0.9267\n",
      "epoch=23, train_loss=0.0242, test_acc=0.9261\n",
      "epoch=24, train_loss=0.0241, test_acc=0.9272\n",
      "epoch=25, train_loss=0.0241, test_acc=0.9275\n",
      "epoch=26, train_loss=0.0242, test_acc=0.9253\n",
      "epoch=27, train_loss=0.0240, test_acc=0.9268\n",
      "epoch=28, train_loss=0.0236, test_acc=0.9261\n",
      "epoch=29, train_loss=0.0234, test_acc=0.9278\n",
      "epoch=30, train_loss=0.0232, test_acc=0.9263\n",
      "epoch=31, train_loss=0.0228, test_acc=0.9272\n",
      "epoch=32, train_loss=0.0224, test_acc=0.9259\n",
      "epoch=33, train_loss=0.0218, test_acc=0.9252\n",
      "epoch=34, train_loss=0.0216, test_acc=0.9276\n",
      "epoch=35, train_loss=0.0215, test_acc=0.9281\n",
      "epoch=36, train_loss=0.0215, test_acc=0.9260\n",
      "epoch=37, train_loss=0.0214, test_acc=0.9254\n",
      "epoch=38, train_loss=0.0214, test_acc=0.9272\n",
      "epoch=39, train_loss=0.0214, test_acc=0.9264\n",
      "epoch=40, train_loss=0.0213, test_acc=0.9268\n",
      "epoch=41, train_loss=0.0213, test_acc=0.9263\n",
      "epoch=42, train_loss=0.0213, test_acc=0.9277\n",
      "epoch=43, train_loss=0.0213, test_acc=0.9265\n",
      "epoch=44, train_loss=0.0212, test_acc=0.9261\n",
      "epoch=45, train_loss=0.0213, test_acc=0.9273\n",
      "epoch=46, train_loss=0.0213, test_acc=0.9265\n",
      "epoch=47, train_loss=0.0213, test_acc=0.9273\n",
      "epoch=48, train_loss=0.0213, test_acc=0.9279\n",
      "epoch=49, train_loss=0.0213, test_acc=0.9271\n",
      "epoch=50, train_loss=0.0213, test_acc=0.9269\n",
      "epoch=51, train_loss=0.0213, test_acc=0.9269\n",
      "epoch=52, train_loss=0.0212, test_acc=0.9271\n",
      "epoch=53, train_loss=0.0213, test_acc=0.9271\n",
      "epoch=54, train_loss=0.0212, test_acc=0.9269\n",
      "epoch=55, train_loss=0.0212, test_acc=0.9267\n",
      "epoch=56, train_loss=0.0213, test_acc=0.9272\n",
      "epoch=57, train_loss=0.0212, test_acc=0.9267\n",
      "epoch=58, train_loss=0.0213, test_acc=0.9269\n",
      "epoch=59, train_loss=0.0213, test_acc=0.9269\n",
      "block 10 recasting...\n",
      "block 10 training started...\n",
      "epoch=0, train_loss=0.2056, test_acc=0.8833\n",
      "epoch=1, train_loss=0.0672, test_acc=0.9180\n",
      "epoch=2, train_loss=0.0511, test_acc=0.8990\n",
      "epoch=3, train_loss=0.0437, test_acc=0.9166\n",
      "epoch=4, train_loss=0.0410, test_acc=0.9180\n",
      "epoch=5, train_loss=0.0389, test_acc=0.9210\n",
      "epoch=6, train_loss=0.0382, test_acc=0.9125\n",
      "epoch=7, train_loss=0.0379, test_acc=0.9199\n",
      "epoch=8, train_loss=0.0369, test_acc=0.9218\n",
      "epoch=9, train_loss=0.0362, test_acc=0.9223\n",
      "epoch=10, train_loss=0.0356, test_acc=0.9066\n",
      "epoch=11, train_loss=0.0350, test_acc=0.9195\n",
      "epoch=12, train_loss=0.0349, test_acc=0.9212\n",
      "epoch=13, train_loss=0.0343, test_acc=0.9204\n",
      "epoch=14, train_loss=0.0346, test_acc=0.9216\n",
      "epoch=15, train_loss=0.0338, test_acc=0.9211\n",
      "epoch=16, train_loss=0.0338, test_acc=0.9210\n",
      "epoch=17, train_loss=0.0336, test_acc=0.9197\n",
      "epoch=18, train_loss=0.0334, test_acc=0.9221\n",
      "epoch=19, train_loss=0.0332, test_acc=0.9156\n",
      "epoch=20, train_loss=0.0323, test_acc=0.9253\n",
      "epoch=21, train_loss=0.0322, test_acc=0.9252\n",
      "epoch=22, train_loss=0.0321, test_acc=0.9241\n",
      "epoch=23, train_loss=0.0321, test_acc=0.9239\n",
      "epoch=24, train_loss=0.0320, test_acc=0.9260\n",
      "epoch=25, train_loss=0.0321, test_acc=0.9255\n",
      "epoch=26, train_loss=0.0321, test_acc=0.9248\n",
      "epoch=27, train_loss=0.0320, test_acc=0.9258\n",
      "epoch=28, train_loss=0.0320, test_acc=0.9258\n",
      "epoch=29, train_loss=0.0320, test_acc=0.9243\n",
      "epoch=30, train_loss=0.0320, test_acc=0.9259\n",
      "epoch=31, train_loss=0.0319, test_acc=0.9246\n",
      "epoch=32, train_loss=0.0319, test_acc=0.9245\n",
      "epoch=33, train_loss=0.0319, test_acc=0.9231\n",
      "epoch=34, train_loss=0.0319, test_acc=0.9254\n",
      "epoch=35, train_loss=0.0319, test_acc=0.9254\n",
      "epoch=36, train_loss=0.0319, test_acc=0.9254\n",
      "epoch=37, train_loss=0.0319, test_acc=0.9245\n",
      "epoch=38, train_loss=0.0319, test_acc=0.9257\n",
      "epoch=39, train_loss=0.0319, test_acc=0.9250\n",
      "epoch=40, train_loss=0.0318, test_acc=0.9254\n",
      "epoch=41, train_loss=0.0318, test_acc=0.9263\n",
      "epoch=42, train_loss=0.0317, test_acc=0.9246\n",
      "epoch=43, train_loss=0.0317, test_acc=0.9240\n",
      "epoch=44, train_loss=0.0317, test_acc=0.9263\n",
      "epoch=45, train_loss=0.0317, test_acc=0.9255\n",
      "epoch=46, train_loss=0.0317, test_acc=0.9253\n",
      "epoch=47, train_loss=0.0317, test_acc=0.9257\n",
      "epoch=48, train_loss=0.0317, test_acc=0.9261\n",
      "epoch=49, train_loss=0.0317, test_acc=0.9244\n",
      "epoch=50, train_loss=0.0318, test_acc=0.9267\n",
      "epoch=51, train_loss=0.0317, test_acc=0.9255\n",
      "epoch=52, train_loss=0.0317, test_acc=0.9257\n",
      "epoch=53, train_loss=0.0317, test_acc=0.9245\n",
      "epoch=54, train_loss=0.0317, test_acc=0.9248\n",
      "epoch=55, train_loss=0.0317, test_acc=0.9263\n",
      "epoch=56, train_loss=0.0317, test_acc=0.9252\n",
      "epoch=57, train_loss=0.0317, test_acc=0.9251\n",
      "epoch=58, train_loss=0.0317, test_acc=0.9246\n",
      "epoch=59, train_loss=0.0317, test_acc=0.9252\n",
      "block 11 recasting...\n",
      "block 11 training started...\n",
      "epoch=0, train_loss=0.2334, test_acc=0.8978\n",
      "epoch=1, train_loss=0.0839, test_acc=0.9165\n",
      "epoch=2, train_loss=0.0645, test_acc=0.9026\n",
      "epoch=3, train_loss=0.0592, test_acc=0.9057\n",
      "epoch=4, train_loss=0.0555, test_acc=0.9156\n",
      "epoch=5, train_loss=0.0529, test_acc=0.9144\n",
      "epoch=6, train_loss=0.0495, test_acc=0.9169\n",
      "epoch=7, train_loss=0.0428, test_acc=0.9137\n",
      "epoch=8, train_loss=0.0430, test_acc=0.9196\n",
      "epoch=9, train_loss=0.0425, test_acc=0.9215\n",
      "epoch=10, train_loss=0.0425, test_acc=0.9160\n",
      "epoch=11, train_loss=0.0413, test_acc=0.9182\n",
      "epoch=12, train_loss=0.0419, test_acc=0.9212\n",
      "epoch=13, train_loss=0.0408, test_acc=0.9223\n",
      "epoch=14, train_loss=0.0415, test_acc=0.9195\n",
      "epoch=15, train_loss=0.0407, test_acc=0.9196\n",
      "epoch=16, train_loss=0.0404, test_acc=0.9198\n",
      "epoch=17, train_loss=0.0401, test_acc=0.9205\n",
      "epoch=18, train_loss=0.0399, test_acc=0.9169\n",
      "epoch=19, train_loss=0.0396, test_acc=0.9215\n",
      "epoch=20, train_loss=0.0385, test_acc=0.9237\n",
      "epoch=21, train_loss=0.0383, test_acc=0.9256\n",
      "epoch=22, train_loss=0.0382, test_acc=0.9249\n",
      "epoch=23, train_loss=0.0383, test_acc=0.9243\n",
      "epoch=24, train_loss=0.0383, test_acc=0.9257\n",
      "epoch=25, train_loss=0.0382, test_acc=0.9240\n",
      "epoch=26, train_loss=0.0383, test_acc=0.9254\n",
      "epoch=27, train_loss=0.0382, test_acc=0.9265\n",
      "epoch=28, train_loss=0.0382, test_acc=0.9240\n",
      "epoch=29, train_loss=0.0381, test_acc=0.9231\n",
      "epoch=30, train_loss=0.0383, test_acc=0.9253\n",
      "epoch=31, train_loss=0.0381, test_acc=0.9239\n",
      "epoch=32, train_loss=0.0381, test_acc=0.9253\n",
      "epoch=33, train_loss=0.0381, test_acc=0.9235\n",
      "epoch=34, train_loss=0.0381, test_acc=0.9217\n",
      "epoch=35, train_loss=0.0380, test_acc=0.9255\n",
      "epoch=36, train_loss=0.0380, test_acc=0.9236\n",
      "epoch=37, train_loss=0.0380, test_acc=0.9232\n",
      "epoch=38, train_loss=0.0380, test_acc=0.9250\n",
      "epoch=39, train_loss=0.0379, test_acc=0.9251\n",
      "epoch=40, train_loss=0.0378, test_acc=0.9260\n",
      "epoch=41, train_loss=0.0378, test_acc=0.9255\n",
      "epoch=42, train_loss=0.0378, test_acc=0.9242\n",
      "epoch=43, train_loss=0.0378, test_acc=0.9249\n",
      "epoch=44, train_loss=0.0378, test_acc=0.9245\n",
      "epoch=45, train_loss=0.0378, test_acc=0.9252\n",
      "epoch=46, train_loss=0.0378, test_acc=0.9248\n",
      "epoch=47, train_loss=0.0378, test_acc=0.9249\n",
      "epoch=48, train_loss=0.0378, test_acc=0.9239\n",
      "epoch=49, train_loss=0.0378, test_acc=0.9254\n",
      "epoch=50, train_loss=0.0377, test_acc=0.9248\n",
      "epoch=51, train_loss=0.0378, test_acc=0.9247\n",
      "epoch=52, train_loss=0.0378, test_acc=0.9239\n",
      "epoch=53, train_loss=0.0378, test_acc=0.9256\n",
      "epoch=54, train_loss=0.0377, test_acc=0.9243\n",
      "epoch=55, train_loss=0.0377, test_acc=0.9258\n",
      "epoch=56, train_loss=0.0378, test_acc=0.9255\n",
      "epoch=57, train_loss=0.0377, test_acc=0.9256\n",
      "epoch=58, train_loss=0.0378, test_acc=0.9259\n",
      "epoch=59, train_loss=0.0377, test_acc=0.9237\n",
      "block 12 recasting...\n",
      "block 12 training started...\n",
      "epoch=0, train_loss=0.2573, test_acc=0.8818\n",
      "epoch=1, train_loss=0.0868, test_acc=0.9144\n",
      "epoch=2, train_loss=0.0648, test_acc=0.9167\n",
      "epoch=3, train_loss=0.0570, test_acc=0.9026\n",
      "epoch=4, train_loss=0.0527, test_acc=0.9135\n",
      "epoch=5, train_loss=0.0527, test_acc=0.9165\n",
      "epoch=6, train_loss=0.0510, test_acc=0.9178\n",
      "epoch=7, train_loss=0.0499, test_acc=0.9167\n",
      "epoch=8, train_loss=0.0497, test_acc=0.9145\n",
      "epoch=9, train_loss=0.0492, test_acc=0.7920\n",
      "epoch=10, train_loss=0.0495, test_acc=0.9175\n",
      "epoch=11, train_loss=0.0482, test_acc=0.9140\n",
      "epoch=12, train_loss=0.0478, test_acc=0.9175\n",
      "epoch=13, train_loss=0.0489, test_acc=0.9190\n",
      "epoch=14, train_loss=0.0479, test_acc=0.9168\n",
      "epoch=15, train_loss=0.0474, test_acc=0.9106\n",
      "epoch=16, train_loss=0.0469, test_acc=0.9222\n",
      "epoch=17, train_loss=0.0470, test_acc=0.9063\n",
      "epoch=18, train_loss=0.0464, test_acc=0.9114\n",
      "epoch=19, train_loss=0.0461, test_acc=0.8969\n",
      "epoch=20, train_loss=0.0447, test_acc=0.9217\n",
      "epoch=21, train_loss=0.0446, test_acc=0.9240\n",
      "epoch=22, train_loss=0.0445, test_acc=0.9223\n",
      "epoch=23, train_loss=0.0445, test_acc=0.9234\n",
      "epoch=24, train_loss=0.0445, test_acc=0.9235\n",
      "epoch=25, train_loss=0.0444, test_acc=0.9231\n",
      "epoch=26, train_loss=0.0444, test_acc=0.9241\n",
      "epoch=27, train_loss=0.0444, test_acc=0.9237\n",
      "epoch=28, train_loss=0.0443, test_acc=0.9247\n",
      "epoch=29, train_loss=0.0443, test_acc=0.9239\n",
      "epoch=30, train_loss=0.0443, test_acc=0.9231\n",
      "epoch=31, train_loss=0.0443, test_acc=0.9228\n",
      "epoch=32, train_loss=0.0442, test_acc=0.9251\n",
      "epoch=33, train_loss=0.0441, test_acc=0.9221\n",
      "epoch=34, train_loss=0.0441, test_acc=0.9227\n",
      "epoch=35, train_loss=0.0442, test_acc=0.9242\n",
      "epoch=36, train_loss=0.0440, test_acc=0.9239\n",
      "epoch=37, train_loss=0.0441, test_acc=0.9244\n",
      "epoch=38, train_loss=0.0440, test_acc=0.9245\n",
      "epoch=39, train_loss=0.0439, test_acc=0.9237\n",
      "epoch=40, train_loss=0.0438, test_acc=0.9241\n",
      "epoch=41, train_loss=0.0437, test_acc=0.9240\n",
      "epoch=42, train_loss=0.0438, test_acc=0.9240\n",
      "epoch=43, train_loss=0.0437, test_acc=0.9244\n",
      "epoch=44, train_loss=0.0438, test_acc=0.9233\n",
      "epoch=45, train_loss=0.0438, test_acc=0.9239\n",
      "epoch=46, train_loss=0.0438, test_acc=0.9246\n",
      "epoch=47, train_loss=0.0437, test_acc=0.9240\n",
      "epoch=48, train_loss=0.0438, test_acc=0.9241\n",
      "epoch=49, train_loss=0.0438, test_acc=0.9241\n",
      "epoch=50, train_loss=0.0437, test_acc=0.9245\n",
      "epoch=51, train_loss=0.0436, test_acc=0.9244\n",
      "epoch=52, train_loss=0.0438, test_acc=0.9234\n",
      "epoch=53, train_loss=0.0438, test_acc=0.9238\n",
      "epoch=54, train_loss=0.0437, test_acc=0.9237\n",
      "epoch=55, train_loss=0.0437, test_acc=0.9245\n",
      "epoch=56, train_loss=0.0437, test_acc=0.9243\n",
      "epoch=57, train_loss=0.0437, test_acc=0.9243\n",
      "epoch=58, train_loss=0.0438, test_acc=0.9242\n",
      "epoch=59, train_loss=0.0437, test_acc=0.9241\n",
      "block 13 recasting...\n",
      "block 13 training started...\n",
      "epoch=0, train_loss=0.2867, test_acc=0.8786\n",
      "epoch=1, train_loss=0.1063, test_acc=0.9065\n",
      "epoch=2, train_loss=0.0807, test_acc=0.9092\n",
      "epoch=3, train_loss=0.0682, test_acc=0.9171\n",
      "epoch=4, train_loss=0.0622, test_acc=0.9162\n",
      "epoch=5, train_loss=0.0612, test_acc=0.8994\n",
      "epoch=6, train_loss=0.0594, test_acc=0.9168\n",
      "epoch=7, train_loss=0.0610, test_acc=0.9179\n",
      "epoch=8, train_loss=0.0591, test_acc=0.9194\n",
      "epoch=9, train_loss=0.0579, test_acc=0.9169\n",
      "epoch=10, train_loss=0.0574, test_acc=0.9222\n",
      "epoch=11, train_loss=0.0579, test_acc=0.9173\n",
      "epoch=12, train_loss=0.0569, test_acc=0.9125\n",
      "epoch=13, train_loss=0.0562, test_acc=0.9197\n",
      "epoch=14, train_loss=0.0558, test_acc=0.9219\n",
      "epoch=15, train_loss=0.0554, test_acc=0.9197\n",
      "epoch=16, train_loss=0.0551, test_acc=0.9161\n",
      "epoch=17, train_loss=0.0557, test_acc=0.9173\n",
      "epoch=18, train_loss=0.0548, test_acc=0.9148\n",
      "epoch=19, train_loss=0.0546, test_acc=0.9128\n",
      "epoch=20, train_loss=0.0531, test_acc=0.9233\n",
      "epoch=21, train_loss=0.0531, test_acc=0.9243\n",
      "epoch=22, train_loss=0.0531, test_acc=0.9226\n",
      "epoch=23, train_loss=0.0531, test_acc=0.9231\n",
      "epoch=24, train_loss=0.0530, test_acc=0.9236\n",
      "epoch=25, train_loss=0.0530, test_acc=0.9252\n",
      "epoch=26, train_loss=0.0529, test_acc=0.9238\n",
      "epoch=27, train_loss=0.0529, test_acc=0.9219\n",
      "epoch=28, train_loss=0.0529, test_acc=0.9233\n",
      "epoch=29, train_loss=0.0528, test_acc=0.9236\n",
      "epoch=30, train_loss=0.0528, test_acc=0.9240\n",
      "epoch=31, train_loss=0.0528, test_acc=0.9235\n",
      "epoch=32, train_loss=0.0528, test_acc=0.9228\n",
      "epoch=33, train_loss=0.0527, test_acc=0.9217\n",
      "epoch=34, train_loss=0.0527, test_acc=0.9248\n",
      "epoch=35, train_loss=0.0528, test_acc=0.9256\n",
      "epoch=36, train_loss=0.0525, test_acc=0.9244\n",
      "epoch=37, train_loss=0.0527, test_acc=0.9240\n",
      "epoch=38, train_loss=0.0526, test_acc=0.9219\n",
      "epoch=39, train_loss=0.0526, test_acc=0.9247\n",
      "epoch=40, train_loss=0.0524, test_acc=0.9251\n",
      "epoch=41, train_loss=0.0524, test_acc=0.9236\n",
      "epoch=42, train_loss=0.0524, test_acc=0.9251\n",
      "epoch=43, train_loss=0.0525, test_acc=0.9246\n",
      "epoch=44, train_loss=0.0524, test_acc=0.9243\n",
      "epoch=45, train_loss=0.0524, test_acc=0.9244\n",
      "epoch=46, train_loss=0.0524, test_acc=0.9242\n",
      "epoch=47, train_loss=0.0524, test_acc=0.9250\n",
      "epoch=48, train_loss=0.0523, test_acc=0.9250\n",
      "epoch=49, train_loss=0.0524, test_acc=0.9249\n",
      "epoch=50, train_loss=0.0524, test_acc=0.9249\n",
      "epoch=51, train_loss=0.0524, test_acc=0.9242\n",
      "epoch=52, train_loss=0.0524, test_acc=0.9247\n",
      "epoch=53, train_loss=0.0524, test_acc=0.9243\n",
      "epoch=54, train_loss=0.0523, test_acc=0.9250\n",
      "epoch=55, train_loss=0.0523, test_acc=0.9247\n",
      "epoch=56, train_loss=0.0524, test_acc=0.9251\n",
      "epoch=57, train_loss=0.0524, test_acc=0.9239\n",
      "epoch=58, train_loss=0.0523, test_acc=0.9246\n",
      "epoch=59, train_loss=0.0524, test_acc=0.9246\n",
      "block 14 recasting...\n",
      "block 14 training started...\n",
      "epoch=0, train_loss=0.3052, test_acc=0.8585\n",
      "epoch=1, train_loss=0.1057, test_acc=0.9155\n",
      "epoch=2, train_loss=0.0759, test_acc=0.9195\n",
      "epoch=3, train_loss=0.0672, test_acc=0.9135\n",
      "epoch=4, train_loss=0.0645, test_acc=0.9051\n",
      "epoch=5, train_loss=0.0604, test_acc=0.9088\n",
      "epoch=6, train_loss=0.0587, test_acc=0.9103\n",
      "epoch=7, train_loss=0.0581, test_acc=0.9141\n",
      "epoch=8, train_loss=0.0576, test_acc=0.9091\n",
      "epoch=9, train_loss=0.0580, test_acc=0.9062\n",
      "epoch=10, train_loss=0.0574, test_acc=0.9152\n",
      "epoch=11, train_loss=0.0570, test_acc=0.9174\n",
      "epoch=12, train_loss=0.0564, test_acc=0.9063\n",
      "epoch=13, train_loss=0.0563, test_acc=0.9139\n",
      "epoch=14, train_loss=0.0563, test_acc=0.9166\n",
      "epoch=15, train_loss=0.0558, test_acc=0.9140\n",
      "epoch=16, train_loss=0.0562, test_acc=0.9153\n",
      "epoch=17, train_loss=0.0553, test_acc=0.9198\n",
      "epoch=18, train_loss=0.0553, test_acc=0.9217\n",
      "epoch=19, train_loss=0.0551, test_acc=0.9209\n",
      "epoch=20, train_loss=0.0535, test_acc=0.9243\n",
      "epoch=21, train_loss=0.0534, test_acc=0.9217\n",
      "epoch=22, train_loss=0.0534, test_acc=0.9230\n",
      "epoch=23, train_loss=0.0534, test_acc=0.9230\n",
      "epoch=24, train_loss=0.0533, test_acc=0.9224\n",
      "epoch=25, train_loss=0.0533, test_acc=0.9227\n",
      "epoch=26, train_loss=0.0533, test_acc=0.9217\n",
      "epoch=27, train_loss=0.0533, test_acc=0.9210\n",
      "epoch=28, train_loss=0.0533, test_acc=0.9236\n",
      "epoch=29, train_loss=0.0532, test_acc=0.9238\n",
      "epoch=30, train_loss=0.0532, test_acc=0.9219\n",
      "epoch=31, train_loss=0.0531, test_acc=0.9228\n",
      "epoch=32, train_loss=0.0532, test_acc=0.9239\n",
      "epoch=33, train_loss=0.0532, test_acc=0.9225\n",
      "epoch=34, train_loss=0.0532, test_acc=0.9224\n",
      "epoch=35, train_loss=0.0530, test_acc=0.9238\n",
      "epoch=36, train_loss=0.0531, test_acc=0.9226\n",
      "epoch=37, train_loss=0.0531, test_acc=0.9208\n",
      "epoch=38, train_loss=0.0530, test_acc=0.9239\n",
      "epoch=39, train_loss=0.0530, test_acc=0.9228\n",
      "epoch=40, train_loss=0.0528, test_acc=0.9236\n",
      "epoch=41, train_loss=0.0528, test_acc=0.9248\n",
      "epoch=42, train_loss=0.0527, test_acc=0.9235\n",
      "epoch=43, train_loss=0.0528, test_acc=0.9233\n",
      "epoch=44, train_loss=0.0528, test_acc=0.9244\n",
      "epoch=45, train_loss=0.0528, test_acc=0.9230\n",
      "epoch=46, train_loss=0.0528, test_acc=0.9237\n",
      "epoch=47, train_loss=0.0528, test_acc=0.9231\n",
      "epoch=48, train_loss=0.0528, test_acc=0.9238\n",
      "epoch=49, train_loss=0.0528, test_acc=0.9244\n",
      "epoch=50, train_loss=0.0528, test_acc=0.9231\n",
      "epoch=51, train_loss=0.0528, test_acc=0.9234\n",
      "epoch=52, train_loss=0.0528, test_acc=0.9231\n",
      "epoch=53, train_loss=0.0527, test_acc=0.9233\n",
      "epoch=54, train_loss=0.0527, test_acc=0.9239\n",
      "epoch=55, train_loss=0.0528, test_acc=0.9229\n",
      "epoch=56, train_loss=0.0527, test_acc=0.9226\n",
      "epoch=57, train_loss=0.0527, test_acc=0.9237\n",
      "epoch=58, train_loss=0.0527, test_acc=0.9240\n",
      "epoch=59, train_loss=0.0527, test_acc=0.9236\n",
      "block 15 recasting...\n",
      "block 15 training started...\n",
      "epoch=0, train_loss=0.3330, test_acc=0.8861\n",
      "epoch=1, train_loss=0.1195, test_acc=0.9092\n",
      "epoch=2, train_loss=0.0874, test_acc=0.9137\n",
      "epoch=3, train_loss=0.0771, test_acc=0.9098\n",
      "epoch=4, train_loss=0.0739, test_acc=0.8999\n",
      "epoch=5, train_loss=0.0722, test_acc=0.8976\n",
      "epoch=6, train_loss=0.0700, test_acc=0.9118\n",
      "epoch=7, train_loss=0.0685, test_acc=0.9134\n",
      "epoch=8, train_loss=0.0674, test_acc=0.9146\n",
      "epoch=9, train_loss=0.0667, test_acc=0.8642\n",
      "epoch=10, train_loss=0.0663, test_acc=0.9172\n",
      "epoch=11, train_loss=0.0657, test_acc=0.9134\n",
      "epoch=12, train_loss=0.0652, test_acc=0.8982\n",
      "epoch=13, train_loss=0.0651, test_acc=0.9136\n",
      "epoch=14, train_loss=0.0647, test_acc=0.9124\n",
      "epoch=15, train_loss=0.0645, test_acc=0.9152\n",
      "epoch=16, train_loss=0.0642, test_acc=0.9153\n",
      "epoch=17, train_loss=0.0641, test_acc=0.8799\n",
      "epoch=18, train_loss=0.0638, test_acc=0.9150\n",
      "epoch=19, train_loss=0.0636, test_acc=0.9118\n",
      "epoch=20, train_loss=0.0618, test_acc=0.9223\n",
      "epoch=21, train_loss=0.0617, test_acc=0.9214\n",
      "epoch=22, train_loss=0.0618, test_acc=0.9210\n",
      "epoch=23, train_loss=0.0617, test_acc=0.9220\n",
      "epoch=24, train_loss=0.0617, test_acc=0.9223\n",
      "epoch=25, train_loss=0.0616, test_acc=0.9212\n",
      "epoch=26, train_loss=0.0616, test_acc=0.9210\n",
      "epoch=27, train_loss=0.0615, test_acc=0.9214\n",
      "epoch=28, train_loss=0.0616, test_acc=0.9227\n",
      "epoch=29, train_loss=0.0615, test_acc=0.9211\n",
      "epoch=30, train_loss=0.0615, test_acc=0.9231\n",
      "epoch=31, train_loss=0.0616, test_acc=0.9212\n",
      "epoch=32, train_loss=0.0614, test_acc=0.9203\n",
      "epoch=33, train_loss=0.0614, test_acc=0.9196\n",
      "epoch=34, train_loss=0.0615, test_acc=0.9219\n",
      "epoch=35, train_loss=0.0614, test_acc=0.9222\n",
      "epoch=36, train_loss=0.0614, test_acc=0.9222\n",
      "epoch=37, train_loss=0.0613, test_acc=0.9209\n",
      "epoch=38, train_loss=0.0614, test_acc=0.9229\n",
      "epoch=39, train_loss=0.0614, test_acc=0.9207\n",
      "epoch=40, train_loss=0.0611, test_acc=0.9224\n",
      "epoch=41, train_loss=0.0611, test_acc=0.9221\n",
      "epoch=42, train_loss=0.0611, test_acc=0.9234\n",
      "epoch=43, train_loss=0.0611, test_acc=0.9233\n",
      "epoch=44, train_loss=0.0611, test_acc=0.9223\n",
      "epoch=45, train_loss=0.0611, test_acc=0.9230\n",
      "epoch=46, train_loss=0.0611, test_acc=0.9229\n",
      "epoch=47, train_loss=0.0611, test_acc=0.9212\n",
      "epoch=48, train_loss=0.0612, test_acc=0.9232\n",
      "epoch=49, train_loss=0.0610, test_acc=0.9218\n",
      "epoch=50, train_loss=0.0610, test_acc=0.9217\n",
      "epoch=51, train_loss=0.0610, test_acc=0.9230\n",
      "epoch=52, train_loss=0.0610, test_acc=0.9214\n",
      "epoch=53, train_loss=0.0611, test_acc=0.9236\n",
      "epoch=54, train_loss=0.0611, test_acc=0.9221\n",
      "epoch=55, train_loss=0.0611, test_acc=0.9222\n",
      "epoch=56, train_loss=0.0611, test_acc=0.9228\n",
      "epoch=57, train_loss=0.0610, test_acc=0.9216\n",
      "epoch=58, train_loss=0.0610, test_acc=0.9222\n",
      "epoch=59, train_loss=0.0610, test_acc=0.9223\n",
      "block 16 recasting...\n",
      "block 16 training started...\n",
      "epoch=0, train_loss=0.3655, test_acc=0.8793\n",
      "epoch=1, train_loss=0.1364, test_acc=0.8889\n",
      "epoch=2, train_loss=0.0986, test_acc=0.9075\n",
      "epoch=3, train_loss=0.0853, test_acc=0.9056\n",
      "epoch=4, train_loss=0.0796, test_acc=0.9142\n",
      "epoch=5, train_loss=0.0771, test_acc=0.9181\n",
      "epoch=6, train_loss=0.0760, test_acc=0.9158\n",
      "epoch=7, train_loss=0.0728, test_acc=0.9128\n",
      "epoch=8, train_loss=0.0716, test_acc=0.9079\n",
      "epoch=9, train_loss=0.0710, test_acc=0.9090\n",
      "epoch=10, train_loss=0.0705, test_acc=0.8973\n",
      "epoch=11, train_loss=0.0697, test_acc=0.9185\n",
      "epoch=12, train_loss=0.0694, test_acc=0.9148\n",
      "epoch=13, train_loss=0.0691, test_acc=0.9117\n",
      "epoch=14, train_loss=0.0689, test_acc=0.9161\n",
      "epoch=15, train_loss=0.0686, test_acc=0.9082\n",
      "epoch=16, train_loss=0.0683, test_acc=0.8933\n",
      "epoch=17, train_loss=0.0675, test_acc=0.9082\n",
      "epoch=18, train_loss=0.0671, test_acc=0.9111\n",
      "epoch=19, train_loss=0.0668, test_acc=0.9080\n",
      "epoch=20, train_loss=0.0650, test_acc=0.9212\n",
      "epoch=21, train_loss=0.0650, test_acc=0.9231\n",
      "epoch=22, train_loss=0.0649, test_acc=0.9206\n",
      "epoch=23, train_loss=0.0649, test_acc=0.9216\n",
      "epoch=24, train_loss=0.0648, test_acc=0.9230\n",
      "epoch=25, train_loss=0.0650, test_acc=0.9204\n",
      "epoch=26, train_loss=0.0648, test_acc=0.9226\n",
      "epoch=27, train_loss=0.0648, test_acc=0.9210\n",
      "epoch=28, train_loss=0.0648, test_acc=0.9220\n",
      "epoch=29, train_loss=0.0647, test_acc=0.9211\n",
      "epoch=30, train_loss=0.0647, test_acc=0.9212\n",
      "epoch=31, train_loss=0.0647, test_acc=0.9186\n",
      "epoch=32, train_loss=0.0646, test_acc=0.9228\n",
      "epoch=33, train_loss=0.0646, test_acc=0.9213\n",
      "epoch=34, train_loss=0.0647, test_acc=0.9224\n",
      "epoch=35, train_loss=0.0645, test_acc=0.9211\n",
      "epoch=36, train_loss=0.0646, test_acc=0.9214\n",
      "epoch=37, train_loss=0.0646, test_acc=0.9200\n",
      "epoch=38, train_loss=0.0645, test_acc=0.9227\n",
      "epoch=39, train_loss=0.0645, test_acc=0.9199\n",
      "epoch=40, train_loss=0.0643, test_acc=0.9225\n",
      "epoch=41, train_loss=0.0643, test_acc=0.9220\n",
      "epoch=42, train_loss=0.0643, test_acc=0.9222\n",
      "epoch=43, train_loss=0.0643, test_acc=0.9217\n",
      "epoch=44, train_loss=0.0643, test_acc=0.9220\n",
      "epoch=45, train_loss=0.0643, test_acc=0.9226\n",
      "epoch=46, train_loss=0.0642, test_acc=0.9219\n",
      "epoch=47, train_loss=0.0642, test_acc=0.9225\n",
      "epoch=48, train_loss=0.0643, test_acc=0.9226\n",
      "epoch=49, train_loss=0.0642, test_acc=0.9225\n",
      "epoch=50, train_loss=0.0642, test_acc=0.9222\n",
      "epoch=51, train_loss=0.0642, test_acc=0.9223\n",
      "epoch=52, train_loss=0.0642, test_acc=0.9226\n",
      "epoch=53, train_loss=0.0642, test_acc=0.9225\n",
      "epoch=54, train_loss=0.0642, test_acc=0.9226\n",
      "epoch=55, train_loss=0.0642, test_acc=0.9220\n",
      "epoch=56, train_loss=0.0642, test_acc=0.9223\n",
      "epoch=57, train_loss=0.0642, test_acc=0.9218\n",
      "epoch=58, train_loss=0.0642, test_acc=0.9229\n",
      "epoch=59, train_loss=0.0641, test_acc=0.9233\n",
      "block 17 recasting...\n",
      "block 17 training started...\n",
      "epoch=0, train_loss=0.3961, test_acc=0.8077\n",
      "epoch=1, train_loss=0.1488, test_acc=0.8957\n",
      "epoch=2, train_loss=0.1103, test_acc=0.9103\n",
      "epoch=3, train_loss=0.0982, test_acc=0.9029\n",
      "epoch=4, train_loss=0.0912, test_acc=0.9153\n",
      "epoch=5, train_loss=0.0879, test_acc=0.8815\n",
      "epoch=6, train_loss=0.0880, test_acc=0.9002\n",
      "epoch=7, train_loss=0.0800, test_acc=0.9111\n",
      "epoch=8, train_loss=0.0771, test_acc=0.9142\n",
      "epoch=9, train_loss=0.0762, test_acc=0.9126\n",
      "epoch=10, train_loss=0.0765, test_acc=0.9174\n",
      "epoch=11, train_loss=0.0756, test_acc=0.9174\n",
      "epoch=12, train_loss=0.0751, test_acc=0.9142\n",
      "epoch=13, train_loss=0.0748, test_acc=0.9051\n",
      "epoch=14, train_loss=0.0747, test_acc=0.9050\n",
      "epoch=15, train_loss=0.0742, test_acc=0.9172\n",
      "epoch=16, train_loss=0.0744, test_acc=0.9124\n",
      "epoch=17, train_loss=0.0736, test_acc=0.9177\n",
      "epoch=18, train_loss=0.0736, test_acc=0.9162\n",
      "epoch=19, train_loss=0.0731, test_acc=0.9129\n",
      "epoch=20, train_loss=0.0710, test_acc=0.9187\n",
      "epoch=21, train_loss=0.0709, test_acc=0.9217\n",
      "epoch=22, train_loss=0.0709, test_acc=0.9209\n",
      "epoch=23, train_loss=0.0710, test_acc=0.9204\n",
      "epoch=24, train_loss=0.0708, test_acc=0.9201\n",
      "epoch=25, train_loss=0.0708, test_acc=0.9206\n",
      "epoch=26, train_loss=0.0708, test_acc=0.9192\n",
      "epoch=27, train_loss=0.0708, test_acc=0.9195\n",
      "epoch=28, train_loss=0.0708, test_acc=0.9203\n",
      "epoch=29, train_loss=0.0707, test_acc=0.9218\n",
      "epoch=30, train_loss=0.0707, test_acc=0.9201\n",
      "epoch=31, train_loss=0.0706, test_acc=0.9216\n",
      "epoch=32, train_loss=0.0706, test_acc=0.9186\n",
      "epoch=33, train_loss=0.0707, test_acc=0.9219\n",
      "epoch=34, train_loss=0.0706, test_acc=0.9180\n",
      "epoch=35, train_loss=0.0705, test_acc=0.9220\n",
      "epoch=36, train_loss=0.0704, test_acc=0.9210\n",
      "epoch=37, train_loss=0.0705, test_acc=0.9196\n",
      "epoch=38, train_loss=0.0704, test_acc=0.9179\n",
      "epoch=39, train_loss=0.0704, test_acc=0.9199\n",
      "epoch=40, train_loss=0.0702, test_acc=0.9215\n",
      "epoch=41, train_loss=0.0701, test_acc=0.9217\n",
      "epoch=42, train_loss=0.0702, test_acc=0.9217\n",
      "epoch=43, train_loss=0.0702, test_acc=0.9217\n",
      "epoch=44, train_loss=0.0702, test_acc=0.9218\n",
      "epoch=45, train_loss=0.0702, test_acc=0.9215\n",
      "epoch=46, train_loss=0.0702, test_acc=0.9207\n",
      "epoch=47, train_loss=0.0701, test_acc=0.9211\n",
      "epoch=48, train_loss=0.0701, test_acc=0.9224\n",
      "epoch=49, train_loss=0.0702, test_acc=0.9217\n",
      "epoch=50, train_loss=0.0701, test_acc=0.9219\n",
      "epoch=51, train_loss=0.0702, test_acc=0.9227\n",
      "epoch=52, train_loss=0.0702, test_acc=0.9224\n",
      "epoch=53, train_loss=0.0701, test_acc=0.9220\n",
      "epoch=54, train_loss=0.0701, test_acc=0.9224\n",
      "epoch=55, train_loss=0.0702, test_acc=0.9229\n",
      "epoch=56, train_loss=0.0702, test_acc=0.9212\n",
      "epoch=57, train_loss=0.0701, test_acc=0.9219\n",
      "epoch=58, train_loss=0.0701, test_acc=0.9218\n",
      "epoch=59, train_loss=0.0701, test_acc=0.9226\n",
      "block 18 recasting...\n",
      "block 18 training started...\n",
      "epoch=0, train_loss=0.0704, test_acc=0.8848\n",
      "epoch=1, train_loss=0.0330, test_acc=0.8933\n",
      "epoch=2, train_loss=0.0299, test_acc=0.8842\n",
      "epoch=3, train_loss=0.0284, test_acc=0.9137\n",
      "epoch=4, train_loss=0.0277, test_acc=0.9102\n",
      "epoch=5, train_loss=0.0272, test_acc=0.8984\n",
      "epoch=6, train_loss=0.0274, test_acc=0.9030\n",
      "epoch=7, train_loss=0.0267, test_acc=0.9161\n",
      "epoch=8, train_loss=0.0261, test_acc=0.9161\n",
      "epoch=9, train_loss=0.0258, test_acc=0.9085\n",
      "epoch=10, train_loss=0.0256, test_acc=0.9086\n",
      "epoch=11, train_loss=0.0253, test_acc=0.9139\n",
      "epoch=12, train_loss=0.0252, test_acc=0.9157\n",
      "epoch=13, train_loss=0.0250, test_acc=0.9130\n",
      "epoch=14, train_loss=0.0248, test_acc=0.9128\n",
      "epoch=15, train_loss=0.0248, test_acc=0.9118\n",
      "epoch=16, train_loss=0.0245, test_acc=0.8949\n",
      "epoch=17, train_loss=0.0247, test_acc=0.9146\n",
      "epoch=18, train_loss=0.0244, test_acc=0.9101\n",
      "epoch=19, train_loss=0.0243, test_acc=0.9091\n",
      "epoch=20, train_loss=0.0232, test_acc=0.9207\n",
      "epoch=21, train_loss=0.0232, test_acc=0.9204\n",
      "epoch=22, train_loss=0.0232, test_acc=0.9202\n",
      "epoch=23, train_loss=0.0231, test_acc=0.9209\n",
      "epoch=24, train_loss=0.0232, test_acc=0.9217\n",
      "epoch=25, train_loss=0.0231, test_acc=0.9165\n",
      "epoch=26, train_loss=0.0231, test_acc=0.9219\n",
      "epoch=27, train_loss=0.0231, test_acc=0.9204\n",
      "epoch=28, train_loss=0.0231, test_acc=0.9213\n",
      "epoch=29, train_loss=0.0230, test_acc=0.9209\n",
      "epoch=30, train_loss=0.0231, test_acc=0.9200\n",
      "epoch=31, train_loss=0.0230, test_acc=0.9213\n",
      "epoch=32, train_loss=0.0230, test_acc=0.9198\n",
      "epoch=33, train_loss=0.0230, test_acc=0.9219\n",
      "epoch=34, train_loss=0.0229, test_acc=0.9208\n",
      "epoch=35, train_loss=0.0229, test_acc=0.9203\n",
      "epoch=36, train_loss=0.0229, test_acc=0.9214\n",
      "epoch=37, train_loss=0.0229, test_acc=0.9204\n",
      "epoch=38, train_loss=0.0229, test_acc=0.9223\n",
      "epoch=39, train_loss=0.0229, test_acc=0.9220\n",
      "epoch=40, train_loss=0.0227, test_acc=0.9209\n",
      "epoch=41, train_loss=0.0227, test_acc=0.9211\n",
      "epoch=42, train_loss=0.0227, test_acc=0.9221\n",
      "epoch=43, train_loss=0.0228, test_acc=0.9217\n",
      "epoch=44, train_loss=0.0227, test_acc=0.9205\n",
      "epoch=45, train_loss=0.0227, test_acc=0.9220\n",
      "epoch=46, train_loss=0.0227, test_acc=0.9216\n",
      "epoch=47, train_loss=0.0227, test_acc=0.9214\n",
      "epoch=48, train_loss=0.0227, test_acc=0.9222\n",
      "epoch=49, train_loss=0.0227, test_acc=0.9218\n",
      "epoch=50, train_loss=0.0227, test_acc=0.9214\n",
      "epoch=51, train_loss=0.0227, test_acc=0.9216\n",
      "epoch=52, train_loss=0.0227, test_acc=0.9207\n",
      "epoch=53, train_loss=0.0227, test_acc=0.9209\n",
      "epoch=54, train_loss=0.0227, test_acc=0.9216\n",
      "epoch=55, train_loss=0.0227, test_acc=0.9217\n",
      "epoch=56, train_loss=0.0227, test_acc=0.9229\n",
      "epoch=57, train_loss=0.0227, test_acc=0.9213\n",
      "epoch=58, train_loss=0.0227, test_acc=0.9213\n",
      "epoch=59, train_loss=0.0227, test_acc=0.9213\n",
      "block 19 recasting...\n",
      "block 19 training started...\n",
      "epoch=0, train_loss=0.0902, test_acc=0.8859\n",
      "epoch=1, train_loss=0.0508, test_acc=0.8351\n",
      "epoch=2, train_loss=0.0466, test_acc=0.9097\n",
      "epoch=3, train_loss=0.0445, test_acc=0.9108\n",
      "epoch=4, train_loss=0.0431, test_acc=0.8817\n",
      "epoch=5, train_loss=0.0422, test_acc=0.9086\n",
      "epoch=6, train_loss=0.0415, test_acc=0.9073\n",
      "epoch=7, train_loss=0.0411, test_acc=0.9010\n",
      "epoch=8, train_loss=0.0405, test_acc=0.9166\n",
      "epoch=9, train_loss=0.0401, test_acc=0.8924\n",
      "epoch=10, train_loss=0.0396, test_acc=0.9135\n",
      "epoch=11, train_loss=0.0393, test_acc=0.9170\n",
      "epoch=12, train_loss=0.0391, test_acc=0.9144\n",
      "epoch=13, train_loss=0.0387, test_acc=0.9108\n",
      "epoch=14, train_loss=0.0384, test_acc=0.9173\n",
      "epoch=15, train_loss=0.0382, test_acc=0.9014\n",
      "epoch=16, train_loss=0.0380, test_acc=0.9194\n",
      "epoch=17, train_loss=0.0379, test_acc=0.9131\n",
      "epoch=18, train_loss=0.0377, test_acc=0.9098\n",
      "epoch=19, train_loss=0.0376, test_acc=0.9116\n",
      "epoch=20, train_loss=0.0363, test_acc=0.9215\n",
      "epoch=21, train_loss=0.0362, test_acc=0.9231\n",
      "epoch=22, train_loss=0.0362, test_acc=0.9218\n",
      "epoch=23, train_loss=0.0362, test_acc=0.9209\n",
      "epoch=24, train_loss=0.0362, test_acc=0.9209\n",
      "epoch=25, train_loss=0.0362, test_acc=0.9225\n",
      "epoch=26, train_loss=0.0361, test_acc=0.9215\n",
      "epoch=27, train_loss=0.0360, test_acc=0.9214\n",
      "epoch=28, train_loss=0.0360, test_acc=0.9224\n",
      "epoch=29, train_loss=0.0361, test_acc=0.9207\n",
      "epoch=30, train_loss=0.0360, test_acc=0.9208\n",
      "epoch=31, train_loss=0.0360, test_acc=0.9213\n",
      "epoch=32, train_loss=0.0360, test_acc=0.9207\n",
      "epoch=33, train_loss=0.0360, test_acc=0.9207\n",
      "epoch=34, train_loss=0.0359, test_acc=0.9211\n",
      "epoch=35, train_loss=0.0359, test_acc=0.9221\n",
      "epoch=36, train_loss=0.0359, test_acc=0.9209\n",
      "epoch=37, train_loss=0.0359, test_acc=0.9218\n",
      "epoch=38, train_loss=0.0359, test_acc=0.9230\n",
      "epoch=39, train_loss=0.0358, test_acc=0.9197\n",
      "epoch=40, train_loss=0.0357, test_acc=0.9213\n",
      "epoch=41, train_loss=0.0356, test_acc=0.9220\n",
      "epoch=42, train_loss=0.0357, test_acc=0.9221\n",
      "epoch=43, train_loss=0.0357, test_acc=0.9212\n",
      "epoch=44, train_loss=0.0357, test_acc=0.9221\n",
      "epoch=45, train_loss=0.0357, test_acc=0.9221\n",
      "epoch=46, train_loss=0.0356, test_acc=0.9213\n",
      "epoch=47, train_loss=0.0356, test_acc=0.9222\n",
      "epoch=48, train_loss=0.0357, test_acc=0.9216\n",
      "epoch=49, train_loss=0.0356, test_acc=0.9225\n",
      "epoch=50, train_loss=0.0356, test_acc=0.9207\n",
      "epoch=51, train_loss=0.0357, test_acc=0.9215\n",
      "epoch=52, train_loss=0.0357, test_acc=0.9219\n",
      "epoch=53, train_loss=0.0356, test_acc=0.9212\n",
      "epoch=54, train_loss=0.0357, test_acc=0.9213\n",
      "epoch=55, train_loss=0.0357, test_acc=0.9224\n",
      "epoch=56, train_loss=0.0357, test_acc=0.9209\n",
      "epoch=57, train_loss=0.0357, test_acc=0.9221\n",
      "epoch=58, train_loss=0.0356, test_acc=0.9219\n",
      "epoch=59, train_loss=0.0356, test_acc=0.9212\n",
      "block 20 recasting...\n",
      "block 20 training started...\n",
      "epoch=0, train_loss=0.1038, test_acc=0.9052\n",
      "epoch=1, train_loss=0.0644, test_acc=0.9067\n",
      "epoch=2, train_loss=0.0607, test_acc=0.8811\n",
      "epoch=3, train_loss=0.0591, test_acc=0.9030\n",
      "epoch=4, train_loss=0.0581, test_acc=0.8971\n",
      "epoch=5, train_loss=0.0573, test_acc=0.8990\n",
      "epoch=6, train_loss=0.0568, test_acc=0.9103\n",
      "epoch=7, train_loss=0.0561, test_acc=0.9046\n",
      "epoch=8, train_loss=0.0557, test_acc=0.9047\n",
      "epoch=9, train_loss=0.0555, test_acc=0.9102\n",
      "epoch=10, train_loss=0.0553, test_acc=0.9125\n",
      "epoch=11, train_loss=0.0550, test_acc=0.9127\n",
      "epoch=12, train_loss=0.0547, test_acc=0.9093\n",
      "epoch=13, train_loss=0.0545, test_acc=0.9101\n",
      "epoch=14, train_loss=0.0544, test_acc=0.9038\n",
      "epoch=15, train_loss=0.0543, test_acc=0.9080\n",
      "epoch=16, train_loss=0.0542, test_acc=0.9113\n",
      "epoch=17, train_loss=0.0539, test_acc=0.9121\n",
      "epoch=18, train_loss=0.0538, test_acc=0.9118\n",
      "epoch=19, train_loss=0.0536, test_acc=0.9079\n",
      "epoch=20, train_loss=0.0519, test_acc=0.9203\n",
      "epoch=21, train_loss=0.0517, test_acc=0.9211\n",
      "epoch=22, train_loss=0.0517, test_acc=0.9196\n",
      "epoch=23, train_loss=0.0517, test_acc=0.9178\n",
      "epoch=24, train_loss=0.0516, test_acc=0.9218\n",
      "epoch=25, train_loss=0.0517, test_acc=0.9207\n",
      "epoch=26, train_loss=0.0516, test_acc=0.9196\n",
      "epoch=27, train_loss=0.0516, test_acc=0.9208\n",
      "epoch=28, train_loss=0.0516, test_acc=0.9187\n",
      "epoch=29, train_loss=0.0516, test_acc=0.9193\n",
      "epoch=30, train_loss=0.0515, test_acc=0.9185\n",
      "epoch=31, train_loss=0.0515, test_acc=0.9216\n",
      "epoch=32, train_loss=0.0515, test_acc=0.9190\n",
      "epoch=33, train_loss=0.0515, test_acc=0.9206\n",
      "epoch=34, train_loss=0.0515, test_acc=0.9186\n",
      "epoch=35, train_loss=0.0515, test_acc=0.9205\n",
      "epoch=36, train_loss=0.0514, test_acc=0.9204\n",
      "epoch=37, train_loss=0.0514, test_acc=0.9205\n",
      "epoch=38, train_loss=0.0514, test_acc=0.9195\n",
      "epoch=39, train_loss=0.0514, test_acc=0.9204\n",
      "epoch=40, train_loss=0.0512, test_acc=0.9212\n",
      "epoch=41, train_loss=0.0512, test_acc=0.9219\n",
      "epoch=42, train_loss=0.0512, test_acc=0.9210\n",
      "epoch=43, train_loss=0.0512, test_acc=0.9206\n",
      "epoch=44, train_loss=0.0511, test_acc=0.9218\n",
      "epoch=45, train_loss=0.0511, test_acc=0.9209\n",
      "epoch=46, train_loss=0.0511, test_acc=0.9212\n",
      "epoch=47, train_loss=0.0511, test_acc=0.9207\n",
      "epoch=48, train_loss=0.0511, test_acc=0.9212\n",
      "epoch=49, train_loss=0.0511, test_acc=0.9204\n",
      "epoch=50, train_loss=0.0511, test_acc=0.9213\n",
      "epoch=51, train_loss=0.0511, test_acc=0.9212\n",
      "epoch=52, train_loss=0.0511, test_acc=0.9215\n",
      "epoch=53, train_loss=0.0511, test_acc=0.9205\n",
      "epoch=54, train_loss=0.0511, test_acc=0.9208\n",
      "epoch=55, train_loss=0.0511, test_acc=0.9201\n",
      "epoch=56, train_loss=0.0511, test_acc=0.9208\n",
      "epoch=57, train_loss=0.0510, test_acc=0.9208\n",
      "epoch=58, train_loss=0.0511, test_acc=0.9214\n",
      "epoch=59, train_loss=0.0511, test_acc=0.9202\n",
      "block 21 recasting...\n",
      "block 21 training started...\n",
      "epoch=0, train_loss=0.1089, test_acc=0.8591\n",
      "epoch=1, train_loss=0.0678, test_acc=0.9047\n",
      "epoch=2, train_loss=0.0639, test_acc=0.9008\n",
      "epoch=3, train_loss=0.0624, test_acc=0.8732\n",
      "epoch=4, train_loss=0.0619, test_acc=0.9016\n",
      "epoch=5, train_loss=0.0608, test_acc=0.9132\n",
      "epoch=6, train_loss=0.0603, test_acc=0.9038\n",
      "epoch=7, train_loss=0.0599, test_acc=0.9105\n",
      "epoch=8, train_loss=0.0595, test_acc=0.9049\n",
      "epoch=9, train_loss=0.0594, test_acc=0.9103\n",
      "epoch=10, train_loss=0.0591, test_acc=0.9073\n",
      "epoch=11, train_loss=0.0588, test_acc=0.9120\n",
      "epoch=12, train_loss=0.0586, test_acc=0.9090\n",
      "epoch=13, train_loss=0.0583, test_acc=0.9021\n",
      "epoch=14, train_loss=0.0582, test_acc=0.9135\n",
      "epoch=15, train_loss=0.0581, test_acc=0.9092\n",
      "epoch=16, train_loss=0.0579, test_acc=0.9028\n",
      "epoch=17, train_loss=0.0578, test_acc=0.9026\n",
      "epoch=18, train_loss=0.0577, test_acc=0.8944\n",
      "epoch=19, train_loss=0.0576, test_acc=0.8873\n",
      "epoch=20, train_loss=0.0557, test_acc=0.9168\n",
      "epoch=21, train_loss=0.0556, test_acc=0.9181\n",
      "epoch=22, train_loss=0.0555, test_acc=0.9175\n",
      "epoch=23, train_loss=0.0555, test_acc=0.9167\n",
      "epoch=24, train_loss=0.0554, test_acc=0.9161\n",
      "epoch=25, train_loss=0.0554, test_acc=0.9150\n",
      "epoch=26, train_loss=0.0554, test_acc=0.9173\n",
      "epoch=27, train_loss=0.0555, test_acc=0.9175\n",
      "epoch=28, train_loss=0.0554, test_acc=0.9179\n",
      "epoch=29, train_loss=0.0554, test_acc=0.9162\n",
      "epoch=30, train_loss=0.0553, test_acc=0.9165\n",
      "epoch=31, train_loss=0.0553, test_acc=0.9177\n",
      "epoch=32, train_loss=0.0553, test_acc=0.9158\n",
      "epoch=33, train_loss=0.0553, test_acc=0.9190\n",
      "epoch=34, train_loss=0.0553, test_acc=0.9168\n",
      "epoch=35, train_loss=0.0553, test_acc=0.9183\n",
      "epoch=36, train_loss=0.0553, test_acc=0.9174\n",
      "epoch=37, train_loss=0.0552, test_acc=0.9170\n",
      "epoch=38, train_loss=0.0552, test_acc=0.9159\n",
      "epoch=39, train_loss=0.0552, test_acc=0.9171\n",
      "epoch=40, train_loss=0.0550, test_acc=0.9175\n",
      "epoch=41, train_loss=0.0550, test_acc=0.9177\n",
      "epoch=42, train_loss=0.0550, test_acc=0.9191\n",
      "epoch=43, train_loss=0.0549, test_acc=0.9183\n",
      "epoch=44, train_loss=0.0549, test_acc=0.9192\n",
      "epoch=45, train_loss=0.0549, test_acc=0.9183\n",
      "epoch=46, train_loss=0.0549, test_acc=0.9188\n",
      "epoch=47, train_loss=0.0550, test_acc=0.9195\n",
      "epoch=48, train_loss=0.0549, test_acc=0.9181\n",
      "epoch=49, train_loss=0.0550, test_acc=0.9195\n",
      "epoch=50, train_loss=0.0549, test_acc=0.9198\n",
      "epoch=51, train_loss=0.0549, test_acc=0.9183\n",
      "epoch=52, train_loss=0.0550, test_acc=0.9185\n",
      "epoch=53, train_loss=0.0549, test_acc=0.9184\n",
      "epoch=54, train_loss=0.0549, test_acc=0.9185\n",
      "epoch=55, train_loss=0.0549, test_acc=0.9172\n",
      "epoch=56, train_loss=0.0549, test_acc=0.9178\n",
      "epoch=57, train_loss=0.0549, test_acc=0.9178\n",
      "epoch=58, train_loss=0.0550, test_acc=0.9177\n",
      "epoch=59, train_loss=0.0549, test_acc=0.9193\n",
      "block 22 recasting...\n",
      "block 22 training started...\n",
      "epoch=0, train_loss=0.1104, test_acc=0.8832\n",
      "epoch=1, train_loss=0.0685, test_acc=0.8982\n",
      "epoch=2, train_loss=0.0643, test_acc=0.9053\n",
      "epoch=3, train_loss=0.0627, test_acc=0.8840\n",
      "epoch=4, train_loss=0.0621, test_acc=0.9028\n",
      "epoch=5, train_loss=0.0614, test_acc=0.8897\n",
      "epoch=6, train_loss=0.0610, test_acc=0.9014\n",
      "epoch=7, train_loss=0.0605, test_acc=0.9052\n",
      "epoch=8, train_loss=0.0603, test_acc=0.9139\n",
      "epoch=9, train_loss=0.0602, test_acc=0.9045\n",
      "epoch=10, train_loss=0.0598, test_acc=0.9103\n",
      "epoch=11, train_loss=0.0596, test_acc=0.9061\n",
      "epoch=12, train_loss=0.0594, test_acc=0.9006\n",
      "epoch=13, train_loss=0.0592, test_acc=0.9075\n",
      "epoch=14, train_loss=0.0591, test_acc=0.9147\n",
      "epoch=15, train_loss=0.0590, test_acc=0.8997\n",
      "epoch=16, train_loss=0.0588, test_acc=0.9079\n",
      "epoch=17, train_loss=0.0586, test_acc=0.9091\n",
      "epoch=18, train_loss=0.0584, test_acc=0.9025\n",
      "epoch=19, train_loss=0.0583, test_acc=0.9048\n",
      "epoch=20, train_loss=0.0565, test_acc=0.9178\n",
      "epoch=21, train_loss=0.0564, test_acc=0.9174\n",
      "epoch=22, train_loss=0.0563, test_acc=0.9170\n",
      "epoch=23, train_loss=0.0563, test_acc=0.9135\n",
      "epoch=24, train_loss=0.0563, test_acc=0.9164\n",
      "epoch=25, train_loss=0.0563, test_acc=0.9174\n",
      "epoch=26, train_loss=0.0562, test_acc=0.9172\n",
      "epoch=27, train_loss=0.0562, test_acc=0.9171\n",
      "epoch=28, train_loss=0.0562, test_acc=0.9183\n",
      "epoch=29, train_loss=0.0562, test_acc=0.9190\n",
      "epoch=30, train_loss=0.0562, test_acc=0.9180\n",
      "epoch=31, train_loss=0.0562, test_acc=0.9171\n",
      "epoch=32, train_loss=0.0561, test_acc=0.9162\n",
      "epoch=33, train_loss=0.0561, test_acc=0.9170\n",
      "epoch=34, train_loss=0.0561, test_acc=0.9147\n",
      "epoch=35, train_loss=0.0561, test_acc=0.9142\n",
      "epoch=36, train_loss=0.0560, test_acc=0.9156\n",
      "epoch=37, train_loss=0.0561, test_acc=0.9166\n",
      "epoch=38, train_loss=0.0560, test_acc=0.9168\n",
      "epoch=39, train_loss=0.0560, test_acc=0.9165\n",
      "epoch=40, train_loss=0.0558, test_acc=0.9170\n",
      "epoch=41, train_loss=0.0557, test_acc=0.9187\n",
      "epoch=42, train_loss=0.0557, test_acc=0.9186\n",
      "epoch=43, train_loss=0.0558, test_acc=0.9169\n",
      "epoch=44, train_loss=0.0557, test_acc=0.9174\n",
      "epoch=45, train_loss=0.0558, test_acc=0.9183\n",
      "epoch=46, train_loss=0.0558, test_acc=0.9176\n",
      "epoch=47, train_loss=0.0557, test_acc=0.9174\n",
      "epoch=48, train_loss=0.0558, test_acc=0.9173\n",
      "epoch=49, train_loss=0.0558, test_acc=0.9169\n",
      "epoch=50, train_loss=0.0558, test_acc=0.9168\n",
      "epoch=51, train_loss=0.0557, test_acc=0.9177\n",
      "epoch=52, train_loss=0.0557, test_acc=0.9184\n",
      "epoch=53, train_loss=0.0558, test_acc=0.9169\n",
      "epoch=54, train_loss=0.0558, test_acc=0.9179\n",
      "epoch=55, train_loss=0.0557, test_acc=0.9166\n",
      "epoch=56, train_loss=0.0557, test_acc=0.9175\n",
      "epoch=57, train_loss=0.0557, test_acc=0.9180\n",
      "epoch=58, train_loss=0.0557, test_acc=0.9180\n",
      "epoch=59, train_loss=0.0557, test_acc=0.9194\n",
      "block 23 recasting...\n",
      "block 23 training started...\n",
      "epoch=0, train_loss=0.1089, test_acc=0.8742\n",
      "epoch=1, train_loss=0.0679, test_acc=0.8951\n",
      "epoch=2, train_loss=0.0626, test_acc=0.9003\n",
      "epoch=3, train_loss=0.0605, test_acc=0.8965\n",
      "epoch=4, train_loss=0.0595, test_acc=0.8999\n",
      "epoch=5, train_loss=0.0589, test_acc=0.8931\n",
      "epoch=6, train_loss=0.0584, test_acc=0.8925\n",
      "epoch=7, train_loss=0.0580, test_acc=0.8928\n",
      "epoch=8, train_loss=0.0578, test_acc=0.8909\n",
      "epoch=9, train_loss=0.0574, test_acc=0.8998\n",
      "epoch=10, train_loss=0.0572, test_acc=0.9007\n",
      "epoch=11, train_loss=0.0571, test_acc=0.8738\n",
      "epoch=12, train_loss=0.0569, test_acc=0.9024\n",
      "epoch=13, train_loss=0.0567, test_acc=0.8956\n",
      "epoch=14, train_loss=0.0566, test_acc=0.8707\n",
      "epoch=15, train_loss=0.0565, test_acc=0.8811\n",
      "epoch=16, train_loss=0.0563, test_acc=0.8976\n",
      "epoch=17, train_loss=0.0563, test_acc=0.9000\n",
      "epoch=18, train_loss=0.0561, test_acc=0.9085\n",
      "epoch=19, train_loss=0.0560, test_acc=0.8917\n",
      "epoch=20, train_loss=0.0542, test_acc=0.9118\n",
      "epoch=21, train_loss=0.0541, test_acc=0.9148\n",
      "epoch=22, train_loss=0.0540, test_acc=0.9124\n",
      "epoch=23, train_loss=0.0539, test_acc=0.9148\n",
      "epoch=24, train_loss=0.0539, test_acc=0.9122\n",
      "epoch=25, train_loss=0.0538, test_acc=0.9121\n",
      "epoch=26, train_loss=0.0539, test_acc=0.9118\n",
      "epoch=27, train_loss=0.0538, test_acc=0.9149\n",
      "epoch=28, train_loss=0.0538, test_acc=0.9127\n",
      "epoch=29, train_loss=0.0538, test_acc=0.9136\n",
      "epoch=30, train_loss=0.0538, test_acc=0.9125\n",
      "epoch=31, train_loss=0.0538, test_acc=0.9145\n",
      "epoch=32, train_loss=0.0538, test_acc=0.9124\n",
      "epoch=33, train_loss=0.0537, test_acc=0.9146\n",
      "epoch=34, train_loss=0.0537, test_acc=0.9135\n",
      "epoch=35, train_loss=0.0538, test_acc=0.9146\n",
      "epoch=36, train_loss=0.0538, test_acc=0.9154\n",
      "epoch=37, train_loss=0.0537, test_acc=0.9152\n",
      "epoch=38, train_loss=0.0537, test_acc=0.9110\n",
      "epoch=39, train_loss=0.0537, test_acc=0.9139\n",
      "epoch=40, train_loss=0.0535, test_acc=0.9135\n",
      "epoch=41, train_loss=0.0534, test_acc=0.9159\n",
      "epoch=42, train_loss=0.0534, test_acc=0.9159\n",
      "epoch=43, train_loss=0.0534, test_acc=0.9134\n",
      "epoch=44, train_loss=0.0534, test_acc=0.9133\n",
      "epoch=45, train_loss=0.0534, test_acc=0.9138\n",
      "epoch=46, train_loss=0.0534, test_acc=0.9138\n",
      "epoch=47, train_loss=0.0534, test_acc=0.9150\n",
      "epoch=48, train_loss=0.0534, test_acc=0.9144\n",
      "epoch=49, train_loss=0.0534, test_acc=0.9144\n",
      "epoch=50, train_loss=0.0534, test_acc=0.9140\n",
      "epoch=51, train_loss=0.0533, test_acc=0.9149\n",
      "epoch=52, train_loss=0.0534, test_acc=0.9151\n",
      "epoch=53, train_loss=0.0534, test_acc=0.9151\n",
      "epoch=54, train_loss=0.0534, test_acc=0.9146\n",
      "epoch=55, train_loss=0.0534, test_acc=0.9145\n",
      "epoch=56, train_loss=0.0533, test_acc=0.9156\n",
      "epoch=57, train_loss=0.0534, test_acc=0.9149\n",
      "epoch=58, train_loss=0.0533, test_acc=0.9155\n",
      "epoch=59, train_loss=0.0534, test_acc=0.9153\n",
      "block 24 recasting...\n",
      "block 24 training started...\n",
      "epoch=0, train_loss=0.1079, test_acc=0.8587\n",
      "epoch=1, train_loss=0.0676, test_acc=0.8808\n",
      "epoch=2, train_loss=0.0628, test_acc=0.8954\n",
      "epoch=3, train_loss=0.0606, test_acc=0.8845\n",
      "epoch=4, train_loss=0.0594, test_acc=0.8964\n",
      "epoch=5, train_loss=0.0587, test_acc=0.9000\n",
      "epoch=6, train_loss=0.0581, test_acc=0.9011\n",
      "epoch=7, train_loss=0.0577, test_acc=0.8937\n",
      "epoch=8, train_loss=0.0574, test_acc=0.8859\n",
      "epoch=9, train_loss=0.0571, test_acc=0.8816\n",
      "epoch=10, train_loss=0.0569, test_acc=0.9012\n",
      "epoch=11, train_loss=0.0568, test_acc=0.8906\n",
      "epoch=12, train_loss=0.0565, test_acc=0.8897\n",
      "epoch=13, train_loss=0.0564, test_acc=0.8909\n",
      "epoch=14, train_loss=0.0563, test_acc=0.8983\n",
      "epoch=15, train_loss=0.0561, test_acc=0.8883\n",
      "epoch=16, train_loss=0.0559, test_acc=0.8726\n",
      "epoch=17, train_loss=0.0559, test_acc=0.8965\n",
      "epoch=18, train_loss=0.0558, test_acc=0.8849\n",
      "epoch=19, train_loss=0.0558, test_acc=0.8969\n",
      "epoch=20, train_loss=0.0538, test_acc=0.9131\n",
      "epoch=21, train_loss=0.0536, test_acc=0.9088\n",
      "epoch=22, train_loss=0.0536, test_acc=0.9109\n",
      "epoch=23, train_loss=0.0535, test_acc=0.9116\n",
      "epoch=24, train_loss=0.0535, test_acc=0.9101\n",
      "epoch=25, train_loss=0.0535, test_acc=0.9094\n",
      "epoch=26, train_loss=0.0535, test_acc=0.9110\n",
      "epoch=27, train_loss=0.0534, test_acc=0.9106\n",
      "epoch=28, train_loss=0.0535, test_acc=0.9095\n",
      "epoch=29, train_loss=0.0534, test_acc=0.9108\n",
      "epoch=30, train_loss=0.0534, test_acc=0.9105\n",
      "epoch=31, train_loss=0.0533, test_acc=0.9059\n",
      "epoch=32, train_loss=0.0534, test_acc=0.9099\n",
      "epoch=33, train_loss=0.0534, test_acc=0.9129\n",
      "epoch=34, train_loss=0.0533, test_acc=0.9072\n",
      "epoch=35, train_loss=0.0533, test_acc=0.9124\n",
      "epoch=36, train_loss=0.0534, test_acc=0.9103\n",
      "epoch=37, train_loss=0.0533, test_acc=0.9113\n",
      "epoch=38, train_loss=0.0533, test_acc=0.9092\n",
      "epoch=39, train_loss=0.0533, test_acc=0.9114\n",
      "epoch=40, train_loss=0.0531, test_acc=0.9117\n",
      "epoch=41, train_loss=0.0530, test_acc=0.9120\n",
      "epoch=42, train_loss=0.0530, test_acc=0.9108\n",
      "epoch=43, train_loss=0.0530, test_acc=0.9113\n",
      "epoch=44, train_loss=0.0530, test_acc=0.9123\n",
      "epoch=45, train_loss=0.0530, test_acc=0.9112\n",
      "epoch=46, train_loss=0.0530, test_acc=0.9118\n",
      "epoch=47, train_loss=0.0529, test_acc=0.9112\n",
      "epoch=48, train_loss=0.0530, test_acc=0.9110\n",
      "epoch=49, train_loss=0.0530, test_acc=0.9111\n",
      "epoch=50, train_loss=0.0530, test_acc=0.9109\n",
      "epoch=51, train_loss=0.0530, test_acc=0.9115\n",
      "epoch=52, train_loss=0.0529, test_acc=0.9113\n",
      "epoch=53, train_loss=0.0530, test_acc=0.9097\n",
      "epoch=54, train_loss=0.0530, test_acc=0.9106\n",
      "epoch=55, train_loss=0.0531, test_acc=0.9102\n",
      "epoch=56, train_loss=0.0531, test_acc=0.9116\n",
      "epoch=57, train_loss=0.0530, test_acc=0.9118\n",
      "epoch=58, train_loss=0.0531, test_acc=0.9113\n",
      "epoch=59, train_loss=0.0530, test_acc=0.9132\n",
      "block 25 recasting...\n",
      "block 25 training started...\n",
      "epoch=0, train_loss=0.1049, test_acc=0.8542\n",
      "epoch=1, train_loss=0.0649, test_acc=0.8865\n",
      "epoch=2, train_loss=0.0606, test_acc=0.8200\n",
      "epoch=3, train_loss=0.0588, test_acc=0.8808\n",
      "epoch=4, train_loss=0.0578, test_acc=0.8840\n",
      "epoch=5, train_loss=0.0569, test_acc=0.8729\n",
      "epoch=6, train_loss=0.0565, test_acc=0.8751\n",
      "epoch=7, train_loss=0.0561, test_acc=0.8787\n",
      "epoch=8, train_loss=0.0558, test_acc=0.8925\n",
      "epoch=9, train_loss=0.0556, test_acc=0.8901\n",
      "epoch=10, train_loss=0.0553, test_acc=0.8880\n",
      "epoch=11, train_loss=0.0551, test_acc=0.8701\n",
      "epoch=12, train_loss=0.0549, test_acc=0.8922\n",
      "epoch=13, train_loss=0.0548, test_acc=0.8793\n",
      "epoch=14, train_loss=0.0546, test_acc=0.8818\n",
      "epoch=15, train_loss=0.0544, test_acc=0.8742\n",
      "epoch=16, train_loss=0.0544, test_acc=0.9033\n",
      "epoch=17, train_loss=0.0543, test_acc=0.8866\n",
      "epoch=18, train_loss=0.0543, test_acc=0.8468\n",
      "epoch=19, train_loss=0.0541, test_acc=0.8933\n",
      "epoch=20, train_loss=0.0521, test_acc=0.9117\n",
      "epoch=21, train_loss=0.0518, test_acc=0.9123\n",
      "epoch=22, train_loss=0.0518, test_acc=0.9115\n",
      "epoch=23, train_loss=0.0517, test_acc=0.9104\n",
      "epoch=24, train_loss=0.0516, test_acc=0.9118\n",
      "epoch=25, train_loss=0.0517, test_acc=0.9125\n",
      "epoch=26, train_loss=0.0516, test_acc=0.9103\n",
      "epoch=27, train_loss=0.0516, test_acc=0.9114\n",
      "epoch=28, train_loss=0.0516, test_acc=0.9102\n",
      "epoch=29, train_loss=0.0515, test_acc=0.9134\n",
      "epoch=30, train_loss=0.0515, test_acc=0.9116\n",
      "epoch=31, train_loss=0.0515, test_acc=0.9120\n",
      "epoch=32, train_loss=0.0515, test_acc=0.9135\n",
      "epoch=33, train_loss=0.0516, test_acc=0.9130\n",
      "epoch=34, train_loss=0.0515, test_acc=0.9101\n",
      "epoch=35, train_loss=0.0515, test_acc=0.9121\n",
      "epoch=36, train_loss=0.0514, test_acc=0.9103\n",
      "epoch=37, train_loss=0.0515, test_acc=0.9113\n",
      "epoch=38, train_loss=0.0514, test_acc=0.9119\n",
      "epoch=39, train_loss=0.0514, test_acc=0.9088\n",
      "epoch=40, train_loss=0.0512, test_acc=0.9132\n",
      "epoch=41, train_loss=0.0512, test_acc=0.9128\n",
      "epoch=42, train_loss=0.0512, test_acc=0.9126\n",
      "epoch=43, train_loss=0.0512, test_acc=0.9122\n",
      "epoch=44, train_loss=0.0512, test_acc=0.9120\n",
      "epoch=45, train_loss=0.0511, test_acc=0.9121\n",
      "epoch=46, train_loss=0.0511, test_acc=0.9121\n",
      "epoch=47, train_loss=0.0512, test_acc=0.9124\n",
      "epoch=48, train_loss=0.0511, test_acc=0.9123\n",
      "epoch=49, train_loss=0.0511, test_acc=0.9132\n",
      "epoch=50, train_loss=0.0511, test_acc=0.9135\n",
      "epoch=51, train_loss=0.0511, test_acc=0.9118\n",
      "epoch=52, train_loss=0.0511, test_acc=0.9121\n",
      "epoch=53, train_loss=0.0511, test_acc=0.9134\n",
      "epoch=54, train_loss=0.0511, test_acc=0.9127\n",
      "epoch=55, train_loss=0.0511, test_acc=0.9124\n",
      "epoch=56, train_loss=0.0511, test_acc=0.9133\n",
      "epoch=57, train_loss=0.0512, test_acc=0.9128\n",
      "epoch=58, train_loss=0.0511, test_acc=0.9126\n",
      "epoch=59, train_loss=0.0511, test_acc=0.9126\n",
      "block 26 recasting...\n",
      "block 26 training started...\n",
      "epoch=0, train_loss=0.4409, test_acc=0.8421\n",
      "epoch=1, train_loss=0.3073, test_acc=0.8703\n",
      "epoch=2, train_loss=0.2892, test_acc=0.8793\n",
      "epoch=3, train_loss=0.2804, test_acc=0.8884\n",
      "epoch=4, train_loss=0.2754, test_acc=0.8855\n",
      "epoch=5, train_loss=0.2715, test_acc=0.8767\n",
      "epoch=6, train_loss=0.2697, test_acc=0.8742\n",
      "epoch=7, train_loss=0.2670, test_acc=0.8922\n",
      "epoch=8, train_loss=0.2649, test_acc=0.8918\n",
      "epoch=9, train_loss=0.2628, test_acc=0.8929\n",
      "epoch=10, train_loss=0.2625, test_acc=0.8733\n",
      "epoch=11, train_loss=0.2612, test_acc=0.9072\n",
      "epoch=12, train_loss=0.2592, test_acc=0.8956\n",
      "epoch=13, train_loss=0.2585, test_acc=0.8913\n",
      "epoch=14, train_loss=0.2557, test_acc=0.8872\n",
      "epoch=15, train_loss=0.2559, test_acc=0.9001\n",
      "epoch=16, train_loss=0.2541, test_acc=0.8825\n",
      "epoch=17, train_loss=0.2546, test_acc=0.8821\n",
      "epoch=18, train_loss=0.2535, test_acc=0.8911\n",
      "epoch=19, train_loss=0.2525, test_acc=0.9080\n",
      "epoch=20, train_loss=0.2337, test_acc=0.9223\n",
      "epoch=21, train_loss=0.2289, test_acc=0.9238\n",
      "epoch=22, train_loss=0.2276, test_acc=0.9223\n",
      "epoch=23, train_loss=0.2283, test_acc=0.9248\n",
      "epoch=24, train_loss=0.2271, test_acc=0.9240\n",
      "epoch=25, train_loss=0.2263, test_acc=0.9252\n",
      "epoch=26, train_loss=0.2254, test_acc=0.9226\n",
      "epoch=27, train_loss=0.2260, test_acc=0.9213\n",
      "epoch=28, train_loss=0.2241, test_acc=0.9237\n",
      "epoch=29, train_loss=0.2258, test_acc=0.9227\n",
      "epoch=30, train_loss=0.2253, test_acc=0.9236\n",
      "epoch=31, train_loss=0.2251, test_acc=0.9254\n",
      "epoch=32, train_loss=0.2243, test_acc=0.9240\n",
      "epoch=33, train_loss=0.2247, test_acc=0.9238\n",
      "epoch=34, train_loss=0.2243, test_acc=0.9239\n",
      "epoch=35, train_loss=0.2234, test_acc=0.9230\n",
      "epoch=36, train_loss=0.2242, test_acc=0.9233\n",
      "epoch=37, train_loss=0.2233, test_acc=0.9209\n",
      "epoch=38, train_loss=0.2236, test_acc=0.9214\n",
      "epoch=39, train_loss=0.2238, test_acc=0.9220\n",
      "epoch=40, train_loss=0.2215, test_acc=0.9229\n",
      "epoch=41, train_loss=0.2215, test_acc=0.9241\n",
      "epoch=42, train_loss=0.2211, test_acc=0.9222\n",
      "epoch=43, train_loss=0.2209, test_acc=0.9233\n",
      "epoch=44, train_loss=0.2211, test_acc=0.9246\n",
      "epoch=45, train_loss=0.2215, test_acc=0.9254\n",
      "epoch=46, train_loss=0.2206, test_acc=0.9240\n",
      "epoch=47, train_loss=0.2211, test_acc=0.9229\n",
      "epoch=48, train_loss=0.2212, test_acc=0.9234\n",
      "epoch=49, train_loss=0.2206, test_acc=0.9243\n",
      "epoch=50, train_loss=0.2212, test_acc=0.9237\n",
      "epoch=51, train_loss=0.2215, test_acc=0.9229\n",
      "epoch=52, train_loss=0.2212, test_acc=0.9245\n",
      "epoch=53, train_loss=0.2205, test_acc=0.9241\n",
      "epoch=54, train_loss=0.2214, test_acc=0.9235\n",
      "epoch=55, train_loss=0.2202, test_acc=0.9242\n",
      "epoch=56, train_loss=0.2205, test_acc=0.9239\n",
      "epoch=57, train_loss=0.2206, test_acc=0.9236\n",
      "epoch=58, train_loss=0.2207, test_acc=0.9229\n",
      "epoch=59, train_loss=0.2202, test_acc=0.9248\n"
     ]
    }
   ],
   "source": [
    "history = dict()\n",
    "for idx in range(len(student.layers)):\n",
    "    history[idx] = dict(train_loss=[], test_acc=[], train_time=[], test_time=[])\n",
    "    \n",
    "    # recasting\n",
    "    print(f'block {idx} recasting...')\n",
    "    target_block = student.layers[idx]\n",
    "    in_channels = target_block.conv1.in_channels\n",
    "    stride = target_block.conv1.stride\n",
    "    out_channels = target_block.conv2.out_channels\n",
    "    \n",
    "    student.layers[idx] = ConvBlock(in_channels, out_channels, stride).to(device)\n",
    "    for m in student.layers[idx].modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    params = []\n",
    "    for i in range(idx + 1):\n",
    "        params.extend(student.layers[i].parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size)\n",
    "\n",
    "    print(f'block {idx} training started...')\n",
    "    for ep in range(epoch):\n",
    "        # train step\n",
    "        train_loss = 0.0\n",
    "        student.train()\n",
    "        s_time = time.time()\n",
    "        for i, (image, _) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "\n",
    "            target = teacher(image, idx)\n",
    "            pred = student(image, idx)\n",
    "\n",
    "            loss = mse_loss(pred, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        e_time = time.time()\n",
    "        history[idx]['train_loss'].append(train_loss/len(train_loader))\n",
    "        history[idx]['train_time'].append(e_time - s_time)\n",
    "\n",
    "        # test step\n",
    "        test_acc = 0.0\n",
    "        student.eval()\n",
    "        s_time = time.time()\n",
    "        for image, target in test_loader:\n",
    "            image = image.to(device)\n",
    "            target = f.one_hot(target, 10).float().to(device)\n",
    "\n",
    "            pred = student(image)\n",
    "            test_acc += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(target, dim=1)).item()\n",
    "        e_time = time.time()\n",
    "        history[idx]['test_acc'].append(test_acc/len(test_dataset))\n",
    "        history[idx]['test_time'].append(e_time - s_time)\n",
    "        print(f'epoch={ep:d}, train_loss={train_loss/len(train_loader):.4f}, test_acc={test_acc/len(test_dataset):.4f}')\n",
    "\n",
    "        checkpoint = dict(\n",
    "            model=student.state_dict(),\n",
    "            optimizer=optimizer.state_dict(),\n",
    "            history=history,\n",
    "            epoch=ep\n",
    "        )\n",
    "        torch.save(checkpoint, f'./result/{dataset_name}_{student_name}.pt')\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 415546\n",
      "CustomResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layers): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): ConvBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): ConvBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (23): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (24): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (25): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (26): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "student = CustomResNet(block=ConvBlock,\n",
    "                   layers=[9, 9, 9],\n",
    "                   num_classes=num_class).to(device)\n",
    "checkpoint = torch.load(f'./result/{dataset_name}_{student_name}.pt')\n",
    "student.load_state_dict(checkpoint['model'])\n",
    "\n",
    "total_params = sum(p.numel() for p in student.parameters())\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "print(student)\n",
    "\n",
    "checkpoint['history'][0]['test_acc']\n",
    "\n",
    "x = np.arange(len(checkpoint['history']))\n",
    "y = list(checkpoint['history'][i]['test_acc'][-1] for i in range(len(checkpoint['history'])))\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
